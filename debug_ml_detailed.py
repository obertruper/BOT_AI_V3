#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ ML –º–æ–¥–µ–ª–∏ - –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö/–≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import asyncio
import json
import sys

import numpy as np
import pandas as pd
import torch

sys.path.append("/mnt/SSD/PYCHARMPRODJECT/BOT_AI_V3")

from core.logger import setup_logger
from database.connections.postgres import AsyncPGPool
from ml.logic.feature_engineering import FeatureEngineer
from ml.ml_manager import MLManager

logger = setup_logger("debug_ml_detailed")


async def debug_ml_pipeline():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ ML pipeline —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤."""

    print("üîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ML PIPELINE\n")

    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    print("1Ô∏è‚É£ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    config = {
        "ml": {
            "model": {"device": "cuda" if torch.cuda.is_available() else "cpu"},
            "model_directory": "models/saved",
        }
    }

    ml_manager = MLManager(config)
    await ml_manager.initialize()

    feature_engineer = FeatureEngineer(config)

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î
    print("\n2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î...")
    query = """
    SELECT * FROM raw_market_data
    WHERE symbol = 'BTCUSDT'
    ORDER BY datetime DESC
    LIMIT 100
    """

    raw_data = await AsyncPGPool.fetch(query)

    if not raw_data:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –ë–î!")
        return

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame (–∏–∑ asyncpg Records)
    df_data = []
    for row in raw_data:
        df_data.append(dict(row))
    df = pd.DataFrame(df_data)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Decimal –≤ float
    for col in ["open", "high", "low", "close", "volume"]:
        df[col] = df[col].astype(float)

    df = df.sort_values("datetime")

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π")
    print(f"   –ü–µ—Ä–∏–æ–¥: {df['datetime'].min()} - {df['datetime'].max()}")
    print(f"   –¶–µ–Ω–∞: ${float(df['close'].iloc[-1]):.2f}")

    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n3Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Engineering)...")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features = feature_engineer.create_features(df)

    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features.shape}")
    print(f"   Shape: {features.shape}")
    print(f"   Min: {features.min():.6f}, Max: {features.max():.6f}")
    print(f"   Mean: {features.mean():.6f}, Std: {features.std():.6f}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
    nan_count = np.isnan(features).sum()
    if nan_count > 0:
        print(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {nan_count} NaN –∑–Ω–∞—á–µ–Ω–∏–π!")

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ scaler
    print("\n4Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (Scaler)...")

    if ml_manager.scaler:
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 96 —Ç–æ—á–µ–∫
        if len(features) >= 96:
            features_window = features[-96:]
        else:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            padding = np.zeros((96 - len(features), features.shape[1]))
            features_window = np.vstack([padding, features])

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features_scaled = ml_manager.scaler.transform(features_window)

        print("‚úÖ –ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:")
        print(f"   Shape: {features_scaled.shape}")
        print(f"   Min: {features_scaled.min():.6f}, Max: {features_scaled.max():.6f}")
        print(
            f"   Mean: {features_scaled.mean():.6f}, Std: {features_scaled.std():.6f}"
        )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤—ã—Ö 10 –∑–Ω–∞—á–µ–Ω–∏–π
        print("\n   –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö 10 –∑–Ω–∞—á–µ–Ω–∏–π (–ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞):")
        print(f"   –î–æ: {features_window[-1, :10]}")
        print(f"   –ü–æ—Å–ª–µ: {features_scaled[-1, :10]}")

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏
    print("\n5Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏...")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    model_info = ml_manager.get_model_info()
    print(f"   –ú–æ–¥–µ–ª—å: {model_info['model_type']}")
    print(f"   Device: {model_info['device']}")
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–∞: {model_info['model_loaded']}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
    if ml_manager.model:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å–∞ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è
        first_layer = list(ml_manager.model.parameters())[0]
        print("\n   –í–µ—Å–∞ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è:")
        print(f"   Shape: {first_layer.shape}")
        print(
            f"   Min: {first_layer.min().item():.6f}, Max: {first_layer.max().item():.6f}"
        )
        print(
            f"   Mean: {first_layer.mean().item():.6f}, Std: {first_layer.std().item():.6f}"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ª–∏ –≤–µ—Å–∞
        if first_layer.std().item() < 0.001:
            print("   ‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í–µ—Å–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω—É–ª–µ–≤—ã–µ - –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")

    # 6. –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
    print("\n6Ô∏è‚É£ –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å...")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–Ω–∑–æ—Ä–∞
    x = torch.FloatTensor(features_scaled).unsqueeze(0).to(ml_manager.device)
    print(f"   Input tensor shape: {x.shape}")

    # Forward pass
    with torch.no_grad():
        # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏
        raw_output = ml_manager.model(x)

        print("\n   Raw model output:")
        print(f"   Shape: {raw_output.shape}")
        print(f"   Values: {raw_output.cpu().numpy()[0]}")
        print(
            f"   Min: {raw_output.min().item():.6f}, Max: {raw_output.max().item():.6f}"
        )

    # 7. –ü–æ–ª–Ω—ã–π predict —á–µ—Ä–µ–∑ MLManager
    print("\n7Ô∏è‚É£ –ü–æ–ª–Ω—ã–π predict —á–µ—Ä–µ–∑ MLManager...")

    prediction = await ml_manager.predict(features_window)

    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print(json.dumps(prediction, indent=2))

    # 8. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º—ã
    print("\n8Ô∏è‚É£ –ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú–´:")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏
    print("\nüèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    print(ml_manager.model)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    model_path = ml_manager.model_path
    if model_path.exists():
        print(f"\n‚úÖ –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–∞–π–¥–µ–Ω: {model_path}")
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
        checkpoint = torch.load(model_path, map_location="cpu")
        print(f"   –ö–ª—é—á–∏ –≤ checkpoint: {list(checkpoint.keys())}")
        if "model_state_dict" in checkpoint:
            state_dict = checkpoint["model_state_dict"]
            print(f"   –°–ª–æ–∏ –≤ –º–æ–¥–µ–ª–∏: {list(state_dict.keys())[:5]}...")
    else:
        print(f"\n‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –ù–ï –ù–ê–ô–î–ï–ù: {model_path}")
        print("   –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç –ø–æ—á–µ–º—É –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ!")

    # 9. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
    print("\n9Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")

    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–æ–≥–∏–∫–∏
    test_values = [
        np.array([0.0, 0.0, 0.0, 0.0]),  # –í—Å–µ –Ω—É–ª–∏
        np.array([1.0, 1.0, 1.0, 1.0]),  # –í—Å–µ –µ–¥–∏–Ω–∏—Ü—ã
        np.array([2.0, 2.0, 2.0, 2.0]),  # –¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞
        np.array([-1.0, 0.0, 1.0, 2.0]),  # –†–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    ]

    print("\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:")
    for i, test_val in enumerate(test_values):
        normalized = np.tanh(test_val)
        interpreted = []
        for norm in normalized:
            if norm > 0.2:
                interpreted.append("LONG")
            elif norm < -0.2:
                interpreted.append("SHORT")
            else:
                interpreted.append("NEUTRAL")

        print(f"\n   Test {i + 1}: {test_val}")
        print(f"   Tanh: {normalized}")
        print(f"   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {interpreted}")

    print("\n" + "=" * 80)
    print("üìå –í–´–í–û–î–´:")
    print("1. –ú–æ–¥–µ–ª—å –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [2.0, 2.0, 2.0, 2.0], –ø–æ—Ç–æ–º—É —á—Ç–æ:")
    print("   - –§–∞–π–ª –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤")
    print("   - –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω—ã–µ/–Ω–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞")
    print("   - –ü–æ—Å–ª–µ tanh(2.0) = 0.964, —á—Ç–æ –≤—Å–µ–≥–¥–∞ > 0.2 ‚Üí –≤—Å–µ–≥–¥–∞ LONG")
    print("\n2. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ:")
    print("   - –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    print("   - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Å–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")
    print("   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")


if __name__ == "__main__":
    asyncio.run(debug_ml_pipeline())
