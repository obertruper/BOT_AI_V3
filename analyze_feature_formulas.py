#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º—É–ª —Ä–∞—Å—á–µ—Ç–∞ –ö–ê–ñ–î–û–ì–û –∏–∑ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ–±—É—á–∞—é—â–∏–π —Ñ–∞–π–ª (–∞–∞–∞.py) —Å —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π.
"""

import re


class DetailedFeatureAnalyzer:
    def __init__(self):
        self.training_file = "/mnt/SSD/PYCHARMPRODJECT/BOT_AI_V3/BOT_AI_V2/–∞–∞–∞.py"
        self.current_file = "/ml/logic/archive_old_versions/feature_engineering_v2.py"
        self.issues = []

    def read_file(self, filepath):
        """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª"""
        with open(filepath, encoding="utf-8") as f:
            return f.read()

    def analyze_critical_features(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ–±—É—á–µ–Ω–∏—è"""
        training_content = self.read_file(self.training_file)

        print("=" * 80)
        print("üî¨ –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –§–û–†–ú–£–õ –ü–†–ò–ó–ù–ê–ö–û–í –ò–ó –û–ë–£–ß–ê–Æ–©–ï–ì–û –§–ê–ô–õ–ê")
        print("=" * 80)

        # 1. RSI
        print("\n1Ô∏è‚É£ RSI (Relative Strength Index):")
        rsi_match = re.search(
            r"df\['rsi'\] = ta\.momentum\.RSIIndicator\([^)]+window=(\d+)", training_content
        )
        if rsi_match:
            print(f"  üìä –í –æ–±—É—á–µ–Ω–∏–∏: RSI —Å –ø–µ—Ä–∏–æ–¥–æ–º {rsi_match.group(1)}")
            print("  ‚ö†Ô∏è  –í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –û–î–ò–ù RSI, –Ω–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ!")

        # 2. SMA
        print("\n2Ô∏è‚É£ SMA (Simple Moving Average):")
        sma_matches = re.findall(r"sma_(\d+)", training_content)
        unique_sma = set(sma_matches)
        print(f"  üìä –í –æ–±—É—á–µ–Ω–∏–∏ SMA –ø–µ—Ä–∏–æ–¥—ã: {sorted([int(p) for p in unique_sma])}")
        sma_formula = re.search(r"df\[f'sma_\{period\}'\] = (.*)", training_content)
        if sma_formula:
            print(f"  üìê –§–æ—Ä–º—É–ª–∞: {sma_formula.group(1)}")

        # 3. Returns
        print("\n3Ô∏è‚É£ RETURNS (–î–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏):")
        returns_basic = re.search(r"df\['returns'\] = (.*)", training_content)
        if returns_basic:
            print(f"  üìä –ë–∞–∑–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∞: {returns_basic.group(1)}")
            if "np.log" in returns_basic.group(1):
                print("  ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è LOG returns!")
            else:
                print("  ‚ùå –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è log returns!")

        # 4. BTC Correlation (–ö–†–ò–¢–ò–ß–ù–û!)
        print("\n4Ô∏è‚É£ BTC CORRELATION (–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û!):")
        btc_corr = re.search(
            r"btc_correlation.*?rolling\(window=(\d+), min_periods=(\d+)\)", training_content
        )
        if btc_corr:
            print(f"  üìä Window: {btc_corr.group(1)}, Min periods: {btc_corr.group(2)}")
            print("  ‚úÖ –¢–û–ß–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: window=96, min_periods=50")

        # 5. BTC Beta
        print("\n5Ô∏è‚É£ BTC BETA:")
        btc_beta = re.search(r"btc_beta.*?rolling\((\d+)\)", training_content)
        if btc_beta:
            print(f"  üìä Rolling window: {btc_beta.group(1)}")

        # 6. Volatility
        print("\n6Ô∏è‚É£ VOLATILITY:")
        vol_matches = re.findall(r"volatility.*?rolling\((\d+)\)\.std\(\)", training_content)
        if vol_matches:
            print(f"  üìä Volatility windows: {vol_matches}")

        # 7. MACD
        print("\n7Ô∏è‚É£ MACD:")
        macd_match = re.search(
            r"MACD\([^,]+,\s*window_slow=(\d+),\s*window_fast=(\d+),\s*window_sign=(\d+)",
            training_content,
        )
        if macd_match:
            print(
                f"  üìä Slow: {macd_match.group(1)}, Fast: {macd_match.group(2)}, Signal: {macd_match.group(3)}"
            )
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
            macd_norm = re.search(r"macd.*?/.*?df\['close'\].*?\*.*?100", training_content)
            if macd_norm:
                print("  ‚úÖ MACD –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—ã (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)!")

        # 8. Bollinger Bands
        print("\n8Ô∏è‚É£ BOLLINGER BANDS:")
        bb_match = re.search(
            r"BollingerBands\([^,]+,\s*window=(\d+),\s*window_dev=(\d+)", training_content
        )
        if bb_match:
            print(f"  üìä Window: {bb_match.group(1)}, Std dev: {bb_match.group(2)}")

        # 9. Cross-asset features summary
        print("\n9Ô∏è‚É£ CROSS-ASSET FEATURES SUMMARY:")
        cross_features = []
        if "btc_correlation" in training_content:
            cross_features.append("btc_correlation")
        if "btc_beta" in training_content:
            cross_features.append("btc_beta")
        if "relative_strength_btc" in training_content:
            cross_features.append("relative_strength_btc")
        if "rs_btc_ma" in training_content:
            cross_features.append("rs_btc_ma")
        if "idio_vol" in training_content:
            cross_features.append("idio_vol")

        print(f"  üìä –ù–∞–π–¥–µ–Ω–æ cross-asset –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(cross_features)}")
        for cf in cross_features:
            print(f"    - {cf}")

        # 10. ETH features check
        print("\nüîü ETH FEATURES:")
        eth_count = training_content.count("eth_")
        print(f"  üìä ETH –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏: {eth_count}")
        if eth_count == 0:
            print("  ‚úÖ ETH –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ù–ï–¢ –≤ –æ–±—É—á–µ–Ω–∏–∏ (—ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ!)")

        return cross_features

    def generate_fix_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é"""
        print("\n" + "=" * 80)
        print("üìù –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Æ")
        print("=" * 80)

        recommendations = [
            {
                "feature": "RSI",
                "current": "rsi_5, rsi_14, rsi_21",
                "should_be": "rsi (single period from config)",
                "action": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω RSI —Å –ø–µ—Ä–∏–æ–¥–æ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞",
            },
            {
                "feature": "BTC Correlation",
                "current": "Multiple timeframes",
                "should_be": "Single correlation with window=96, min_periods=50",
                "action": "–ò–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å —Ç–æ—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏",
            },
            {
                "feature": "ETH Correlation",
                "current": "Present in current",
                "should_be": "Not in training",
                "action": "–£–±—Ä–∞—Ç—å ETH –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏–ª–∏ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∑–∞–≥–ª—É—à–∫–∞–º–∏ 0.5",
            },
            {
                "feature": "BTC Beta",
                "current": "Unknown",
                "should_be": "rolling(100).cov / rolling(100).var",
                "action": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—á–Ω—É—é —Ñ–æ—Ä–º—É–ª—É –∏–∑ –æ–±—É—á–µ–Ω–∏—è",
            },
            {
                "feature": "MACD",
                "current": "Absolute values",
                "should_be": "Normalized by price (* 100)",
                "action": "–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å MACD –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—ã",
            },
            {
                "feature": "Returns",
                "current": "Simple returns",
                "should_be": "Log returns: np.log(close/close.shift(period))",
                "action": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏",
            },
        ]

        print("\nüìã –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:")
        for i, rec in enumerate(recommendations, 1):
            print(f"\n{i}. {rec['feature']}:")
            print(f"   –°–µ–π—á–∞—Å: {rec['current']}")
            print(f"   –î–æ–ª–∂–Ω–æ: {rec['should_be']}")
            print(f"   ‚úèÔ∏è –î–µ–π—Å—Ç–≤–∏–µ: {rec['action']}")

        return recommendations

    def check_exact_feature_list(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –æ–±—É—á–µ–Ω–∏—è"""
        training_content = self.read_file(self.training_file)

        print("\n" + "=" * 80)
        print("üìä –¢–û–ß–ù–´–ô –°–ü–ò–°–û–ö –ü–†–ò–ó–ù–ê–ö–û–í –ò–ó –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 80)

        # –ò—â–µ–º –≤—Å–µ df['feature_name'] =
        feature_assignments = re.findall(r"df\['([^']+)'\]\s*=", training_content)
        unique_features = sorted(set(feature_assignments))

        print(f"\n–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏: {len(unique_features)}")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        feature_groups = {
            "returns": [],
            "volatility": [],
            "sma": [],
            "ema": [],
            "rsi": [],
            "macd": [],
            "bb": [],
            "btc": [],
            "volume": [],
            "price": [],
            "other": [],
        }

        for feat in unique_features:
            categorized = False
            for key in feature_groups:
                if key in feat.lower() and key != "other":
                    feature_groups[key].append(feat)
                    categorized = True
                    break
            if not categorized:
                feature_groups["other"].append(feat)

        # –í—ã–≤–æ–¥–∏–º –ø–æ –≥—Ä—É–ø–ø–∞–º
        for group, features in feature_groups.items():
            if features:
                print(f"\n{group.upper()} ({len(features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤):")
                for f in features[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    print(f"  - {f}")
                if len(features) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(features) - 10}")

        return unique_features


if __name__ == "__main__":
    analyzer = DetailedFeatureAnalyzer()

    # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    cross_features = analyzer.analyze_critical_features()

    # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations = analyzer.generate_fix_recommendations()

    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫
    exact_features = analyzer.check_exact_feature_list()

    print("\n" + "=" * 80)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù")
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(exact_features)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–º —Ñ–∞–π–ª–µ")
    print(f"–¢—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å {len(recommendations)} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π")
    print("=" * 80)
