#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
"""

import sys
from pathlib import Path

import numpy as np
import pandas as pd
import torch

sys.path.insert(0, str(Path(__file__).parent))

from core.logger import setup_logger
from ml.logic.feature_engineering import FeatureEngineer

logger = setup_logger("fix_ml")


def analyze_features():
    """–ê–Ω–∞–ª–∏–∑ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

    print("üîç –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    np.random.seed(42)
    n_candles = 300

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    timestamps = pd.date_range(end=pd.Timestamp.now(), periods=n_candles, freq="15min")

    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∏ —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è
    scenarios = {
        "uptrend": {
            "trend": np.linspace(100000, 105000, n_candles),  # +5%
            "noise": np.random.normal(0, 100, n_candles),
        },
        "downtrend": {
            "trend": np.linspace(100000, 95000, n_candles),  # -5%
            "noise": np.random.normal(0, 100, n_candles),
        },
        "sideways": {
            "trend": np.full(n_candles, 100000),
            "noise": np.random.normal(0, 500, n_candles),
        },
    }

    fe = FeatureEngineer({})

    for scenario_name, scenario_data in scenarios.items():
        print(f"\nüìä –°—Ü–µ–Ω–∞—Ä–∏–π: {scenario_name}")

        prices = scenario_data["trend"] + scenario_data["noise"]

        data = pd.DataFrame(
            {
                "timestamp": timestamps,
                "open": prices * (1 + np.random.uniform(-0.001, 0.001, n_candles)),
                "high": prices * (1 + np.random.uniform(0, 0.002, n_candles)),
                "low": prices * (1 - np.random.uniform(0, 0.002, n_candles)),
                "close": prices,
                "volume": np.random.uniform(100, 1000, n_candles),
                "symbol": "BTCUSDT",
            }
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = fe.create_features(data)

        print(f"  Shape: {features.shape}")
        print("  –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–≤—ã—Ö 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for i in range(min(10, features.shape[1])):
            mean_val = np.mean(features[:, i])
            std_val = np.std(features[:, i])
            print(f"    Feature {i}: mean={mean_val:.4f}, std={std_val:.4f}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        constant_features = []
        for i in range(features.shape[1]):
            if np.std(features[:, i]) < 0.0001:
                constant_features.append(i)

        if constant_features:
            print(
                f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(constant_features)} –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {constant_features[:10]}..."
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN/Inf
        nan_count = np.isnan(features).sum()
        inf_count = np.isinf(features).sum()

        if nan_count > 0:
            print(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {nan_count} NaN –∑–Ω–∞—á–µ–Ω–∏–π")
        if inf_count > 0:
            print(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {inf_count} Inf –∑–Ω–∞—á–µ–Ω–∏–π")


def test_model_outputs():
    """–¢–µ—Å—Ç –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é"""

    print("\nüß™ –¢–µ—Å—Ç –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    from ml.logic.patchtst_model import create_unified_model

    config = {
        "model": {
            "input_size": 240,
            "output_size": 20,
            "context_window": 96,
            "patch_len": 16,
            "stride": 8,
            "d_model": 256,
            "n_heads": 4,
            "e_layers": 3,
            "d_ff": 512,
            "dropout": 0.1,
        }
    }

    model = create_unified_model(config)
    checkpoint = torch.load(
        "models/saved/best_model_20250728_215703.pth", map_location="cpu"
    )
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ –≤—Ö–æ–¥–∞–º–∏
    test_inputs = [
        torch.randn(1, 96, 240),  # –°–ª—É—á–∞–π–Ω—ã–π
        torch.zeros(1, 96, 240),  # –ù—É–ª–∏
        torch.ones(1, 96, 240),  # –ï–¥–∏–Ω–∏—Ü—ã
        torch.randn(1, 96, 240) * 10,  # –ë–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    ]

    print("\n–í—ã—Ö–æ–¥—ã –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤:")
    with torch.no_grad():
        for i, x in enumerate(test_inputs):
            outputs = model(x)
            outputs_np = outputs.numpy()[0]

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º future_directions (–∏–Ω–¥–µ–∫—Å—ã 4-7)
            future_directions = outputs_np[4:8]

            print(f"\n–í—Ö–æ–¥ {i + 1}:")
            print(f"  Future directions: {future_directions}")
            print(f"  –ü–æ—Å–ª–µ tanh: {np.tanh(future_directions)}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –≤—ã—Ö–æ–¥—ã
            print(f"  Future returns (0-3): {outputs_np[0:4]}")
            print(f"  Level targets (8-15): {outputs_np[8:16]}")
            print(f"  Risk metrics (16-19): {outputs_np[16:20]}")


def compare_with_llm_transform():
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å LLM TRANSFORM —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π"""

    print("\nüìã –ö–ª—é—á–µ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è —Å LLM TRANSFORM:")

    differences = """
    1. BOT_AI_V3 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç StandardScaler –≤–º–µ—Å—Ç–æ RobustScaler
       - StandardScaler —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º
       - RobustScaler –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–¥–∏–∞–Ω—É –∏ IQR

    2. BOT_AI_V3 –Ω–µ –∏–º–µ–µ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
       - –û–¥–∏–Ω —Å–∫–µ–π–ª–µ—Ä –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
       - –í LLM TRANSFORM - –æ—Ç–¥–µ–ª—å–Ω—ã–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞

    3. –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç crypto-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:
       - Funding rates
       - Liquidation levels
       - Cross-asset correlations
       - Market microstructure

    4. –ù–µ—Ç walk-forward validation
       - –í–æ–∑–º–æ–∂–Ω–∞ —É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ
       - –í LLM TRANSFORM —Å—Ç—Ä–æ–≥–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ

    5. –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
       - –ù–µ—Ç –∫–ª–∏–ø–ø–∏–Ω–≥–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
       - –ù–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–µ–ª–µ–Ω–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π inf/nan
    """

    print(differences)

    print("\n‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å feature_engineering.py –∏–∑ LLM TRANSFORM")
    print("2. –ó–∞–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –∏ scaler –Ω–∞ –≤–µ—Ä—Å–∏–∏ –∏–∑ LLM TRANSFORM")
    print("3. –û–±–Ω–æ–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
    print("4. –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")


if __name__ == "__main__":
    print("=" * 60)
    print("–ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú–´ ML –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô")
    print("=" * 60)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    analyze_features()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    test_model_outputs()

    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —ç—Ç–∞–ª–æ–Ω–æ–º
    compare_with_llm_transform()

    print("\n" + "=" * 60)
    print("–í–´–í–û–î: –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ feature engineering –∏–∑ LLM TRANSFORM")
    print("=" * 60)
