# \!/usr/bin/env python3
"""
–¢–µ—Å—Ç ML –º–æ–¥–µ–ª–∏ –Ω–∞ GPU –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–æ–≤
"""

import asyncio
import sys
import time
from pathlib import Path

import numpy as np
import pandas as pd
import torch

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, str(Path(__file__).parent))

from core.logger import setup_logger
from ml.ml_manager import MLManager

logger = setup_logger("test_ml_gpu")


async def test_ml_on_gpu():
    """–¢–µ—Å—Ç ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ GPU"""

    print("=" * 60)
    print("–¢–ï–°–¢ ML –ú–û–î–ï–õ–ò –ù–ê RTX 5090")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    print("\nüñ•Ô∏è –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
    print(f"  PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"  CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")

    if torch.cuda.is_available():
        print(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"  GPU {i}: {props.name}")
            print(f"    Compute Capability: {props.major}.{props.minor}")
            print(f"    –ü–∞–º—è—Ç—å: {props.total_memory / 1024**3:.1f} GB")
            print(
                f"    –°–≤–æ–±–æ–¥–Ω–æ: {(props.total_memory - torch.cuda.memory_allocated(i)) / 1024**3:.1f} GB"
            )

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = {
        "ml": {
            "model": {
                "device": "auto",  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä GPU/CPU
                "model_directory": "models/saved",
                "context_window": 96,
                "patch_len": 16,
                "stride": 8,
                "d_model": 256,
                "n_heads": 4,
                "e_layers": 3,
                "d_ff": 512,
                "dropout": 0.1,
            },
            "cache": {
                "indicator_ttl": 900,  # 15 –º–∏–Ω—É—Ç
                "feature_ttl": 300,  # 5 –º–∏–Ω—É—Ç
            },
        }
    }

    print("\nüß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML Manager...")
    ml_manager = MLManager(config)
    await ml_manager.initialize()

    print(f"‚úÖ ML Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ {ml_manager.device}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    model_info = ml_manager.get_model_info()
    print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
    for key, value in model_info.items():
        print(f"  {key}: {value}")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("\nüìà –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    np.random.seed(42)
    n_candles = 300

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ OHLCV –¥–∞–Ω–Ω—ã–µ
    base_price = 100000
    timestamps = pd.date_range(end=pd.Timestamp.now(), periods=n_candles, freq="15min")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–Ω—ã —Å —Ç—Ä–µ–Ω–¥–æ–º
    trend = np.linspace(0, 0.5, n_candles)  # –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
    noise = np.random.normal(0, 0.02, n_candles)
    prices = base_price * (1 + trend + noise)

    # –°–æ–∑–¥–∞–µ–º OHLCV DataFrame
    data = pd.DataFrame(
        {
            "timestamp": timestamps,
            "open": prices * (1 + np.random.uniform(-0.001, 0.001, n_candles)),
            "high": prices * (1 + np.random.uniform(0, 0.002, n_candles)),
            "low": prices * (1 - np.random.uniform(0, 0.002, n_candles)),
            "close": prices,
            "volume": np.random.uniform(100, 1000, n_candles),
            "symbol": "BTCUSDT",
        }
    )

    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(data)} —Å–≤–µ—á–µ–π")
    print(f"  –¶–µ–Ω–∞ –æ—Ç {data['close'].min():.2f} –¥–æ {data['close'].max():.2f}")
    print(f"  –ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {data['close'].iloc[-1]:.2f}")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print("\n‚ö° –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")

    # –ü—Ä–æ–≥—Ä–µ–≤
    _ = await ml_manager.predict(data)

    # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
    times = []
    predictions = []

    for i in range(5):
        start_time = time.time()
        pred = await ml_manager.predict(data)
        elapsed = time.time() - start_time
        times.append(elapsed)
        predictions.append(pred)
        print(
            f"  –ü–æ–ø—ã—Ç–∫–∞ {i + 1}: {elapsed * 1000:.1f}ms - –°–∏–≥–Ω–∞–ª: {pred['signal_type']}"
        )

    avg_time = np.mean(times)
    print(f"\nüìä –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {avg_time * 1000:.1f}ms")
    print(f"  –ú–∏–Ω: {min(times) * 1000:.1f}ms, –ú–∞–∫—Å: {max(times) * 1000:.1f}ms")

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    last_pred = predictions[-1]
    print("\nüéØ –î–µ—Ç–∞–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print(f"  –°–∏–≥–Ω–∞–ª: {last_pred['signal_type']}")
    print(f"  –°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞: {last_pred['signal_strength']:.3f}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {last_pred['confidence']:.3f}")
    print(f"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {last_pred['success_probability']:.1%}")
    print(f"  –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {last_pred['risk_level']}")

    if last_pred["stop_loss"] and last_pred["take_profit"]:
        print(f"  Stop Loss: {last_pred['stop_loss']:.2f}")
        print(f"  Take Profit: {last_pred['take_profit']:.2f}")

    print("\n  –î–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    for key, value in last_pred["predictions"].items():
        print(f"    {key}: {value:.3f}")

    # –¢–µ—Å—Ç —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä—ã–Ω–æ—á–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏
    print("\nüß™ –¢–µ—Å—Ç —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π:")

    # –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
    down_trend = data.copy()
    down_trend["close"] = down_trend["close"] * np.linspace(1, 0.95, len(down_trend))
    pred_down = await ml_manager.predict(down_trend)
    print(
        f"  –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (-5%): {pred_down['signal_type']} (—Å–∏–ª–∞: {pred_down['signal_strength']:.3f})"
    )

    # –ë–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
    sideways = data.copy()
    sideways["close"] = base_price + np.random.normal(0, 100, len(sideways))
    pred_sideways = await ml_manager.predict(sideways)
    print(
        f"  –ë–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ: {pred_sideways['signal_type']} (—Å–∏–ª–∞: {pred_sideways['signal_strength']:.3f})"
    )

    # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
    volatile = data.copy()
    volatile["high"] = volatile["close"] * 1.05
    volatile["low"] = volatile["close"] * 0.95
    pred_volatile = await ml_manager.predict(volatile)
    print(
        f"  –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {pred_volatile['signal_type']} (—Å–∏–ª–∞: {pred_volatile['signal_strength']:.3f})"
    )

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏ GPU
    if torch.cuda.is_available():
        print("\nüíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏:")
        print(f"  –í—ã–¥–µ–ª–µ–Ω–æ: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        print(f"  –ö—ç—à–∏—Ä–æ–≤–∞–Ω–æ: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
        print(f"  –ú–∞–∫—Å–∏–º—É–º: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")

    print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print(f"   –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞ {ml_manager.device}")

    return True


if __name__ == "__main__":
    try:
        asyncio.run(test_ml_on_gpu())
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)
