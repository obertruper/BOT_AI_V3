#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –í–°–ï–• 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è UnifiedPatchTST –º–æ–¥–µ–ª–∏
"""

import sys

import numpy as np
import pandas as pd

from ml.config.features_240 import REQUIRED_FEATURES_240, get_feature_groups
from ml.logic.feature_engineering_v2 import FeatureEngineer


def test_240_features():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤—Å–µ—Ö 240 —Ç—Ä–µ–±—É–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

    print("üß™ –§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ì–ï–ù–ï–†–ê–¶–ò–ò 240 –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 60)

    # 1. –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    print("üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    np.random.seed(42)

    # BTCUSDT –¥–∞–Ω–Ω—ã–µ
    n_points = 500  # –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    btc_data = pd.DataFrame(
        {
            "symbol": ["BTCUSDT"] * n_points,
            "datetime": pd.date_range("2024-01-01", periods=n_points, freq="15min"),
            "open": np.random.randn(n_points).cumsum() + 50000,
            "high": np.random.randn(n_points).cumsum() + 50100,
            "low": np.random.randn(n_points).cumsum() + 49900,
            "close": np.random.randn(n_points).cumsum() + 50000,
            "volume": np.random.randint(1000, 10000, n_points),
            "turnover": np.random.randint(50000000, 500000000, n_points),
        }
    )

    # ETHUSDT –¥–∞–Ω–Ω—ã–µ –¥–ª—è cross-asset features
    eth_data = pd.DataFrame(
        {
            "symbol": ["ETHUSDT"] * n_points,
            "datetime": pd.date_range("2024-01-01", periods=n_points, freq="15min"),
            "open": np.random.randn(n_points).cumsum() + 3000,
            "high": np.random.randn(n_points).cumsum() + 3100,
            "low": np.random.randn(n_points).cumsum() + 2900,
            "close": np.random.randn(n_points).cumsum() + 3000,
            "volume": np.random.randint(1000, 15000, n_points),
            "turnover": np.random.randint(3000000, 45000000, n_points),
        }
    )

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    test_df = pd.concat([btc_data, eth_data], ignore_index=True)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(test_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {test_df['symbol'].nunique()} —Å–∏–º–≤–æ–ª–æ–≤")

    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º FeatureEngineer
    print("\nüîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FeatureEngineer...")
    fe = FeatureEngineer({"features": {}}, inference_mode=True)
    fe.disable_progress = False  # –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

    # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    print("\n‚öôÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    try:
        result_df = fe.create_features(test_df, inference_mode=True)
        print("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        import traceback

        traceback.print_exc()
        return False

    # 4. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüìà –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("-" * 40)

    metadata_cols = ["symbol", "datetime", "open", "high", "low", "close", "volume"]
    feature_cols = [col for col in result_df.columns if col not in metadata_cols]

    print("üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  - –ó–∞–ø–∏—Å–µ–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ: {len(result_df):,}")
    print(f"  - –°–∏–º–≤–æ–ª–æ–≤: {result_df['symbol'].nunique()}")
    print(f"  - –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(result_df.columns)}")
    print(f"  - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {len(metadata_cols)}")
    print(f"  - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    print(f"  - –¢—Ä–µ–±—É–µ—Ç—Å—è: {len(REQUIRED_FEATURES_240)}")

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    missing_features = set(REQUIRED_FEATURES_240) - set(feature_cols)
    extra_features = set(feature_cols) - set(REQUIRED_FEATURES_240)

    print("\nüéØ –ü–†–û–í–ï–†–ö–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:")
    print(f"  - –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(missing_features)}")
    print(f"  - –õ–∏—à–Ω–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(extra_features)}")

    if missing_features:
        print(f"\n‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –ü–†–ò–ó–ù–ê–ö–ò ({len(missing_features)}):")
        for i, feat in enumerate(sorted(missing_features), 1):
            print(f"  {i:3d}. {feat}")
        return False

    if extra_features:
        print(f"\n‚ö†Ô∏è –õ–ò–®–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–ò ({len(extra_features)}):")
        for i, feat in enumerate(sorted(extra_features)[:10], 1):
            print(f"  {i:3d}. {feat}")
        if len(extra_features) > 10:
            print(f"  ... –∏ –µ—â–µ {len(extra_features) - 10} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # 6. –ê–Ω–∞–ª–∏–∑ –ø–æ –≥—Ä—É–ø–ø–∞–º
    print("\nüìã –ê–ù–ê–õ–ò–ó –ü–û –ì–†–£–ü–ü–ê–ú –ü–†–ò–ó–ù–ê–ö–û–í:")
    print("-" * 40)

    groups = get_feature_groups()
    for group_name, group_features in groups.items():
        if group_name == "basic":  # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            continue

        present = [f for f in group_features if f in feature_cols]
        missing_group = [f for f in group_features if f not in feature_cols]

        status = "‚úÖ" if len(missing_group) == 0 else "‚ùå"
        print(f"  {status} {group_name.upper()}: {len(present)}/{len(group_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        if missing_group:
            print(f"    –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {missing_group[:3]}{'...' if len(missing_group) > 3 else ''}")

    # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüîç –ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–•:")
    print("-" * 40)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ NaN
    nan_count = result_df[feature_cols].isna().sum().sum()
    print(f"  - NaN –∑–Ω–∞—á–µ–Ω–∏–π: {nan_count:,}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–µ–π
    inf_count = np.isinf(result_df[feature_cols].select_dtypes(include=[np.number])).sum().sum()
    print(f"  - –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {inf_count:,}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numeric_features = result_df[feature_cols].select_dtypes(include=[np.number])
    constant_features = []
    for col in numeric_features.columns:
        if numeric_features[col].nunique() <= 1:
            constant_features.append(col)

    print(f"  - –ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(constant_features)}")
    if constant_features:
        print(f"    –°–ø–∏—Å–æ–∫: {constant_features[:5]}{'...' if len(constant_features) > 5 else ''}")

    # 8. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    print("\nüèÜ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê:")
    print("=" * 40)

    if len(missing_features) == 0:
        print("‚úÖ –í–°–ï 240 –¢–†–ï–ë–£–ï–ú–´–• –ü–†–ò–ó–ù–ê–ö–û–í –ì–ï–ù–ï–†–ò–†–£–Æ–¢–°–Ø –ö–û–†–†–ï–ö–¢–ù–û!")
        print("‚úÖ ML –º–æ–¥–µ–ª—å UnifiedPatchTST –ø–æ–ª—É—á–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ")
        print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É")

        # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        print("\nüí° –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:")
        print("```python")
        print("from ml.logic.feature_engineering_v2 import FeatureEngineer")
        print("fe = FeatureEngineer({'features': {}}, inference_mode=True)")
        print("features_df = fe.create_features(market_data, inference_mode=True)")
        print("# features_df —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–æ–≤–Ω–æ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
        print("```")

        return True
    else:
        print(f"‚ùå –¢–ï–°–¢ –ù–ï –ü–†–û–ô–î–ï–ù: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {len(missing_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return False


if __name__ == "__main__":
    success = test_240_features()
    sys.exit(0 if success else 1)
