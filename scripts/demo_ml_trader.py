#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç —Ä–∞–±–æ—Ç—ã ML —Ç—Ä–µ–π–¥–µ—Ä–∞
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ –æ—Ç PatchTST –º–æ–¥–µ–ª–∏
"""

import asyncio
import logging
import pickle
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
import torch
from colorama import Fore, Style, init

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è colorama
init(autoreset=True)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class MLTraderDemo:
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã ML —Ç—Ä–µ–π–¥–µ—Ä–∞"""

    def __init__(self):
        self.model = None
        self.scaler = None
        self.config = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

    def load_model_components(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏"""
        logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏...")

        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            model_path = Path("models/saved/best_model_20250728_215703.pth")
            if model_path.exists():
                checkpoint = torch.load(model_path, map_location=self.device)
                if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
                    # –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ checkpoint
                    logger.info("–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ checkpoint, —Å–æ–∑–¥–∞–µ–º mock –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ")
                    self.model = None  # –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–º—É–ª—è—Ü–∏—é
                else:
                    self.model = checkpoint
                    if hasattr(self.model, "eval"):
                        self.model.eval()
                logger.info(f"{Fore.GREEN}‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ä–µ–∂–∏–º —Å–∏–º—É–ª—è—Ü–∏–∏){Style.RESET_ALL}")
            else:
                logger.error(f"{Fore.RED}‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}{Style.RESET_ALL}")
                return False

            # –ó–∞–≥—Ä—É–∑–∫–∞ scaler
            scaler_path = Path("models/saved/data_scaler.pkl")
            if scaler_path.exists():
                with open(scaler_path, "rb") as f:
                    self.scaler = pickle.load(f)
                logger.info(f"{Fore.GREEN}‚úÖ Scaler –∑–∞–≥—Ä—É–∂–µ–Ω{Style.RESET_ALL}")
            else:
                logger.error(f"{Fore.RED}‚ùå –§–∞–π–ª scaler –Ω–µ –Ω–∞–π–¥–µ–Ω: {scaler_path}{Style.RESET_ALL}")
                return False

            # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            config_path = Path("models/saved/config.pkl")
            if config_path.exists():
                with open(config_path, "rb") as f:
                    self.config = pickle.load(f)
                logger.info(f"{Fore.GREEN}‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞{Style.RESET_ALL}")
            else:
                logger.error(
                    f"{Fore.RED}‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}{Style.RESET_ALL}"
                )
                return False

            return True

        except Exception as e:
            logger.error(f"{Fore.RED}‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}{Style.RESET_ALL}")
            return False

    def generate_sample_data(self, num_points: int = 100) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥
        dates = pd.date_range(end=datetime.now(), periods=num_points, freq="15min")

        # –ë–∞–∑–æ–≤–∞—è —Ü–µ–Ω–∞ —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —à—É–º–æ–º
        base_price = 50000
        trend = np.linspace(0, 1000, num_points)
        noise = np.random.normal(0, 200, num_points)
        prices = base_price + trend + noise

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        volatility = np.random.normal(0, 100, num_points)

        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame(
            {
                "timestamp": dates,
                "open": prices + volatility * 0.5,
                "high": prices + abs(volatility),
                "low": prices - abs(volatility),
                "close": prices,
                "volume": np.random.uniform(100, 1000, num_points),
            }
        )

        # –í—ã—á–∏—Å–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df["sma_20"] = df["close"].rolling(20).mean()
        df["sma_50"] = df["close"].rolling(50).mean()
        df["rsi"] = self.calculate_rsi(df["close"])
        df["macd"], df["macd_signal"] = self.calculate_macd(df["close"])

        return df.dropna()

    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """–†–∞—Å—á–µ—Ç RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))

    def calculate_macd(self, prices: pd.Series) -> tuple:
        """–†–∞—Å—á–µ—Ç MACD"""
        ema12 = prices.ewm(span=12, adjust=False).mean()
        ema26 = prices.ewm(span=26, adjust=False).mean()
        macd = ema12 - ema26
        signal = macd.ewm(span=9, adjust=False).mean()
        return macd, signal

    def prepare_features(self, df: pd.DataFrame) -> np.ndarray:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        feature_cols = [
            "open",
            "high",
            "low",
            "close",
            "volume",
            "sma_20",
            "sma_50",
            "rsi",
            "macd",
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
        available_cols = [col for col in feature_cols if col in df.columns]

        if len(available_cols) < len(feature_cols):
            logger.warning(f"–ù–µ –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ–º: {available_cols}")

        features = df[available_cols].values

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if self.scaler:
            try:
                # –ü–æ–¥–≥–æ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–æ–¥ scaler
                if features.shape[1] < self.scaler.n_features_in_:
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                    padding = np.zeros(
                        (
                            features.shape[0],
                            self.scaler.n_features_in_ - features.shape[1],
                        )
                    )
                    features = np.hstack([features, padding])
                elif features.shape[1] > self.scaler.n_features_in_:
                    # –û–±—Ä–µ–∑–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                    features = features[:, : self.scaler.n_features_in_]

                features = self.scaler.transform(features)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ.")

        return features

    def generate_signals(self, df: pd.DataFrame) -> list[dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
        signals = []

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = self.prepare_features(df)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        features_tensor = torch.FloatTensor(features).unsqueeze(0).to(self.device)

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            with torch.no_grad():
                if self.model:
                    predictions = self.model(features_tensor)
                    # –ü—Ä–æ—Å—Ç–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –µ—Å–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ > 0, —Ç–æ –ø–æ–∫—É–ø–∫–∞
                    pred_values = predictions.cpu().numpy().flatten()
                else:
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É
                    pred_values = np.random.randn(len(df))

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            for i in range(min(5, len(pred_values))):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–∏–≥–Ω–∞–ª–æ–≤
                idx = -(i + 1)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞
                if pred_values[idx] > 0.5:
                    signal_type = "BUY"
                    color = Fore.GREEN
                elif pred_values[idx] < -0.5:
                    signal_type = "SELL"
                    color = Fore.RED
                else:
                    signal_type = "HOLD"
                    color = Fore.YELLOW

                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                confidence = min(abs(pred_values[idx]) / 2, 1.0)

                signal = {
                    "timestamp": df.iloc[idx]["timestamp"],
                    "type": signal_type,
                    "symbol": "BTC/USDT",
                    "price": df.iloc[idx]["close"],
                    "confidence": confidence,
                    "strength": abs(pred_values[idx]),
                    "color": color,
                    "features": {
                        "rsi": df.iloc[idx]["rsi"],
                        "macd": df.iloc[idx]["macd"],
                        "volume": df.iloc[idx]["volume"],
                    },
                }
                signals.append(signal)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

        return signals

    def print_signals(self, signals: list[dict[str, Any]]):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        print(f"\n{Fore.CYAN}{'=' * 60}{Style.RESET_ALL}")
        print(f"{Fore.CYAN}üìà –¢–û–†–ì–û–í–´–ï –°–ò–ì–ù–ê–õ–´ –û–¢ ML –ú–û–î–ï–õ–ò (PatchTST){Style.RESET_ALL}")
        print(f"{Fore.CYAN}{'=' * 60}{Style.RESET_ALL}\n")

        for signal in signals:
            color = signal["color"]
            print(f"{color}{'‚îÄ' * 50}{Style.RESET_ALL}")
            print(f"‚è∞ –í—Ä–µ–º—è: {signal['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"üìä –°–∏–º–≤–æ–ª: {signal['symbol']}")
            print(f"üí∞ –¶–µ–Ω–∞: ${signal['price']:.2f}")
            print(f"{color}üéØ –°–∏–≥–Ω–∞–ª: {signal['type']}{Style.RESET_ALL}")
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {signal['confidence']:.1%}")
            print(f"üí™ –°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞: {signal['strength']:.3f}")
            print("\nüìà –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:")
            print(f"   RSI: {signal['features']['rsi']:.2f}")
            print(f"   MACD: {signal['features']['macd']:.2f}")
            print(f"   Volume: {signal['features']['volume']:.2f}")

        print(f"\n{Fore.CYAN}{'=' * 60}{Style.RESET_ALL}")

    async def run_demo(self):
        """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        print(f"\n{Fore.CYAN}üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø ML –¢–†–ï–ô–î–ï–†–ê{Style.RESET_ALL}")
        print(f"{Fore.CYAN}–ú–æ–¥–µ–ª—å: PatchTST (Patch Time Series Transformer){Style.RESET_ALL}\n")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        if not self.load_model_components():
            logger.warning("–†–∞–±–æ—Ç–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ —Å–∏–º—É–ª—è—Ü–∏–∏ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        df = self.generate_sample_data()
        logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö")

        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        iteration = 0
        while True:
            try:
                iteration += 1
                print(f"\n{Fore.YELLOW}üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è #{iteration}{Style.RESET_ALL}")

                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                new_data = self.generate_sample_data(10)
                df = pd.concat([df, new_data]).tail(100)  # –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Ç–æ—á–µ–∫

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
                signals = self.generate_signals(df)

                # –í—ã–≤–æ–¥–∏–º —Å–∏–≥–Ω–∞–ª—ã
                if signals:
                    self.print_signals(signals)
                else:
                    print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                buy_signals = sum(1 for s in signals if s["type"] == "BUY")
                sell_signals = sum(1 for s in signals if s["type"] == "SELL")

                print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"   {Fore.GREEN}–°–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –ø–æ–∫—É–ø–∫—É: {buy_signals}{Style.RESET_ALL}")
                print(f"   {Fore.RED}–°–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É: {sell_signals}{Style.RESET_ALL}")
                print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {np.mean([s['confidence'] for s in signals]):.1%}")

                print(f"\n{Fore.CYAN}–û–∂–∏–¥–∞–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥... (Ctrl+C –¥–ª—è –≤—ã—Ö–æ–¥–∞){Style.RESET_ALL}")
                await asyncio.sleep(10)

            except KeyboardInterrupt:
                print(f"\n{Fore.YELLOW}–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞{Style.RESET_ALL}")
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(5)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    demo = MLTraderDemo()
    await demo.run_demo()


if __name__ == "__main__":
    asyncio.run(main())
