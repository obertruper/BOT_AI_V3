#!/usr/bin/env python3
"""
üéØ –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è BOT_AI_V3
–í–∏–∑—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –ø–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""

import argparse
import asyncio
import json
import shutil
import sys
import time
from datetime import datetime
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞—à–±–æ—Ä–¥–∞
try:
    from enhanced_dashboard_generator import EnhancedDashboardGenerator

    ENHANCED_DASHBOARD_AVAILABLE = True
except ImportError:
    ENHANCED_DASHBOARD_AVAILABLE = False


# –¶–≤–µ—Ç–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞
class Colors:
    HEADER = "\033[95m"
    BLUE = "\033[94m"
    CYAN = "\033[96m"
    GREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    UNDERLINE = "\033[4m"


class UnifiedTestOrchestrator:
    """–ï–¥–∏–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º"""

    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.results_dir = self.project_root / "test_results"
        self.results_dir.mkdir(exist_ok=True)

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.components = {
            "unit_tests": {
                "name": "Unit Tests",
                "icon": "üß™",
                "command": "pytest tests/unit/test_simple_working.py tests/unit/test_database_simple.py tests/unit/test_trading_simple.py tests/unit/test_ml_simple.py --tb=short -q",
                "enabled": True,
                "status": "pending",
            },
            "database_tests": {
                "name": "Database Tests",
                "icon": "üóÑÔ∏è",
                "command": "pytest tests/unit/test_database_simple.py --tb=short -q",
                "enabled": True,
                "status": "pending",
            },
            "trading_tests": {
                "name": "Trading Tests",
                "icon": "üìà",
                "command": "pytest tests/unit/test_trading_simple.py --tb=short -q",
                "enabled": True,
                "status": "pending",
            },
            "ml_tests": {
                "name": "ML System Tests",
                "icon": "üß†",
                "command": "pytest tests/unit/test_ml_simple.py --tb=short -q",
                "enabled": True,
                "status": "pending",
            },
            "integration_tests": {
                "name": "Integration Tests",
                "icon": "üîó",
                "command": "pytest tests/integration/test_core_system_integration.py tests/integration/test_end_to_end_workflows.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "performance_tests": {
                "name": "Performance Tests",
                "icon": "‚ö°",
                "command": "python3 test_signal_quality.py 2>/dev/null || echo 'Performance test not found'",
                "enabled": False,
                "status": "pending",
            },
            "code_quality": {
                "name": "Code Quality Check",
                "icon": "‚ú®",
                "command": "ruff check . --statistics 2>/dev/null || echo 'Ruff not configured'",
                "enabled": True,
                "status": "pending",
            },
            "type_check": {
                "name": "Type Checking",
                "icon": "üîç",
                "command": "mypy . --ignore-missing-imports --no-error-summary 2>/dev/null || echo 'MyPy check skipped'",
                "enabled": False,
                "status": "pending",
            },
            "coverage_report": {
                "name": "Coverage Report",
                "icon": "üìä",
                "command": "pytest tests/unit/test_simple_working.py tests/unit/test_database_simple.py tests/unit/test_trading_simple.py tests/unit/test_ml_simple.py tests/unit/test_feature_engineering_production.py tests/unit/test_exchanges_comprehensive.py tests/unit/test_web_api_comprehensive.py tests/unit/test_core_orchestrator.py tests/unit/test_trading_engine_comprehensive.py tests/unit/test_ml_manager_comprehensive.py tests/unit/test_core_system_comprehensive.py tests/unit/test_main_application.py tests/unit/test_unified_launcher.py tests/unit/test_ml_prediction_logger.py tests/unit/test_ml_manager_enhanced.py --cov=main --cov=unified_launcher --cov=core --cov=trading --cov=ml --cov=database --cov=exchanges --cov=web --cov-report=term-missing --cov-report=json -q",
                "enabled": True,
                "status": "pending",
            },
            "security_check": {
                "name": "Security Check",
                "icon": "üîê",
                "command": "grep -r 'API_KEY\\|SECRET\\|PASSWORD' --include='*.py' . 2>/dev/null | grep -v '.env' | grep -v 'test_' || echo 'No secrets found in code'",
                "enabled": True,
                "status": "pending",
            },
            "feature_engineering_tests": {
                "name": "Feature Engineering Tests",
                "icon": "‚öôÔ∏è",
                "command": "pytest tests/unit/test_feature_engineering_production.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "exchanges_tests": {
                "name": "Exchanges System Tests",
                "icon": "üîÑ",
                "command": "pytest tests/unit/test_exchanges_comprehensive.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "web_api_tests": {
                "name": "Web API Tests",
                "icon": "üåê",
                "command": "pytest tests/unit/test_web_api_comprehensive.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "core_orchestrator_tests": {
                "name": "Core Orchestrator Tests",
                "icon": "üéØ",
                "command": "pytest tests/unit/test_core_orchestrator.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "trading_engine_tests": {
                "name": "Trading Engine Tests",
                "icon": "‚ö°",
                "command": "pytest tests/unit/test_trading_engine_comprehensive.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "ml_manager_tests": {
                "name": "ML Manager Tests",
                "icon": "üß†",
                "command": "pytest tests/unit/test_ml_manager_comprehensive.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "core_system_tests": {
                "name": "Core System Tests",
                "icon": "‚öôÔ∏è",
                "command": "pytest tests/unit/test_core_system_comprehensive.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "main_application_tests": {
                "name": "Main Application Tests",
                "icon": "üéØ",
                "command": "pytest tests/unit/test_main_application.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "unified_launcher_tests": {
                "name": "Unified Launcher Tests",
                "icon": "üöÄ",
                "command": "pytest tests/unit/test_unified_launcher.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "ml_prediction_logger_tests": {
                "name": "ML Prediction Logger Tests",
                "icon": "üìä",
                "command": "pytest tests/unit/test_ml_prediction_logger.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "ml_manager_enhanced_tests": {
                "name": "ML Manager Enhanced Tests",
                "icon": "üß†",
                "command": "pytest tests/unit/test_ml_manager_enhanced.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "code_usage_analyzer_tests": {
                "name": "Code Usage Analyzer Tests",
                "icon": "üîç",
                "command": "pytest tests/analysis/test_code_usage_analyzer.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "code_analyzer_validation_tests": {
                "name": "Code Analyzer Validation Tests",
                "icon": "‚úÖ",
                "command": "pytest tests/analysis/test_code_analyzer_validation.py --tb=short -v",
                "enabled": True,
                "status": "pending",
            },
            "code_analysis_report": {
                "name": "Code Usage Analysis Report",
                "icon": "üìä",
                "command": "python3 scripts/run_code_usage_analysis.py --format both --verbose",
                "enabled": False,  # –û—Ç–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–∞–∫ –∫–∞–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º
                "status": "pending",
            },
            # === DYNAMIC SL/TP TEST SUITE ===
            "dynamic_sltp_unit_tests": {
                "name": "Dynamic SL/TP Unit Tests",
                "icon": "üìä",
                "command": "pytest tests/unit/trading/orders/test_dynamic_sltp_calculator.py -v --tb=short -m sltp",
                "enabled": True,
                "status": "pending",
            },
            "dynamic_sltp_integration_tests": {
                "name": "Dynamic SL/TP Integration",
                "icon": "üîó",
                "command": "pytest tests/integration/test_dynamic_sltp_integration.py -v --tb=short -m 'integration and sltp'",
                "enabled": True,
                "status": "pending",
            },
            "dynamic_sltp_e2e_tests": {
                "name": "Dynamic SL/TP E2E Tests",
                "icon": "üéØ",
                "command": "pytest tests/integration/test_dynamic_sltp_e2e.py -v --tb=short -m 'e2e and sltp'",
                "enabled": True,
                "status": "pending",
            },
            "dynamic_sltp_performance_tests": {
                "name": "Dynamic SL/TP Performance",
                "icon": "‚ö°",
                "command": "pytest tests/performance/test_dynamic_sltp_performance.py -v --tb=short -m 'performance and sltp'",
                "enabled": False,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ç–∫–ª—é—á–µ–Ω - –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º
                "status": "pending",
            },
            "dynamic_sltp_comprehensive": {
                "name": "Complete Dynamic SL/TP Suite",
                "icon": "üé™",
                "command": "pytest tests/unit/trading/orders/test_dynamic_sltp_calculator.py tests/integration/test_dynamic_sltp_integration.py tests/integration/test_dynamic_sltp_e2e.py -v --tb=short -m sltp",
                "enabled": True,
                "status": "pending",
            },
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "coverage_percent": 0.0,
            "execution_time": 0,
            "errors": [],
            "warnings": [],
        }

    def print_header(self):
        """–ö—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫"""
        terminal_width = shutil.get_terminal_size().columns
        print("\n" + Colors.CYAN + "=" * terminal_width + Colors.ENDC)
        print(
            Colors.BOLD
            + Colors.HEADER
            + "üöÄ UNIFIED TEST ORCHESTRATOR FOR BOT_AI_V3 üöÄ".center(terminal_width)
            + Colors.ENDC
        )
        print(Colors.CYAN + "=" * terminal_width + Colors.ENDC)
        print(f"{Colors.BLUE}üìÅ Project:{Colors.ENDC} {self.project_root}")
        print(f"{Colors.BLUE}üìä Results:{Colors.ENDC} {self.results_dir}")
        print(
            f"{Colors.BLUE}‚è∞ Started:{Colors.ENDC} {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )
        print(Colors.CYAN + "=" * terminal_width + Colors.ENDC)

    def print_menu(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –º–µ–Ω—é"""
        print(f"\n{Colors.BOLD}üìã Test Components:{Colors.ENDC}")
        print("-" * 60)

        for key, component in self.components.items():
            status_icon = "‚úÖ" if component["enabled"] else "‚≠ï"
            status_color = Colors.GREEN if component["enabled"] else Colors.WARNING
            print(
                f"{status_color}{status_icon}{Colors.ENDC} {component['icon']} "
                f"{component['name']:<25} [{key}]"
            )

        print("-" * 60)
        print(f"\n{Colors.BOLD}‚öôÔ∏è  Options:{Colors.ENDC}")
        print("  [1] Run all enabled tests")
        print("  [2] Toggle component on/off")
        print("  [3] Run specific component")
        print("  [4] Generate HTML report")
        print("  [5] Clean previous results")
        print("  [6] Quick test (unit only)")
        print("  [7] Full analysis (everything)")
        print("  [8] Visual dashboard")
        print("  [9] Code analysis suite")
        print("  [D] Dynamic SL/TP test suite üìä")
        if ENHANCED_DASHBOARD_AVAILABLE:
            print("  [E] Enhanced interactive dashboard ‚ú®")
        print("  [0] Exit")

    def toggle_component(self, component_key: str):
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç"""
        if component_key in self.components:
            self.components[component_key]["enabled"] = not self.components[component_key][
                "enabled"
            ]
            status = "enabled" if self.components[component_key]["enabled"] else "disabled"
            print(f"{Colors.GREEN}‚úì{Colors.ENDC} {self.components[component_key]['name']} {status}")
        else:
            print(f"{Colors.FAIL}‚úó{Colors.ENDC} Unknown component: {component_key}")

    async def run_component(self, key: str, component: dict) -> dict:
        """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞"""
        print(f"\n{Colors.CYAN}‚ñ∂{Colors.ENDC} Running {component['icon']} {component['name']}...")

        start_time = time.time()
        result = {
            "name": component["name"],
            "start_time": datetime.now().isoformat(),
            "status": "running",
            "output": "",
            "error": "",
            "execution_time": 0,
        }

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º python –∏–∑ venv –Ω–∞–ø—Ä—è–º—É—é
            venv_python = self.project_root / "venv/bin/python3"
            if venv_python.exists():
                # –ó–∞–º–µ–Ω—è–µ–º pytest –Ω–∞ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ pytest –∏–∑ venv
                command = component["command"].replace("pytest", f"{venv_python.parent}/pytest")
                command = command.replace("python3", str(venv_python))
                command = command.replace("ruff", f"{venv_python.parent}/ruff")
                command = command.replace("mypy", f"{venv_python.parent}/mypy")
            else:
                command = component["command"]

            full_command = f"cd {self.project_root} && {command}"

            process = await asyncio.create_subprocess_shell(
                full_command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            result["output"] = stdout.decode() if stdout else ""
            result["error"] = stderr.decode() if stderr else ""

            # –î–ª—è pytest –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –≤—ã–≤–æ–¥–∞
            if "pytest" in component["command"]:
                output_text = result["output"] + result["error"]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –≤ –≤—ã–≤–æ–¥–µ
                if "passed" in output_text and "failed" not in output_text:
                    result["status"] = "success"
                elif "passed" in output_text and "failed" in output_text:
                    # –ï—Å—Ç—å –∏ —É—Å–ø–µ—à–Ω—ã–µ –∏ –ø—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
                    result["status"] = "partial"
                elif "No tests ran" in output_text or "no tests ran" in output_text:
                    result["status"] = "failed"
                elif process.returncode == 0 or "warning" in output_text.lower():
                    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ warnings, —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–º
                    result["status"] = "success"
                else:
                    result["status"] = "failed"
            else:
                result["status"] = "success" if process.returncode == 0 else "failed"

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
            self.components[key]["status"] = result["status"]

            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ —ç—Ç–æ pytest
            if "pytest" in component["command"]:
                self._parse_pytest_output(result["output"])
                # –¢–∞–∫–∂–µ –ø–∞—Ä—Å–∏–º stderr, —Ç–∞–∫ –∫–∞–∫ pytest –º–æ–∂–µ—Ç –≤—ã–≤–æ–¥–∏—Ç—å —Ç—É–¥–∞
                if result["error"]:
                    self._parse_pytest_output(result["error"])

            status_icon = "‚úÖ" if result["status"] == "success" else "‚ùå"
            print(f"{status_icon} {component['name']}: {result['status'].upper()}")

        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
            self.components[key]["status"] = "error"
            print(f"‚ùå {component['name']}: ERROR - {e}")

        result["execution_time"] = time.time() - start_time
        result["end_time"] = datetime.now().isoformat()

        return result

    def _parse_pytest_output(self, output: str):
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–≤–æ–¥–∞ pytest"""
        import re

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º –Ω–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
        current_passed = 0
        current_failed = 0

        lines = output.split("\n")
        for line in lines:
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "37 passed, 2 warnings in 0.09s" –∏–ª–∏ "5 passed, 2 failed in 1.23s"
            # –¢–∞–∫–∂–µ –∏—â–µ–º "====== 37 passed in 0.09s ======"
            if "passed" in line or "failed" in line:
                # –ò—â–µ–º —á–∏—Å–ª–∞ –ø–µ—Ä–µ–¥ —Å–ª–æ–≤–∞–º–∏ passed –∏ failed
                passed_match = re.search(r"(\d+)\s+passed", line)
                failed_match = re.search(r"(\d+)\s+failed", line)

                if passed_match:
                    current_passed = max(current_passed, int(passed_match.group(1)))
                if failed_match:
                    current_failed = max(current_failed, int(failed_match.group(1)))

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        if current_passed > 0 or current_failed > 0:
            self.stats["passed_tests"] += current_passed
            self.stats["failed_tests"] += current_failed
            self.stats["total_tests"] = self.stats["passed_tests"] + self.stats["failed_tests"]

    async def run_dynamic_sltp_suite(self):
        """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ Dynamic SL/TP test suite"""
        print(f"\n{Colors.HEADER}üìä DYNAMIC SL/TP TEST SUITE{Colors.ENDC}")
        print(f"{Colors.CYAN}{'='*50}{Colors.ENDC}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Dynamic SL/TP
        dynamic_sltp_components = [
            "dynamic_sltp_unit_tests",
            "dynamic_sltp_integration_tests", 
            "dynamic_sltp_e2e_tests",
            "dynamic_sltp_performance_tests",
            "dynamic_sltp_comprehensive"
        ]
        
        # –û—Ç–∫–ª—é—á–∞–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        for key in self.components:
            if key in dynamic_sltp_components:
                self.components[key]["enabled"] = True
                print(f"{Colors.GREEN}‚úì{Colors.ENDC} Enabled: {self.components[key]['name']}")
            else:
                self.components[key]["enabled"] = False
        
        print(f"\n{Colors.BLUE}üéØ Running Dynamic SL/TP comprehensive test suite...{Colors.ENDC}")
        
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        print(f"\n{Colors.BOLD}Select test mode:{Colors.ENDC}")
        print("  [1] Quick tests (unit + integration)")
        print("  [2] Complete suite (unit + integration + e2e)")  
        print("  [3] Performance suite (all + performance)")
        print("  [4] Comprehensive all-in-one test")
        print("  [0] Cancel")
        
        try:
            mode_choice = input(f"\n{Colors.BOLD}Enter mode choice:{Colors.ENDC} ").strip()
            
            if mode_choice == "0":
                print(f"{Colors.WARNING}‚úó{Colors.ENDC} Cancelled")
                return
            elif mode_choice == "1":
                # Quick tests
                selected_components = ["dynamic_sltp_unit_tests", "dynamic_sltp_integration_tests"]
            elif mode_choice == "2":
                # Complete suite
                selected_components = ["dynamic_sltp_unit_tests", "dynamic_sltp_integration_tests", "dynamic_sltp_e2e_tests"]
            elif mode_choice == "3":
                # Performance suite
                selected_components = dynamic_sltp_components  # –≤—Å–µ –≤–∫–ª—é—á–∞—è performance
            elif mode_choice == "4":
                # Comprehensive all-in-one
                selected_components = ["dynamic_sltp_comprehensive"]
            else:
                print(f"{Colors.WARNING}‚ö†Ô∏è Invalid mode, running quick tests{Colors.ENDC}")
                selected_components = ["dynamic_sltp_unit_tests", "dynamic_sltp_integration_tests"]
                
            # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–µ—Å–µ–ª–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            for key in dynamic_sltp_components:
                self.components[key]["enabled"] = key in selected_components
                
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
            await self.run_all_enabled()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            print(f"\n{Colors.GREEN}‚ú® Generating Dynamic SL/TP test report...{Colors.ENDC}")
            self.generate_html_dashboard()
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\n{Colors.HEADER}üìä Dynamic SL/TP Test Results Summary:{Colors.ENDC}")
            print(f"  Total tests: {self.stats['total_tests']}")
            print(f"  Passed: {Colors.GREEN}{self.stats['passed_tests']}{Colors.ENDC}")
            print(f"  Failed: {Colors.FAIL}{self.stats['failed_tests']}{Colors.ENDC}")
            
            if self.stats['failed_tests'] == 0:
                print(f"\n{Colors.GREEN}üéâ All Dynamic SL/TP tests passed!{Colors.ENDC}")
            else:
                print(f"\n{Colors.WARNING}‚ö†Ô∏è Some tests failed, check the detailed report{Colors.ENDC}")
                
        except KeyboardInterrupt:
            print(f"\n{Colors.WARNING}‚úó{Colors.ENDC} Dynamic SL/TP test suite cancelled")
        except Exception as e:
            print(f"{Colors.FAIL}‚ùå Error in Dynamic SL/TP suite: {e}{Colors.ENDC}")

    def generate_enhanced_dashboard(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥"""
        if not ENHANCED_DASHBOARD_AVAILABLE:
            print(
                f"{Colors.WARNING}‚ö†Ô∏è Enhanced dashboard not available, using basic version{Colors.ENDC}"
            )
            self.generate_html_dashboard()
            return

        print(f"{Colors.CYAN}‚ú® Generating enhanced interactive dashboard...{Colors.ENDC}")

        try:
            generator = EnhancedDashboardGenerator()

            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            results = getattr(self, "last_results", {})

            html_content = generator.generate_interactive_dashboard(
                stats=self.stats, components=self.components, results=results
            )

            dashboard_file = self.results_dir / "enhanced_dashboard.html"
            with open(dashboard_file, "w", encoding="utf-8") as f:
                f.write(html_content)

            print(f"{Colors.GREEN}‚ú® Enhanced dashboard generated: {dashboard_file}{Colors.ENDC}")
            print(f"  üåê Open in browser: file://{dashboard_file}")

            # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å –≤ –±—Ä–∞—É–∑–µ—Ä–µ
            try:
                import webbrowser

                webbrowser.open(f"file://{dashboard_file}")
            except:
                pass

        except Exception as e:
            print(f"{Colors.FAIL}‚ùå Error generating enhanced dashboard: {e}{Colors.ENDC}")
            print(f"{Colors.WARNING}üìã Falling back to basic dashboard{Colors.ENDC}")
            self.generate_html_dashboard()

    async def run_all_enabled(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –≤–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        print(f"\n{Colors.BOLD}üöÄ Starting test execution...{Colors.ENDC}\n")

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
        self.stats = {
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "coverage_percent": 0.0,
            "execution_time": 0,
            "errors": [],
            "warnings": [],
        }

        results = {}
        start_time = time.time()

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
        for key, component in self.components.items():
            if component["enabled"]:
                results[key] = await self.run_component(key, component)
                await asyncio.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏

        self.stats["execution_time"] = time.time() - start_time

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–±—ä–µ–∫—Ç–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
        self.last_results = results

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_results(results)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–∏
        self._print_summary()

        return results

    def _save_results(self, results: dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # JSON –æ—Ç—á–µ—Ç
        report = {
            "timestamp": datetime.now().isoformat(),
            "project": str(self.project_root),
            "stats": self.stats,
            "components": results,
            "coverage": self._get_coverage_data(),
        }

        json_file = self.results_dir / f"test_report_{timestamp}.json"
        with open(json_file, "w") as f:
            json.dump(report, f, indent=2)

        print(f"\n{Colors.GREEN}‚úì{Colors.ENDC} Report saved: {json_file}")

    def _get_coverage_data(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–∫—Ä—ã—Ç–∏—è"""
        coverage_file = self.project_root / "coverage.json"
        if coverage_file.exists():
            try:
                with open(coverage_file) as f:
                    data = json.load(f)
                    if "totals" in data:
                        self.stats["coverage_percent"] = data["totals"].get("percent_covered", 0)
                        return data["totals"]
            except Exception as e:
                print(f"Warning: Could not parse coverage data: {e}")

        # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –ø–æ–∫—Ä—ã—Ç–∏–µ –≤ –≤—ã–≤–æ–¥–µ pytest
        for key, component in self.components.items():
            if key == "coverage_report" and component.get("status") == "success":
                # –ò—â–µ–º coverage –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
                results = getattr(self, "last_results", {})
                if key in results:
                    output = results[key].get("output", "")
                    if "%" in output:
                        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "TOTAL ... 45%"
                        import re

                        match = re.search(r"TOTAL.*?(\d+)%", output)
                        if match:
                            coverage = float(match.group(1))
                            self.stats["coverage_percent"] = coverage
                            return {"percent_covered": coverage}

        return {}

    def _print_summary(self):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤"""
        terminal_width = shutil.get_terminal_size().columns

        print("\n" + Colors.CYAN + "=" * terminal_width + Colors.ENDC)
        print(Colors.BOLD + "üìä TEST EXECUTION SUMMARY".center(terminal_width) + Colors.ENDC)
        print(Colors.CYAN + "=" * terminal_width + Colors.ENDC)

        # –°—Ç–∞—Ç—É—Å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        print(f"\n{Colors.BOLD}Component Status:{Colors.ENDC}")
        for key, component in self.components.items():
            if component["enabled"]:
                status = component["status"]
                if status == "success":
                    icon = f"{Colors.GREEN}‚úÖ{Colors.ENDC}"
                elif status == "failed":
                    icon = f"{Colors.FAIL}‚ùå{Colors.ENDC}"
                elif status == "error":
                    icon = f"{Colors.WARNING}‚ö†Ô∏è{Colors.ENDC}"
                else:
                    icon = "‚≠ï"

                print(f"  {icon} {component['name']:<30} {status}")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\n{Colors.BOLD}Overall Statistics:{Colors.ENDC}")
        print(f"  üìã Total Tests: {self.stats['total_tests']}")
        print(f"  ‚úÖ Passed: {Colors.GREEN}{self.stats['passed_tests']}{Colors.ENDC}")
        print(f"  ‚ùå Failed: {Colors.FAIL}{self.stats['failed_tests']}{Colors.ENDC}")
        print(f"  üìä Coverage: {Colors.CYAN}{self.stats['coverage_percent']:.1f}%{Colors.ENDC}")
        print(f"  ‚è±Ô∏è  Execution Time: {self.stats['execution_time']:.2f}s")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if self.stats["coverage_percent"] < 80:
            print(f"\n{Colors.WARNING}‚ö†Ô∏è  Recommendations:{Colors.ENDC}")
            print("  ‚Ä¢ Coverage is below 80%. Run test generator to create more tests")
            print("  ‚Ä¢ Focus on critical components: trading/, ml/, exchanges/")
            print("  ‚Ä¢ Use 'python3 scripts/mass_test_generator.py' for automatic test generation")

        print("\n" + Colors.CYAN + "=" * terminal_width + Colors.ENDC)

    def generate_html_dashboard(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –¥–∞—à–±–æ—Ä–¥–∞"""
        print(f"\n{Colors.CYAN}üìä Generating HTML dashboard...{Colors.ENDC}")

        html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BOT_AI_V3 Test Dashboard</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
        }}
        .header {{
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            text-align: center;
        }}
        h1 {{
            color: #333;
            font-size: 2.5em;
            margin-bottom: 10px;
        }}
        .subtitle {{
            color: #666;
            font-size: 1.2em;
        }}
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        .stat-card {{
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            transition: transform 0.3s;
        }}
        .stat-card:hover {{
            transform: translateY(-5px);
        }}
        .stat-icon {{
            font-size: 2em;
            margin-bottom: 10px;
        }}
        .stat-value {{
            font-size: 2.5em;
            font-weight: bold;
            color: #667eea;
            margin-bottom: 5px;
        }}
        .stat-label {{
            color: #999;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
        }}
        .components {{
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }}
        .component-item {{
            display: flex;
            align-items: center;
            padding: 15px;
            border-bottom: 1px solid #f0f0f0;
            transition: background 0.3s;
        }}
        .component-item:hover {{
            background: #f9f9f9;
        }}
        .component-icon {{
            font-size: 1.5em;
            margin-right: 15px;
        }}
        .component-name {{
            flex: 1;
            font-weight: 500;
            color: #333;
        }}
        .component-status {{
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 500;
        }}
        .status-success {{
            background: #d4edda;
            color: #155724;
        }}
        .status-failed {{
            background: #f8d7da;
            color: #721c24;
        }}
        .status-pending {{
            background: #fff3cd;
            color: #856404;
        }}
        .coverage-bar {{
            width: 100%;
            height: 30px;
            background: #f0f0f0;
            border-radius: 15px;
            overflow: hidden;
            margin-top: 20px;
        }}
        .coverage-fill {{
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            transition: width 1s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
        }}
        .timestamp {{
            text-align: center;
            color: #999;
            margin-top: 30px;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ BOT_AI_V3 Test Dashboard</h1>
            <div class="subtitle">Comprehensive Testing & Code Analysis</div>
        </div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-icon">üìã</div>
                <div class="stat-value">{self.stats['total_tests']}</div>
                <div class="stat-label">Total Tests</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-icon">‚úÖ</div>
                <div class="stat-value">{self.stats['passed_tests']}</div>
                <div class="stat-label">Passed Tests</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-icon">‚ùå</div>
                <div class="stat-value">{self.stats['failed_tests']}</div>
                <div class="stat-label">Failed Tests</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-icon">üìä</div>
                <div class="stat-value">{self.stats['coverage_percent']:.1f}%</div>
                <div class="stat-label">Code Coverage</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-icon">‚è±Ô∏è</div>
                <div class="stat-value">{self.stats['execution_time']:.1f}s</div>
                <div class="stat-label">Execution Time</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-icon">üéØ</div>
                <div class="stat-value">{len([c for c in self.components.values() if c['status'] == 'success'])}/{len(self.components)}</div>
                <div class="stat-label">Components Passed</div>
            </div>
        </div>
        
        <div class="components">
            <h2 style="margin-bottom: 20px; color: #333;">Test Components Status</h2>
            {"".join([f'''
            <div class="component-item">
                <div class="component-icon">{component['icon']}</div>
                <div class="component-name">{component['name']}</div>
                <div class="component-status status-{component['status']}">{component['status'].upper()}</div>
            </div>
            ''' for component in self.components.values()])}
            
            <div class="coverage-bar">
                <div class="coverage-fill" style="width: {self.stats['coverage_percent']}%">
                    {self.stats['coverage_percent']:.1f}% Coverage
                </div>
            </div>
        </div>
        
        <div class="timestamp">
            Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
</body>
</html>
        """

        dashboard_file = self.results_dir / "dashboard.html"
        with open(dashboard_file, "w") as f:
            f.write(html_content)

        print(f"{Colors.GREEN}‚úì{Colors.ENDC} Dashboard generated: {dashboard_file}")
        print(f"  Open in browser: file://{dashboard_file}")

        # –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å –≤ –±—Ä–∞—É–∑–µ—Ä–µ
        try:
            import webbrowser

            webbrowser.open(f"file://{dashboard_file}")
        except:
            pass

    def clean_results(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print(f"\n{Colors.WARNING}üßπ Cleaning previous results...{Colors.ENDC}")

        for file in self.results_dir.glob("*"):
            if file.is_file():
                file.unlink()
                print(f"  Deleted: {file.name}")

        # –û—á–∏—Å—Ç–∫–∞ coverage —Ñ–∞–π–ª–æ–≤
        coverage_files = [".coverage", "coverage.json", "htmlcov"]
        for cf in coverage_files:
            path = self.project_root / cf
            if path.exists():
                if path.is_dir():
                    import shutil

                    shutil.rmtree(path)
                else:
                    path.unlink()
                print(f"  Deleted: {cf}")

        print(f"{Colors.GREEN}‚úì{Colors.ENDC} Cleanup complete")

    async def run_interactive(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º"""
        self.print_header()

        while True:
            self.print_menu()

            try:
                choice = input(f"\n{Colors.BOLD}Enter choice:{Colors.ENDC} ").strip()

                if choice == "0":
                    print(f"\n{Colors.CYAN}üëã Goodbye!{Colors.ENDC}")
                    break

                elif choice == "1":
                    await self.run_all_enabled()
                    self.generate_html_dashboard()

                elif choice == "2":
                    component_key = input("Enter component key to toggle: ").strip()
                    self.toggle_component(component_key)

                elif choice == "3":
                    component_key = input("Enter component key to run: ").strip()
                    if component_key in self.components:
                        result = await self.run_component(
                            component_key, self.components[component_key]
                        )
                        self._save_results({component_key: result})
                    else:
                        print(f"{Colors.FAIL}‚úó{Colors.ENDC} Unknown component")

                elif choice == "4":
                    self.generate_html_dashboard()

                elif choice == "5":
                    self.clean_results()

                elif choice == "6":
                    # Quick test - —Ç–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã
                    for key in self.components:
                        self.components[key]["enabled"] = key == "unit_tests"
                    await self.run_all_enabled()
                    self.generate_html_dashboard()

                elif choice == "7":
                    # Full analysis - –≤—Å–µ –≤–∫–ª—é—á–µ–Ω–æ
                    for key in self.components:
                        self.components[key]["enabled"] = True
                    await self.run_all_enabled()
                    self.generate_html_dashboard()

                elif choice == "8":
                    self.generate_html_dashboard()

                elif choice == "9":
                    # Code analysis suite - –≤–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
                    for key in self.components:
                        self.components[key]["enabled"] = key in [
                            "code_usage_analyzer_tests",
                            "code_analyzer_validation_tests",
                            "code_analysis_report",
                        ]
                    await self.run_all_enabled()
                    self.generate_html_dashboard()

                elif choice.upper() == "D":
                    # Dynamic SL/TP test suite
                    await self.run_dynamic_sltp_suite()

                elif choice.upper() == "E" and ENHANCED_DASHBOARD_AVAILABLE:
                    # Enhanced interactive dashboard
                    self.generate_enhanced_dashboard()

                else:
                    print(f"{Colors.WARNING}‚ö†Ô∏è  Invalid choice{Colors.ENDC}")

            except KeyboardInterrupt:
                print(f"\n\n{Colors.CYAN}üëã Interrupted by user{Colors.ENDC}")
                break
            except Exception as e:
                print(f"{Colors.FAIL}‚ùå Error: {e}{Colors.ENDC}")

    async def run_cli(self, mode: str = "full"):
        """CLI —Ä–µ–∂–∏–º –¥–ª—è —Å–∫—Ä–∏–ø—Ç–æ–≤"""
        self.print_header()

        if mode == "full" or mode == "full-analysis":
            # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            for key in self.components:
                self.components[key]["enabled"] = True
        elif mode == "quick":
            # –¢–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã
            for key in self.components:
                self.components[key]["enabled"] = key == "unit_tests"
        elif mode == "visual":
            # –¢–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
            for key in self.components:
                self.components[key]["enabled"] = key in ["visual_tests", "api_tests"]
        elif mode == "ml":
            # ML —Ç–µ—Å—Ç—ã
            for key in self.components:
                self.components[key]["enabled"] = key in ["ml_tests", "unit_tests"]
        elif mode == "code-analysis":
            # –¢–µ—Å—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
            for key in self.components:
                self.components[key]["enabled"] = key in [
                    "code_usage_analyzer_tests",
                    "code_analyzer_validation_tests",
                    "code_analysis_report",
                ]

        results = await self.run_all_enabled()
        self.generate_html_dashboard()

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        failed = sum(1 for c in self.components.values() if c["status"] == "failed")
        return 0 if failed == 0 else 1


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="üöÄ Unified Test Orchestrator for BOT_AI_V3")
    parser.add_argument(
        "--mode",
        choices=["interactive", "full", "full-analysis", "quick", "visual", "ml", "code-analysis"],
        default="interactive",
        help="Execution mode",
    )
    parser.add_argument(
        "--clean", action="store_true", help="Clean previous results before running"
    )

    args = parser.parse_args()

    orchestrator = UnifiedTestOrchestrator()

    if args.clean:
        orchestrator.clean_results()

    if args.mode == "interactive":
        await orchestrator.run_interactive()
    else:
        exit_code = await orchestrator.run_cli(args.mode)
        sys.exit(exit_code)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{Colors.CYAN}üëã Goodbye!{Colors.ENDC}")
        sys.exit(0)
