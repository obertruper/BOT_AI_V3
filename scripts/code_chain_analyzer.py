#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞ –¥–ª—è BOT_AI_V3
–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∫–æ–¥
"""
import ast
import json
import sys
from collections import defaultdict
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any

import networkx as nx

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


@dataclass
class FunctionNode:
    """–£–∑–µ–ª —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –≥—Ä–∞—Ñ–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""

    name: str
    file_path: str
    line_number: int
    is_async: bool
    is_entry_point: bool
    calls: list[str]  # –§—É–Ω–∫—Ü–∏–∏ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–∑—ã–≤–∞–µ—Ç
    called_by: list[str]  # –§—É–Ω–∫—Ü–∏–∏ –∫–æ—Ç–æ—Ä—ã–µ –µ—ë –≤—ã–∑—ã–≤–∞—é—Ç
    complexity: int
    is_tested: bool
    is_reachable: bool = False
    execution_count: int = 0


@dataclass
class CodeChainAnalysis:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞"""

    total_functions: int
    reachable_functions: int
    unreachable_functions: list[str]
    entry_points: list[str]
    critical_paths: list[list[str]]
    unused_code_candidates: list[str]
    dependency_graph: dict[str, list[str]]
    coverage_gaps: dict[str, float]


class CallGraphBuilder:
    """–°—Ç—Ä–æ–∏—Ç–µ–ª—å –≥—Ä–∞—Ñ–∞ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.functions: dict[str, FunctionNode] = {}
        self.imports: dict[str, set[str]] = defaultdict(set)
        self.entry_points = [
            "unified_launcher.py:main",
            "main.py:main",
            "unified_launcher.py:UnifiedLauncher.start",
            "core/system/orchestrator.py:SystemOrchestrator.start_all",
            "trading/engine.py:TradingEngine.process_signal",
            "ml/ml_manager.py:MLManager.get_prediction",
            "api/main.py:create_app",
        ]

    def analyze_file(self, file_path: Path) -> list[FunctionNode]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ —Å –∏—Ö –≤—ã–∑–æ–≤–∞–º–∏"""
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()

            tree = ast.parse(content)
            functions = []

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–ø–æ—Ä—Ç—ã
            imports = self._extract_imports(tree)
            rel_path = str(file_path.relative_to(self.project_root))
            self.imports[rel_path] = imports

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    func_node = self._extract_function_node(node, file_path)
                    if func_node:
                        functions.append(func_node)
                        func_key = f"{rel_path}:{func_node.name}"
                        self.functions[func_key] = func_node

            return functions

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {file_path}: {e}")
            return []

    def _extract_imports(self, tree: ast.AST) -> set[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞"""
        imports = set()

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.add(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    for alias in node.names:
                        imports.add(f"{node.module}.{alias.name}")

        return imports

    def _extract_function_node(self, node: ast.FunctionDef, file_path: Path) -> FunctionNode | None:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ—É–Ω–∫—Ü–∏–∏"""
        if node.name.startswith("_") and not node.name.startswith("__"):
            return None  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

        rel_path = str(file_path.relative_to(self.project_root))

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π
        calls = self._extract_function_calls(node)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —è–≤–ª—è–µ—Ç—Å—è –ª–∏ entry point
        func_key = f"{rel_path}:{node.name}"
        is_entry = any(ep in func_key for ep in self.entry_points)

        # –í—ã—á–∏—Å–ª—è–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        complexity = self._calculate_complexity(node)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ç–µ—Å—Ç—ã
        is_tested = self._check_has_tests(node.name, file_path)

        return FunctionNode(
            name=node.name,
            file_path=rel_path,
            line_number=node.lineno,
            is_async=isinstance(node, ast.AsyncFunctionDef),
            is_entry_point=is_entry,
            calls=calls,
            called_by=[],
            complexity=complexity,
            is_tested=is_tested,
        )

    def _extract_function_calls(self, node: ast.FunctionDef) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ —Ç–µ–ª–∞ —Ñ—É–Ω–∫—Ü–∏–∏"""
        calls = []

        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                call_name = self._get_call_name(child)
                if call_name:
                    calls.append(call_name)

        return calls

    def _get_call_name(self, call_node: ast.Call) -> str | None:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è –≤—ã–∑—ã–≤–∞–µ–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏"""
        if isinstance(call_node.func, ast.Name):
            return call_node.func.id
        elif isinstance(call_node.func, ast.Attribute):
            # –î–ª—è –º–µ—Ç–æ–¥–æ–≤ —Ç–∏–ø–∞ obj.method()
            if isinstance(call_node.func.value, ast.Name):
                return f"{call_node.func.value.id}.{call_node.func.attr}"
            else:
                return call_node.func.attr
        return None

    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å"""
        complexity = 1

        for child in ast.walk(node):
            if (
                isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor))
                or isinstance(child, ast.ExceptHandler)
                or isinstance(child, (ast.And, ast.Or))
            ):
                complexity += 1

        return complexity

    def _check_has_tests(self, func_name: str, file_path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ —Ç–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏"""
        rel_path = file_path.relative_to(self.project_root)
        test_file = self.project_root / "tests" / f"test_{rel_path.name}"

        if not test_file.exists():
            return False

        try:
            with open(test_file) as f:
                content = f.read()
                return f"test_{func_name}" in content
        except:
            return False

    def build_call_graph(self) -> nx.DiGraph:
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π"""
        # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ Python —Ñ–∞–π–ª—ã
        python_files = list(self.project_root.rglob("*.py"))
        source_files = [
            f
            for f in python_files
            if not any(part.startswith((".", "__pycache__", "test_")) for part in f.parts)
        ]

        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(source_files)} —Ñ–∞–π–ª–æ–≤...")

        for file_path in source_files:
            self.analyze_file(file_path)

        # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        graph = nx.DiGraph()

        # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã
        for func_key, func_node in self.functions.items():
            graph.add_node(func_key, **asdict(func_node))

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä—ë–±—Ä–∞ (–≤—ã–∑–æ–≤—ã)
        for func_key, func_node in self.functions.items():
            for call in func_node.calls:
                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
                target_func = self._resolve_call_target(call, func_node.file_path)
                if target_func and target_func in self.functions:
                    graph.add_edge(func_key, target_func)
                    # –û–±–Ω–æ–≤–ª—è–µ–º called_by
                    self.functions[target_func].called_by.append(func_key)

        return graph

    def _resolve_call_target(self, call: str, from_file: str) -> str | None:
        """–†–∞–∑—Ä–µ—à–∞–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π target"""
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ - –∏—â–µ–º –≤ —Ç–æ–º –∂–µ —Ñ–∞–π–ª–µ
        same_file_target = f"{from_file}:{call}"
        if same_file_target in self.functions:
            return same_file_target

        # –ò—â–µ–º –≤ –∏–º–ø–æ—Ä—Ç–∞—Ö
        imports = self.imports.get(from_file, set())
        for imp in imports:
            if call in imp:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –∏–º–ø–æ—Ä—Ç–∞
                possible_target = self._find_import_target(imp, call)
                if possible_target:
                    return possible_target

        # –ò—â–µ–º –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∏–º–µ–Ω–∏
        for func_key in self.functions.keys():
            if func_key.endswith(f":{call}"):
                return func_key

        return None

    def _find_import_target(self, import_path: str, call: str) -> str | None:
        """–ù–∞—Ö–æ–¥–∏—Ç target —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –∏–º–ø–æ—Ä—Ç–µ"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
        parts = import_path.split(".")
        if len(parts) >= 2:
            file_part = "/".join(parts[:-1]) + ".py"
            func_part = parts[-1]
            target = f"{file_part}:{func_part}"
            if target in self.functions:
                return target

        return None


class DeadCodeDetector:
    """–î–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞"""

    def __init__(self, call_graph: nx.DiGraph, functions: dict[str, FunctionNode]):
        self.call_graph = call_graph
        self.functions = functions

    def find_reachable_functions(self, entry_points: list[str]) -> set[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –¥–æ—Å—Ç–∏–∂–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç entry points"""
        reachable = set()

        # –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∞–ª—å–Ω—ã–µ entry points –≤ –≥—Ä–∞—Ñ–µ
        actual_entry_points = []
        for node in self.call_graph.nodes():
            node_data = self.call_graph.nodes[node]
            if node_data.get("is_entry_point", False):
                actual_entry_points.append(node)

        if not actual_entry_points:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã entry points, –∏—â–µ–º –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
            for node in self.call_graph.nodes():
                if any(ep in node for ep in entry_points):
                    actual_entry_points.append(node)

        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(actual_entry_points)} entry points")

        # –û–±—Ö–æ–¥ –≤ –≥–ª—É–±–∏–Ω—É –æ—Ç –∫–∞–∂–¥–æ–π entry point
        for entry in actual_entry_points:
            if entry in self.call_graph:
                reachable.update(nx.descendants(self.call_graph, entry))
                reachable.add(entry)  # –î–æ–±–∞–≤–ª—è–µ–º —Å–∞–º—É entry point

        return reachable

    def find_unreachable_functions(self, entry_points: list[str]) -> list[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–¥–æ—Å—Ç–∏–∂–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
        reachable = self.find_reachable_functions(entry_points)
        all_functions = set(self.call_graph.nodes())
        unreachable = all_functions - reachable

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ reachable
        for func_key in self.functions:
            self.functions[func_key].is_reachable = func_key in reachable

        return list(unreachable)

    def find_dead_code_candidates(self) -> list[dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ"""
        candidates = []

        for func_key, func_node in self.functions.items():
            if not func_node.is_reachable and not func_node.is_entry_point:
                risk_level = self._assess_removal_risk(func_node)
                candidates.append(
                    {
                        "function": func_key,
                        "file": func_node.file_path,
                        "line": func_node.line_number,
                        "risk_level": risk_level,
                        "reason": self._get_removal_reason(func_node, risk_level),
                        "safe_to_remove": risk_level == "LOW",
                    }
                )

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞
        risk_order = {"LOW": 0, "MEDIUM": 1, "HIGH": 2}
        candidates.sort(key=lambda x: risk_order[x["risk_level"]])

        return candidates

    def _assess_removal_risk(self, func_node: FunctionNode) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–∏—Å–∫ —É–¥–∞–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏"""
        # –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫
        if func_node.name.startswith("__"):  # Magic methods
            return "HIGH"
        if "api" in func_node.file_path.lower():  # API endpoints
            return "HIGH"
        if "test" in func_node.name.lower():  # Test functions
            return "HIGH"

        # –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫
        if func_node.complexity > 5:  # –°–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            return "MEDIUM"
        if func_node.is_async:  # Async —Ñ—É–Ω–∫—Ü–∏–∏
            return "MEDIUM"
        if len(func_node.calls) > 10:  # –ú–Ω–æ–≥–æ –≤—ã–∑–æ–≤–æ–≤
            return "MEDIUM"

        # –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫
        return "LOW"

    def _get_removal_reason(self, func_node: FunctionNode, risk_level: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏—á–∏–Ω—É –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è"""
        reasons = []

        if not func_node.is_reachable:
            reasons.append("–Ω–µ–¥–æ—Å—Ç–∏–∂–∏–º–∞ –æ—Ç entry points")
        if not func_node.is_tested:
            reasons.append("–Ω–µ –ø–æ–∫—Ä—ã—Ç–∞ —Ç–µ—Å—Ç–∞–º–∏")
        if func_node.execution_count == 0:
            reasons.append("–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å")

        return "; ".join(reasons) if reasons else "–Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è"


class CodeChainAnalyzer:
    """–ì–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.call_graph_builder = CallGraphBuilder(project_root)
        self.call_graph = None
        self.dead_code_detector = None

    def full_analysis(self) -> CodeChainAnalysis:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞"""
        print("üîç –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞...")

        # 1. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –≤—ã–∑–æ–≤–æ–≤
        print("üìä –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π...")
        self.call_graph = self.call_graph_builder.build_call_graph()

        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä –º—ë—Ä—Ç–≤–æ–≥–æ –∫–æ–¥–∞
        self.dead_code_detector = DeadCodeDetector(
            self.call_graph, self.call_graph_builder.functions
        )

        # 3. –ù–∞—Ö–æ–¥–∏–º –Ω–µ–¥–æ—Å—Ç–∏–∂–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        print("üîç –ò—â–µ–º –Ω–µ–¥–æ—Å—Ç–∏–∂–∏–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏...")
        entry_points = [
            "unified_launcher.py:main",
            "main.py:main",
            "unified_launcher.py:UnifiedLauncher.start",
        ]
        unreachable = self.dead_code_detector.find_unreachable_functions(entry_points)

        # 4. –ù–∞—Ö–æ–¥–∏–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
        print("üóëÔ∏è –ò—â–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ...")
        dead_code_candidates = self.dead_code_detector.find_dead_code_candidates()

        # 5. –ù–∞—Ö–æ–¥–∏–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏
        print("üéØ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏...")
        critical_paths = self._find_critical_paths()

        # 6. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ
        print("üìà –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏...")
        coverage_gaps = self._analyze_coverage_gaps()

        # 7. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        dependency_graph = self._build_dependency_graph()

        total_functions = len(self.call_graph_builder.functions)
        reachable_count = total_functions - len(unreachable)

        return CodeChainAnalysis(
            total_functions=total_functions,
            reachable_functions=reachable_count,
            unreachable_functions=unreachable,
            entry_points=entry_points,
            critical_paths=critical_paths,
            unused_code_candidates=[c["function"] for c in dead_code_candidates],
            dependency_graph=dependency_graph,
            coverage_gaps=coverage_gaps,
        )

    def _find_critical_paths(self) -> list[list[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        critical_paths = []

        # –û—Å–Ω–æ–≤–Ω—ã–µ workflow
        workflows = [
            # –¢–æ—Ä–≥–æ–≤—ã–π workflow
            ["unified_launcher.py", "trading/engine.py", "trading/order_manager.py", "exchanges/"],
            # ML workflow
            ["ml/ml_manager.py", "ml/logic/patchtst_model.py", "trading/signal_processor.py"],
            # API workflow
            ["api/main.py", "api/endpoints/", "database/connections/"],
            # WebSocket workflow
            ["web/websocket/", "trading/engine.py", "api/real_time/"],
        ]

        for workflow in workflows:
            path = self._trace_execution_path(workflow)
            if path:
                critical_paths.append(path)

        return critical_paths

    def _trace_execution_path(self, workflow_pattern: list[str]) -> list[str]:
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø—É—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è workflow"""
        path = []

        for pattern in workflow_pattern:
            # –ù–∞—Ö–æ–¥–∏–º —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—É
            matching_functions = [
                func_key
                for func_key in self.call_graph_builder.functions.keys()
                if pattern in func_key
            ]

            if matching_functions:
                # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏–∫—É –≤—ã–±–æ—Ä–∞)
                path.append(matching_functions[0])

        return path

    def _analyze_coverage_gaps(self) -> dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–µ–ª—ã –≤ –ø–æ–∫—Ä—ã—Ç–∏–∏"""
        coverage_by_module = defaultdict(lambda: {"total": 0, "tested": 0})

        for func_key, func_node in self.call_graph_builder.functions.items():
            module = func_node.file_path.split("/")[0]
            coverage_by_module[module]["total"] += 1
            if func_node.is_tested:
                coverage_by_module[module]["tested"] += 1

        coverage_gaps = {}
        for module, stats in coverage_by_module.items():
            if stats["total"] > 0:
                coverage_gaps[module] = (stats["tested"] / stats["total"]) * 100
            else:
                coverage_gaps[module] = 0.0

        return coverage_gaps

    def _build_dependency_graph(self) -> dict[str, list[str]]:
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        dependency_graph = {}

        for func_key, func_node in self.call_graph_builder.functions.items():
            dependency_graph[func_key] = func_node.calls

        return dependency_graph

    def save_analysis(self, analysis: CodeChainAnalysis, output_file: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        analysis_data = {
            "total_functions": analysis.total_functions,
            "reachable_functions": analysis.reachable_functions,
            "unreachable_functions": analysis.unreachable_functions,
            "entry_points": analysis.entry_points,
            "critical_paths": analysis.critical_paths,
            "unused_code_candidates": analysis.unused_code_candidates,
            "dependency_graph": analysis.dependency_graph,
            "coverage_gaps": analysis.coverage_gaps,
        }

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)

        print(f"üíæ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}")

    def save_graph(self, output_file: Path):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞—Ñ –≤ —Ñ–æ—Ä–º–∞—Ç–µ GraphML –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        if self.call_graph:
            nx.write_graphml(self.call_graph, output_file)
            print(f"üìä –ì—Ä–∞—Ñ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    project_root = Path(__file__).parent.parent
    analyzer = CodeChainAnalyzer(project_root)

    print("üöÄ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ü–µ–ø–æ—á–∫–∏ –∫–æ–¥–∞ BOT_AI_V3")
    print("=" * 50)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    analysis = analyzer.full_analysis()

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
    print(f"  –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π: {analysis.total_functions}")
    print(f"  –î–æ—Å—Ç–∏–∂–∏–º—ã—Ö: {analysis.reachable_functions}")
    print(f"  –ù–µ–¥–æ—Å—Ç–∏–∂–∏–º—ã—Ö: {len(analysis.unreachable_functions)}")
    print(f"  –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ: {len(analysis.unused_code_candidates)}")

    print("\nüìà –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ –º–æ–¥—É–ª—è–º:")
    for module, coverage in analysis.coverage_gaps.items():
        print(f"  {module}: {coverage:.1f}%")

    print(f"\nüéØ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏ ({len(analysis.critical_paths)}):")
    for i, path in enumerate(analysis.critical_paths, 1):
        print(f"  {i}. {' ‚Üí '.join([p.split(':')[0] for p in path[:3]])}...")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_dir = project_root / "analysis_results"
    output_dir.mkdir(exist_ok=True)

    analyzer.save_analysis(analysis, output_dir / "code_chain_analysis.json")
    analyzer.save_graph(output_dir / "call_graph.graphml")

    print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ {output_dir}/")
    print("üìÑ JSON –æ—Ç—á—ë—Ç: code_chain_analysis.json")
    print("üìä –ì—Ä–∞—Ñ: call_graph.graphml (–º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –≤ Gephi/Cytoscape)")


if __name__ == "__main__":
    main()
