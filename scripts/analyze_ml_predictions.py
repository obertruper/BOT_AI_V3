#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–Ω–∞–ª–∏–∑ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –ø—Ä–∏—á–∏–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
"""

import asyncio
import sys
from collections import defaultdict
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import and_, select

from core.config.config_manager import ConfigManager
from core.logger import setup_logger
from database.connections import get_async_db, init_async_db
from database.models.signal import Signal
from ml.ml_manager import MLManager
from ml.ml_signal_processor import MLSignalProcessor

logger = setup_logger("ml_analyzer")


class MLPredictionAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""

    def __init__(self):
        self.predictions = []
        self.filtered_predictions = []
        self.signals_generated = []

    async def analyze_predictions(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞"""
        logger.info("üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        await init_async_db()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_manager = ConfigManager()
        await config_manager.initialize()
        config = config_manager._config

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML Manager —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º –ª–æ–≥–æ–≤
        ml_manager = MLManager(config)
        await ml_manager.initialize()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Signal Processor
        signal_processor = MLSignalProcessor(ml_manager, config, config_manager)
        await signal_processor.initialize()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        original_confidence = signal_processor.min_confidence
        original_strength = signal_processor.min_signal_strength

        logger.info("üìä –¢–µ–∫—É—â–∏–µ –ø–æ—Ä–æ–≥–∏:")
        logger.info(f"   Min confidence: {original_confidence}")
        logger.info(f"   Min strength: {original_strength}")

        # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
        test_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT"]

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        signal_processor.min_confidence = 0.0
        signal_processor.min_signal_strength = 0.0

        all_predictions = []

        for symbol in test_symbols:
            logger.info(f"\nüéØ –ê–Ω–∞–ª–∏–∑ {symbol}...")

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é
            signal = await signal_processor.process_realtime_signal(
                symbol=symbol, exchange="bybit"
            )

            # –î–∞–∂–µ –µ—Å–ª–∏ —Å–∏–≥–Ω–∞–ª –Ω–µ –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä—ã, –ø–æ–ª—É—á–∞–µ–º raw –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            # —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ ML Manager
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∏–º–≤–æ–ª–∞
                from database.models.market_data import RawMarketData

                async with get_async_db() as session:
                    stmt = (
                        select(RawMarketData)
                        .where(
                            and_(
                                RawMarketData.symbol == symbol,
                                RawMarketData.exchange == "bybit",
                                RawMarketData.interval_minutes == 15,
                            )
                        )
                        .order_by(RawMarketData.timestamp.desc())
                        .limit(500)
                    )

                    result = await session.execute(stmt)
                    data = result.scalars().all()

                    if len(data) >= 96:
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
                        df = pd.DataFrame(
                            [
                                {
                                    "timestamp": d.timestamp,
                                    "open": float(d.open),
                                    "high": float(d.high),
                                    "low": float(d.low),
                                    "close": float(d.close),
                                    "volume": float(d.volume),
                                    "symbol": symbol,
                                }
                                for d in data[:96]
                            ]
                        )

                        df = df.sort_values("timestamp")

                        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                        prediction = await ml_manager.predict(df)

                        all_predictions.append(
                            {
                                "symbol": symbol,
                                "signal_type": prediction["signal_type"],
                                "confidence": prediction["confidence"],
                                "strength": prediction["signal_strength"],
                                "success_probability": prediction[
                                    "success_probability"
                                ],
                                "risk_level": prediction["risk_level"],
                                "predictions": prediction["predictions"],
                                "passed_filters": signal is not None,
                            }
                        )

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {symbol}: {e}")

        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._analyze_results(all_predictions, original_confidence, original_strength)

        # –ê–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –ë–î
        await self._analyze_database_signals()

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self._generate_recommendations(all_predictions)

    def _analyze_results(self, predictions, min_conf, min_strength):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""

        logger.info("\nüìä –ê–ù–ê–õ–ò–ó –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô:")
        logger.info("=" * 60)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = len(predictions)
        buy_signals = sum(1 for p in predictions if p["signal_type"] == "BUY")
        sell_signals = sum(1 for p in predictions if p["signal_type"] == "SELL")
        neutral_signals = sum(1 for p in predictions if p["signal_type"] == "NEUTRAL")

        logger.info(f"\nüìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ (–≤—Å–µ–≥–æ {total}):")
        logger.info(f"   BUY:     {buy_signals} ({buy_signals / total * 100:.1f}%)")
        logger.info(f"   SELL:    {sell_signals} ({sell_signals / total * 100:.1f}%)")
        logger.info(
            f"   NEUTRAL: {neutral_signals} ({neutral_signals / total * 100:.1f}%)"
        )

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        logger.info("\nüìä –î–µ—Ç–∞–ª–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º:")
        for pred in predictions:
            logger.info(f"\n{pred['symbol']}:")
            logger.info(f"   –¢–∏–ø: {pred['signal_type']}")
            logger.info(
                f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {pred['confidence']:.3f} {'‚úÖ' if pred['confidence'] >= min_conf else '‚ùå'}"
            )
            logger.info(
                f"   –°–∏–ª–∞: {pred['strength']:.3f} {'‚úÖ' if pred['strength'] >= min_strength else '‚ùå'}"
            )
            logger.info(f"   –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {pred['success_probability']:.1%}")
            logger.info(f"   –†–∏—Å–∫: {pred['risk_level']}")
            logger.info(f"   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {pred['predictions']['raw_directions']}")
            logger.info(
                f"   –ü—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä—ã: {'‚úÖ' if pred['passed_filters'] else '‚ùå'}"
            )

        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        logger.info("\nüö´ –ü—Ä–∏—á–∏–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤:")

        filtered_by_type = sum(1 for p in predictions if p["signal_type"] == "NEUTRAL")
        filtered_by_confidence = sum(
            1
            for p in predictions
            if p["signal_type"] != "NEUTRAL" and p["confidence"] < min_conf
        )
        filtered_by_strength = sum(
            1
            for p in predictions
            if p["signal_type"] != "NEUTRAL" and p["strength"] < min_strength
        )

        logger.info(f"   NEUTRAL —Å–∏–≥–Ω–∞–ª—ã: {filtered_by_type}")
        logger.info(f"   –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {filtered_by_confidence}")
        logger.info(f"   –°–ª–∞–±–∞—è —Å–∏–ª–∞: {filtered_by_strength}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
        if predictions:
            confidences = [p["confidence"] for p in predictions]
            strengths = [p["strength"] for p in predictions]
            success_probs = [p["success_probability"] for p in predictions]

            logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–µ—Ç—Ä–∏–∫:")
            logger.info(
                f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: min={min(confidences):.3f}, max={max(confidences):.3f}, avg={np.mean(confidences):.3f}"
            )
            logger.info(
                f"   –°–∏–ª–∞: min={min(strengths):.3f}, max={max(strengths):.3f}, avg={np.mean(strengths):.3f}"
            )
            logger.info(
                f"   –£—Å–ø–µ—Ö: min={min(success_probs):.1%}, max={max(success_probs):.1%}, avg={np.mean(success_probs):.1%}"
            )

    async def _analyze_database_signals(self):
        """–ê–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –ë–î"""
        logger.info("\nüóÑÔ∏è –ê–ù–ê–õ–ò–ó –°–ò–ì–ù–ê–õ–û–í –í –ë–î:")
        logger.info("=" * 60)

        async with get_async_db() as session:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–≥–Ω–∞–ª—ã
            stmt = (
                select(Signal)
                .where(Signal.strategy_name.in_(["PatchTST_ML", "PatchTST_RealTime"]))
                .order_by(Signal.created_at.desc())
                .limit(100)
            )

            result = await session.execute(stmt)
            signals = result.scalars().all()

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –ë–î: {len(signals)}")

            if signals:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
                by_type = defaultdict(int)
                by_symbol = defaultdict(int)

                for signal in signals:
                    by_type[signal.signal_type.value] += 1
                    by_symbol[signal.symbol] += 1

                logger.info("\n–ü–æ —Ç–∏–ø–∞–º:")
                for sig_type, count in by_type.items():
                    logger.info(f"   {sig_type}: {count}")

                logger.info("\n–ü–æ —Å–∏–º–≤–æ–ª–∞–º:")
                for symbol, count in by_symbol.items():
                    logger.info(f"   {symbol}: {count}")

                # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                last_signal = signals[0]
                logger.info("\n–ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–∏–≥–Ω–∞–ª:")
                logger.info(f"   –í—Ä–µ–º—è: {last_signal.created_at}")
                logger.info(f"   –°–∏–º–≤–æ–ª: {last_signal.symbol}")
                logger.info(f"   –¢–∏–ø: {last_signal.signal_type.value}")
                logger.info(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {last_signal.confidence:.3f}")
                logger.info(f"   –°–∏–ª–∞: {last_signal.strength:.3f}")

    def _generate_recommendations(self, predictions):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        logger.info("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        logger.info("=" * 60)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        if predictions:
            avg_confidence = np.mean([p["confidence"] for p in predictions])
            avg_strength = np.mean([p["strength"] for p in predictions])
            neutral_pct = sum(
                1 for p in predictions if p["signal_type"] == "NEUTRAL"
            ) / len(predictions)

            logger.info("\n1. –ü–æ—Ä–æ–≥–∏:")
            logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f}")
            logger.info(
                f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥ confidence: {max(0.3, avg_confidence * 0.7):.3f}"
            )
            logger.info(f"   –°—Ä–µ–¥–Ω—è—è —Å–∏–ª–∞: {avg_strength:.3f}")
            logger.info(
                f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥ strength: {max(0.1, avg_strength * 0.7):.3f}"
            )

            logger.info("\n2. –ú–æ–¥–µ–ª—å:")
            if neutral_pct > 0.8:
                logger.info("   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ NEUTRAL —Å–∏–≥–Ω–∞–ª–æ–≤")
                logger.info("   - –°–Ω–∏–∑—å—Ç–µ –ø–æ—Ä–æ–≥ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ ML Manager —Å 0.1 –¥–æ 0.05")
                logger.info("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                logger.info(
                    "   - –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –±–æ–ª–µ–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                )

            logger.info("\n3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
            logger.info("   –û–±–Ω–æ–≤–∏—Ç–µ config/system.yaml:")
            logger.info(f"   min_confidence: {max(0.3, avg_confidence * 0.7):.2f}")
            logger.info(f"   min_signal_strength: {max(0.1, avg_strength * 0.7):.2f}")

            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            self._create_visualization(predictions)

    def _create_visualization(self, predictions):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            import matplotlib

            matplotlib.use("Agg")  # –î–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ GUI

            fig, axes = plt.subplots(2, 2, figsize=(12, 10))

            # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
            signal_types = [p["signal_type"] for p in predictions]
            type_counts = pd.Series(signal_types).value_counts()
            axes[0, 0].pie(
                type_counts.values, labels=type_counts.index, autopct="%1.1f%%"
            )
            axes[0, 0].set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤")

            # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidences = [p["confidence"] for p in predictions]
            axes[0, 1].hist(confidences, bins=20, alpha=0.7, color="blue")
            axes[0, 1].axvline(
                x=0.45, color="red", linestyle="--", label="–¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥"
            )
            axes[0, 1].set_xlabel("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
            axes[0, 1].set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            axes[0, 1].set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
            axes[0, 1].legend()

            # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞
            strengths = [p["strength"] for p in predictions]
            axes[1, 0].hist(strengths, bins=20, alpha=0.7, color="green")
            axes[1, 0].axvline(
                x=0.2, color="red", linestyle="--", label="–¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥"
            )
            axes[1, 0].set_xlabel("–°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞")
            axes[1, 0].set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            axes[1, 0].set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞")
            axes[1, 0].legend()

            # 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ—Ç—Ä–∏–∫
            df = pd.DataFrame(predictions)
            if not df.empty:
                scatter_data = df[df["signal_type"] != "NEUTRAL"]
                if not scatter_data.empty:
                    colors = {"BUY": "green", "SELL": "red"}
                    for sig_type in ["BUY", "SELL"]:
                        data = scatter_data[scatter_data["signal_type"] == sig_type]
                        if not data.empty:
                            axes[1, 1].scatter(
                                data["confidence"],
                                data["strength"],
                                c=colors[sig_type],
                                label=sig_type,
                                alpha=0.6,
                            )
                    axes[1, 1].axvline(x=0.45, color="red", linestyle="--", alpha=0.5)
                    axes[1, 1].axhline(y=0.2, color="red", linestyle="--", alpha=0.5)
                    axes[1, 1].set_xlabel("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                    axes[1, 1].set_ylabel("–°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞")
                    axes[1, 1].set_title("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ—Ç—Ä–∏–∫")
                    axes[1, 1].legend()

            plt.tight_layout()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            output_path = Path("data/analysis/ml_predictions_analysis.png")
            output_path.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(output_path)
            plt.close()

            logger.info(f"\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}")

        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é: {e}")


async def main():
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞"""
    analyzer = MLPredictionAnalyzer()
    await analyzer.analyze_predictions()


if __name__ == "__main__":
    asyncio.run(main())
