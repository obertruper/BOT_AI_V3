#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã
"""

import asyncio
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

from sqlalchemy import text

from core.logger import setup_logger
from database.connections import AsyncSessionLocal

logger = setup_logger(__name__)


async def check_tables():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–∞–±–ª–∏—Ü"""
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü ML —Å–∏—Å—Ç–µ–º—ã...")

    required_tables = [
        "raw_market_data",
        "processed_market_data",
        "signals",
        "technical_indicators",
        "market_data_snapshots",
    ]

    async with AsyncSessionLocal() as session:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
        result = await session.execute(
            text(
                """
            SELECT table_name
            FROM information_schema.tables
            WHERE table_schema = 'public'
            AND table_name = ANY(:tables)
            ORDER BY table_name;
        """
            ),
            {"tables": required_tables},
        )

        existing_tables = [row[0] for row in result]

        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(existing_tables)}")
        for table in existing_tables:
            logger.info(f"  ‚úì {table}")

        missing_tables = set(required_tables) - set(existing_tables)
        if missing_tables:
            logger.warning(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç–∞–±–ª–∏—Ü—ã: {missing_tables}")
            return False

        return True


async def check_indexes():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤"""
    logger.info("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤...")

    async with AsyncSessionLocal() as session:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã
        result = await session.execute(
            text(
                """
            SELECT
                schemaname,
                tablename,
                indexname,
                indexdef
            FROM pg_indexes
            WHERE schemaname = 'public'
            AND tablename IN ('raw_market_data', 'processed_market_data', 'signals')
            ORDER BY tablename, indexname;
        """
            )
        )

        existing_indexes = {}
        for row in result:
            table = row[1]
            if table not in existing_indexes:
                existing_indexes[table] = []
            existing_indexes[table].append(row[2])

        logger.info("‚úÖ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã:")
        for table, indexes in existing_indexes.items():
            logger.info(f"\n  –¢–∞–±–ª–∏—Ü–∞ {table}:")
            for idx in indexes:
                logger.info(f"    ‚úì {idx}")


async def create_missing_indexes():
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    logger.info("\nüõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...")

    indexes_to_create = [
        # –î–ª—è raw_market_data - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è ML
        {
            "name": "idx_raw_market_data_symbol_timestamp_desc",
            "table": "raw_market_data",
            "columns": "symbol, timestamp DESC",
            "condition": None,
        },
        {
            "name": "idx_raw_market_data_interval_symbol",
            "table": "raw_market_data",
            "columns": "interval_minutes, symbol",
            "condition": None,
        },
        # –î–ª—è processed_market_data - –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ ML –¥–∞–Ω–Ω—ã–º
        {
            "name": "idx_processed_market_data_timestamp_desc",
            "table": "processed_market_data",
            "columns": "timestamp DESC",
            "condition": None,
        },
        {
            "name": "idx_processed_market_data_ml_features",
            "table": "processed_market_data",
            "columns": "ml_features",
            "condition": None,
            "method": "gin",
        },
        # –î–ª—è signals - –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
        {
            "name": "idx_signals_created_at_desc",
            "table": "signals",
            "columns": "created_at DESC",
            "condition": None,
        },
        {
            "name": "idx_signals_expires_at",
            "table": "signals",
            "columns": "expires_at",
            "condition": "WHERE expires_at IS NOT NULL",
        },
        {
            "name": "idx_signals_signal_type_symbol",
            "table": "signals",
            "columns": "signal_type, symbol",
            "condition": None,
        },
    ]

    async with AsyncSessionLocal() as session:
        for index in indexes_to_create:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
                check_result = await session.execute(
                    text(
                        """
                    SELECT 1 FROM pg_indexes
                    WHERE schemaname = 'public'
                    AND indexname = :index_name
                """
                    ),
                    {"index_name": index["name"]},
                )

                if check_result.scalar():
                    logger.info(f"  ‚úì –ò–Ω–¥–µ–∫—Å {index['name']} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    continue

                # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
                method = f"USING {index['method']}" if index.get("method") else ""
                condition = index.get("condition", "")

                sql = f"""
                    CREATE INDEX CONCURRENTLY IF NOT EXISTS {index["name"]}
                    ON {index["table"]} {method} ({index["columns"]})
                    {condition}
                """

                await session.execute(text(sql))
                await session.commit()
                logger.info(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å {index['name']}")

            except Exception as e:
                logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ {index['name']}: {e}")


async def check_table_sizes():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–∞–±–ª–∏—Ü –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–∞–±–ª–∏—Ü:")

    async with AsyncSessionLocal() as session:
        result = await session.execute(
            text(
                """
            SELECT
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
                pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes,
                (SELECT COUNT(*) FROM pg_stat_user_tables WHERE schemaname = t.schemaname AND tablename = t.tablename) as stats_count
            FROM pg_tables t
            WHERE schemaname = 'public'
            AND tablename IN ('raw_market_data', 'processed_market_data', 'signals', 'technical_indicators')
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
        """
            )
        )

        for row in result:
            logger.info(f"  {row[1]:25} | –†–∞–∑–º–µ—Ä: {row[2]:>10}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
        for table in ["raw_market_data", "processed_market_data", "signals"]:
            try:
                count_result = await session.execute(text(f"SELECT COUNT(*) FROM {table}"))
                count = count_result.scalar()
                logger.info(f"  {table:25} | –ó–∞–ø–∏—Å–µ–π: {count:>10,}")
            except Exception as e:
                logger.error(f"  {table:25} | –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞: {e}")


async def create_scheduler_metrics_table():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –º–µ—Ç—Ä–∏–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    logger.info("\nüõ†Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—ã scheduler_metrics...")

    async with AsyncSessionLocal() as session:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        result = await session.execute(
            text(
                """
            SELECT EXISTS (
                SELECT FROM information_schema.tables
                WHERE table_schema = 'public'
                AND table_name = 'scheduler_metrics'
            );
        """
            )
        )

        exists = result.scalar()

        if not exists:
            logger.info("  ‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ scheduler_metrics –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º...")

            await session.execute(
                text(
                    """
                CREATE TABLE scheduler_metrics (
                    id BIGSERIAL PRIMARY KEY,
                    cycle_start TIMESTAMP WITH TIME ZONE NOT NULL,
                    cycle_end TIMESTAMP WITH TIME ZONE NOT NULL,
                    duration_seconds FLOAT NOT NULL,
                    symbols_processed INTEGER NOT NULL,
                    signals_generated INTEGER NOT NULL,
                    errors_count INTEGER DEFAULT 0,
                    avg_symbol_processing_time FLOAT,
                    memory_usage_mb FLOAT,
                    cpu_usage_percent FLOAT,
                    status VARCHAR(20) DEFAULT 'completed',
                    error_details JSONB,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                );

                CREATE INDEX idx_scheduler_metrics_cycle_start ON scheduler_metrics(cycle_start DESC);
                CREATE INDEX idx_scheduler_metrics_status ON scheduler_metrics(status);
            """
                )
            )

            await session.commit()
            logger.info("  ‚úÖ –¢–∞–±–ª–∏—Ü–∞ scheduler_metrics —Å–æ–∑–¥–∞–Ω–∞")
        else:
            logger.info("  ‚úÖ –¢–∞–±–ª–∏—Ü–∞ scheduler_metrics —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")


async def check_performance():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ 50+ —Å–∏–º–≤–æ–ª–æ–≤"""
    logger.info("\n‚ö° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã...")

    async with AsyncSessionLocal() as session:
        # –¢–µ—Å—Ç –≤—ã–±–æ—Ä–∫–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–º–≤–æ–ª–∞
        test_query = """
            SELECT
                symbol,
                datetime,
                close,
                volume
            FROM raw_market_data
            WHERE symbol = 'BTCUSDT'
            AND interval_minutes = 15
            ORDER BY timestamp DESC
            LIMIT 100;
        """

        import time

        start_time = time.time()

        try:
            await session.execute(text(test_query))
            elapsed = (time.time() - start_time) * 1000

            logger.info(f"  ‚úÖ –¢–µ—Å—Ç –≤—ã–±–æ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {elapsed:.2f} –º—Å")

            if elapsed > 50:
                logger.warning("  ‚ö†Ô∏è –í—ã–±–æ—Ä–∫–∞ –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª–µ–µ 50–º—Å, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")

        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ë–î –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã BOT_AI_V3")
    logger.info("=" * 60)

    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫–∏
        tables_ok = await check_tables()

        if tables_ok:
            await check_indexes()
            await create_missing_indexes()
            await create_scheduler_metrics_table()
            await check_table_sizes()
            await check_performance()

            logger.info("\n" + "=" * 60)
            logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            logger.info("üöÄ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≥–æ—Ç–æ–≤–∞ –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã")
        else:
            logger.error("\n" + "=" * 60)
            logger.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏!")
            logger.error("–í—ã–ø–æ–ª–Ω–∏—Ç–µ: alembic upgrade head")

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
