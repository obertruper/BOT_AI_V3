#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ ML –º–æ–¥–µ–ª–∏ –∫ —Ä–∞–±–æ—Ç–µ
"""

import pickle
import sys
from datetime import datetime
from pathlib import Path

import torch

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from ml.logic.patchtst_model import UnifiedPatchTSTForTrading


def check_model_files():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏...")

    required_files = {
        "model": Path("models/saved/best_model_20250728_215703.pth"),
        "scaler": Path("models/saved/data_scaler.pkl"),
        "config": Path("models/saved/config.pkl"),
    }

    all_exist = True
    file_info = {}

    for name, path in required_files.items():
        if path.exists():
            size = path.stat().st_size / (1024 * 1024)  # MB
            file_info[name] = {
                "path": str(path),
                "size_mb": round(size, 2),
                "exists": True,
            }
            print(f"‚úÖ {name}: {path} ({size:.2f} MB)")
        else:
            file_info[name] = {"path": str(path), "exists": False}
            print(f"‚ùå {name}: {path} - –ù–ï –ù–ê–ô–î–ï–ù")
            all_exist = False

    return all_exist, file_info


def check_model_loading():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏"""
    print("\nüì¶ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏...")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        with open("models/saved/config.pkl", "rb") as f:
            config = pickle.load(f)
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = UnifiedPatchTSTForTrading(config)
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        device = torch.device("cpu")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        checkpoint = torch.load("models/saved/best_model_20250728_215703.pth", map_location=device)

        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            model.load_state_dict(checkpoint["model_state_dict"])
        else:
            model.load_state_dict(checkpoint)

        model.to(device)
        model.eval()
        print(f"‚úÖ –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–∞ {device}")

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        print("\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
        print(f"- –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
        print(f"- –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}")
        print(f"- –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        print(f"- –í—Ö–æ–¥–æ–≤: {config['model']['input_size']}")
        print(f"- –í—ã—Ö–æ–¥–æ–≤: {config['model']['output_size']}")

        return True, model, config

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False, None, None


def check_scaler():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ scaler"""
    print("\nüîß –ü—Ä–æ–≤–µ—Ä–∫–∞ scaler...")

    try:
        with open("models/saved/data_scaler.pkl", "rb") as f:
            scaler = pickle.load(f)

        print("‚úÖ Scaler –∑–∞–≥—Ä—É–∂–µ–Ω")
        print(f"- –¢–∏–ø: {type(scaler).__name__}")

        if hasattr(scaler, "mean_"):
            print(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(scaler.mean_)}")

        return True, scaler

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ scaler: {e}")
        return False, None


def test_inference(model, config, scaler):
    """–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""
    print("\nüöÄ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...")

    try:
        import numpy as np

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        batch_size = 1
        seq_len = 96  # context_window
        input_size = config["model"]["input_size"]

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = np.random.randn(seq_len, input_size)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        if scaler:
            test_data = scaler.transform(test_data)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        device = next(model.parameters()).device
        test_tensor = torch.FloatTensor(test_data).unsqueeze(0).to(device)

        print(f"- –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {test_tensor.shape}")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
        start_time = datetime.now()
        with torch.no_grad():
            output = model(test_tensor)
        inference_time = (datetime.now() - start_time).total_seconds() * 1000

        print("‚úÖ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —É—Å–ø–µ—à–µ–Ω")
        print(f"- –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {output.shape}")
        print(f"- –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {inference_time:.2f} –º—Å")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥—ã
        output_np = output.cpu().numpy()[0]
        print("\nüìà –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
        print(f"- Future return 15m: {output_np[0]:.4f}")
        print(f"- Direction 15m: {output_np[4]:.0f}")
        print(f"- Long probability 1%: {1 / (1 + np.exp(-output_np[8])):.2%}")
        print(f"- Max drawdown 1h: {output_np[16]:.4f}")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {e}")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("üîç –ü–†–û–í–ï–†–ö–ê –ì–û–¢–û–í–ù–û–°–¢–ò ML –ú–û–î–ï–õ–ò")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    files_ok, file_info = check_model_files()
    if not files_ok:
        print("\n‚ùå –ù–µ –≤—Å–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –Ω–∞–π–¥–µ–Ω—ã!")
        print("–°–∫–æ–ø–∏—Ä—É–π—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ LLM TRANSFORM")
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
    model_ok, model, config = check_model_loading()
    if not model_ok:
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ scaler
    scaler_ok, scaler = check_scaler()
    if not scaler_ok:
        return

    # –¢–µ—Å—Ç–æ–≤—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
    if model and config:
        inference_ok = test_inference(model, config, scaler)

    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\n" + "=" * 60)
    if files_ok and model_ok and scaler_ok and inference_ok:
        print("‚úÖ ML –ú–û–î–ï–õ–¨ –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï!")
        print("\n–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å:")
        print("python scripts/create_ml_trader.py")
    else:
        print("‚ùå ML –º–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
        print("–ò—Å–ø—Ä–∞–≤—å—Ç–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –≤—ã—à–µ –ø—Ä–æ–±–ª–µ–º—ã")
    print("=" * 60)


if __name__ == "__main__":
    main()
