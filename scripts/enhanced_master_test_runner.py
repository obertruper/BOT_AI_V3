#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π Master Test Runner –¥–ª—è BOT_AI_V3
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –Ω–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
"""
import argparse
import asyncio
import json
import sys
import time
from pathlib import Path
from typing import Any

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
from scripts.advanced_analyzers.ast_performance_analyzer import HighPerformanceASTAnalyzer
from scripts.advanced_analyzers.class_relationship_mapper import ClassRelationshipMapper
from scripts.smart_test_generators.ml_based_test_generator import MLBasedTestGenerator


class EnhancedMasterTestRunner:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–∞—Å—Ç–µ—Ä —Ä–∞–Ω–Ω–µ—Ä —Ç–µ—Å—Ç–æ–≤
    –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤
    """

    def __init__(self, project_root: Path = None):
        self.project_root = project_root or PROJECT_ROOT
        self.results_dir = self.project_root / "analysis_results"
        self.results_dir.mkdir(exist_ok=True)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self.ast_analyzer = HighPerformanceASTAnalyzer()
        self.class_mapper = ClassRelationshipMapper()
        self.test_generator = MLBasedTestGenerator()

        self.total_stages = 8
        self.current_stage = 0
        self.start_time = None

    def print_header(self):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫"""
        print("\n" + "üöÄ " + "ENHANCED BOT_AI_V3 MASTER TEST RUNNER".center(70) + " üöÄ")
        print("=" * 72)
        print("üéØ –¶–µ–ª—å: –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ 100% –ø–æ–∫—Ä—ã—Ç–∏—è –∫–æ–¥–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é")
        print("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞")
        print("‚ö° –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ AST")
        print("üß† ML-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
        print("üîó –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏")
        print("=" * 72)
        print(f"üìÅ –ü—Ä–æ–µ–∫—Ç: {self.project_root}")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {self.results_dir}/")
        print(f"üåê –î–∞—à–±–æ—Ä–¥: file://{self.results_dir}/enhanced_testing_dashboard.html")
        print("üóÑÔ∏è PostgreSQL: localhost:5555")
        print("=" * 72)

    def print_stage_header(self, stage_num: int, stage_name: str, description: str):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ç—Ç–∞–ø–∞"""
        self.current_stage = stage_num
        print(f"\nüìä [{stage_num}/{self.total_stages}] {stage_name}")
        print("‚îÄ" * 60)
        print(f"   üìù {description}")
        print("   ‚è≥ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...", end="", flush=True)

    def print_stage_result(self, duration: float, success: bool, details: dict = None):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞"""
        status = "‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ" if success else "‚ùå –û—à–∏–±–∫–∞"
        print(f"\r   [{self._get_progress_bar()}] 100.0% {status} –∑–∞ {duration:.2f}—Å")

        if details:
            print("   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            for key, value in details.items():
                print(f"      {key}: {value}")

    def _get_progress_bar(self, width: int = 40) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä"""
        return "‚ñà" * width

    async def run_enhanced_analysis(self, mode: str = "full") -> dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        self.start_time = time.time()
        self.print_header()

        results = {
            "start_time": self.start_time,
            "stages": {},
            "summary": {},
            "recommendations": [],
        }

        try:
            # –≠—Ç–∞–ø 1: –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π AST –∞–Ω–∞–ª–∏–∑
            if mode in ["full", "ast"]:
                stage_result = await self._run_ast_analysis()
                results["stages"]["ast_analysis"] = stage_result

            # –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –∫–ª–∞—Å—Å–æ–≤
            if mode in ["full", "classes"]:
                stage_result = await self._run_class_analysis()
                results["stages"]["class_analysis"] = stage_result

            # –≠—Ç–∞–ø 3: ML-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤
            if mode in ["full", "tests"]:
                stage_result = await self._run_test_generation()
                results["stages"]["test_generation"] = stage_result

            # –≠—Ç–∞–ø 4: –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è
            if mode in ["full", "coverage"]:
                stage_result = await self._run_coverage_analysis()
                results["stages"]["coverage_analysis"] = stage_result

            # –≠—Ç–∞–ø 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤
            if mode in ["full", "imports"]:
                stage_result = await self._run_import_analysis()
                results["stages"]["import_analysis"] = stage_result

            # –≠—Ç–∞–ø 6: –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞
            if mode in ["full", "unused"]:
                stage_result = await self._run_unused_code_analysis()
                results["stages"]["unused_code"] = stage_result

            # –≠—Ç–∞–ø 7: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤
            if mode in ["full", "reports"]:
                stage_result = await self._generate_reports(results)
                results["stages"]["reports"] = stage_result

            # –≠—Ç–∞–ø 8: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞
            if mode in ["full", "dashboard"]:
                stage_result = await self._create_dashboard(results)
                results["stages"]["dashboard"] = stage_result

            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
            results["summary"] = self._generate_summary(results)
            self._print_final_summary(results)

        except Exception as e:
            print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback

            traceback.print_exc()
            results["error"] = str(e)

        return results

    async def _run_ast_analysis(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 1: –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π AST –∞–Ω–∞–ª–∏–∑"""
        self.print_stage_header(
            1,
            "–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π AST –∞–Ω–∞–ª–∏–∑",
            "–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ AST —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å—é",
        )

        start_time = time.time()
        success = True

        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
            ast_results = await self.ast_analyzer.analyze_codebase_fast(self.project_root)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file = self.results_dir / "enhanced_ast_analysis.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(ast_results, f, indent=2, ensure_ascii=False)

            duration = time.time() - start_time

            details = {
                "üîç –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤": ast_results["statistics"]["total_files"],
                "üî¢ –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π": ast_results["statistics"]["total_functions"],
                "üèóÔ∏è –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤": ast_results["statistics"]["total_classes"],
                "üì¶ –í—Å–µ–≥–æ –∏–º–ø–æ—Ä—Ç–æ–≤": ast_results["statistics"]["total_imports"],
                "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file),
                "statistics": ast_results["statistics"],
                "data": ast_results,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _run_class_analysis(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –∫–ª–∞—Å—Å–æ–≤"""
        self.print_stage_header(
            2, "–ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏", "–ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, –∫–æ–º–ø–æ–∑–∏—Ü–∏—è, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –ø–∞—Ç—Ç–µ—Ä–Ω—ã"
        )

        start_time = time.time()
        success = True

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AST –∞–Ω–∞–ª–∏–∑–∞
            ast_file = self.results_dir / "enhanced_ast_analysis.json"
            if not ast_file.exists():
                raise FileNotFoundError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ AST –∞–Ω–∞–ª–∏–∑")

            with open(ast_file, encoding="utf-8") as f:
                ast_results = json.load(f)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–≤—è–∑–∏ –∫–ª–∞—Å—Å–æ–≤
            class_results = self.class_mapper.analyze_class_relationships(ast_results)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file = self.results_dir / "enhanced_class_relationships.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(class_results, f, indent=2, ensure_ascii=False)

            duration = time.time() - start_time

            details = {
                "üèóÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã—Ö –∫–ª–∞—Å—Å–æ–≤": len(
                    class_results["relationships"]["inheritance"]["chains"]
                ),
                "üîó –°–≤—è–∑–µ–π –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è": len(
                    class_results["relationships"]["inheritance"]["chains"]
                ),
                "üì¶ –°–≤—è–∑–µ–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏": len(class_results["relationships"]["composition"]),
                "‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º": len(class_results["potential_issues"]),
                "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file),
                "data": class_results,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _run_test_generation(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 3: ML-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤"""
        self.print_stage_header(
            3,
            "ML-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É–º–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤",
            "–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫–æ–¥–∞ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤",
        )

        start_time = time.time()
        success = True

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã AST –∞–Ω–∞–ª–∏–∑–∞
            ast_file = self.results_dir / "enhanced_ast_analysis.json"
            with open(ast_file, encoding="utf-8") as f:
                ast_results = json.load(f)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π
            all_test_cases = []
            functions_analyzed = 0

            for func_name, func_info in ast_results.get("functions", {}).items():
                try:
                    test_cases = self.test_generator.generate_tests_for_function(func_info)
                    all_test_cases.extend(test_cases)
                    functions_analyzed += 1

                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    if functions_analyzed >= 50:
                        break

                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞ –¥–ª—è {func_name}: {e}")
                    continue

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            test_results = {
                "generated_tests": [
                    {
                        "name": tc.name,
                        "code": tc.code,
                        "description": tc.description,
                        "test_type": tc.test_type,
                        "priority": tc.priority,
                        "dependencies": tc.dependencies,
                    }
                    for tc in all_test_cases
                ],
                "statistics": {
                    "functions_analyzed": functions_analyzed,
                    "tests_generated": len(all_test_cases),
                    "unit_tests": len([tc for tc in all_test_cases if tc.test_type == "unit"]),
                    "integration_tests": len(
                        [tc for tc in all_test_cases if tc.test_type == "integration"]
                    ),
                    "e2e_tests": len([tc for tc in all_test_cases if tc.test_type == "e2e"]),
                },
            }

            output_file = self.results_dir / "enhanced_generated_tests.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(test_results, f, indent=2, ensure_ascii=False)

            duration = time.time() - start_time

            details = {
                "üîç –§—É–Ω–∫—Ü–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ": functions_analyzed,
                "üß™ –¢–µ—Å—Ç–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ": len(all_test_cases),
                "üìã Unit —Ç–µ—Å—Ç–æ–≤": test_results["statistics"]["unit_tests"],
                "üîó Integration —Ç–µ—Å—Ç–æ–≤": test_results["statistics"]["integration_tests"],
                "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file),
                "statistics": test_results["statistics"],
                "data": test_results,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _run_coverage_analysis(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 4: –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è"""
        self.print_stage_header(
            4, "–ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–æ–¥–∞", "–ò–∑–º–µ—Ä–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –∏ –ø–æ–∏—Å–∫ –ø—Ä–æ–±–µ–ª–æ–≤"
        )

        start_time = time.time()
        success = True

        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º pytest —Å coverage
            import subprocess

            coverage_cmd = [
                sys.executable,
                "-m",
                "pytest",
                "tests/",
                "--cov=.",
                "--cov-report=json:coverage.json",
                "--cov-report=html:htmlcov",
                "--quiet",
            ]

            result = subprocess.run(
                coverage_cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300,  # 5 –º–∏–Ω—É—Ç –º–∞–∫—Å–∏–º—É–º
            )

            # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫—Ä—ã—Ç–∏—è
            coverage_file = self.project_root / "coverage.json"
            if coverage_file.exists():
                with open(coverage_file) as f:
                    coverage_data = json.load(f)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ results
                output_file = self.results_dir / "enhanced_coverage_analysis.json"
                with open(output_file, "w") as f:
                    json.dump(coverage_data, f, indent=2)

                total_coverage = coverage_data["totals"]["percent_covered"]
                lines_covered = coverage_data["totals"]["covered_lines"]
                lines_total = coverage_data["totals"]["num_statements"]

                details = {
                    "üìä –ü–æ–∫—Ä—ã—Ç–∏–µ": f"{total_coverage:.1f}%",
                    "üìÑ –°—Ç—Ä–æ–∫ –ø–æ–∫—Ä—ã—Ç–æ": f"{lines_covered}/{lines_total}",
                    "üìÅ –§–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ": len(coverage_data["files"]),
                    "üîó HTML –æ—Ç—á—ë—Ç": "htmlcov/index.html",
                    "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
                }

            else:
                details = {"‚ùå –§–∞–π–ª –ø–æ–∫—Ä—ã—Ç–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω": "coverage.json"}
                success = False

            duration = time.time() - start_time
            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file) if coverage_file.exists() else None,
                "coverage_percent": total_coverage if coverage_file.exists() else 0,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _run_import_analysis(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤"""
        self.print_stage_header(
            5, "–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏–º–ø–æ—Ä—Ç–æ–≤", "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
        )

        start_time = time.time()
        success = True

        try:
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤
            import_issues = []
            valid_imports = 0

            # –ó–∞–≥—Ä—É–∂–∞–µ–º AST —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            ast_file = self.results_dir / "enhanced_ast_analysis.json"
            with open(ast_file, encoding="utf-8") as f:
                ast_results = json.load(f)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã
            for file_path, imports in ast_results.get("imports", {}).items():
                for import_info in imports:
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å
                        module_name = import_info.get("module", "")
                        if module_name and not module_name.startswith("."):
                            __import__(module_name)
                            valid_imports += 1
                    except ImportError as e:
                        import_issues.append(
                            {"file": file_path, "module": module_name, "error": str(e)}
                        )
                    except Exception:
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏
                        pass

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            import_results = {
                "valid_imports": valid_imports,
                "import_issues": import_issues,
                "total_checked": valid_imports + len(import_issues),
            }

            output_file = self.results_dir / "enhanced_import_analysis.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(import_results, f, indent=2, ensure_ascii=False)

            duration = time.time() - start_time

            details = {
                "‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤": valid_imports,
                "‚ùå –ü—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤": len(import_issues),
                "üìä –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ": import_results["total_checked"],
                "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file),
                "data": import_results,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _run_unused_code_analysis(self) -> dict[str, Any]:
        """–≠—Ç–∞–ø 6: –ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞"""
        self.print_stage_header(
            6, "–ü–æ–∏—Å–∫ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞", "–ê–Ω–∞–ª–∏–∑ call graph –∏ –ø–æ–∏—Å–∫ –º—ë—Ä—Ç–≤–æ–≥–æ –∫–æ–¥–∞"
        )

        start_time = time.time()
        success = True

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º AST —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            ast_file = self.results_dir / "enhanced_ast_analysis.json"
            with open(ast_file, encoding="utf-8") as f:
                ast_results = json.load(f)

            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞
            call_graph = ast_results.get("call_graph", {})
            all_functions = set(ast_results.get("functions", {}).keys())
            called_functions = set()

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤—ã–∑—ã–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            for caller, callees in call_graph.items():
                called_functions.update(callees)

            # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            unused_functions = all_functions - called_functions

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
            filtered_unused = []
            for func in unused_functions:
                func_name = func.split(":")[-1] if ":" in func else func
                if not (func_name.startswith("__") and func_name.endswith("__")):
                    if not func_name.startswith("test_"):
                        filtered_unused.append(func)

            unused_results = {
                "total_functions": len(all_functions),
                "called_functions": len(called_functions),
                "unused_functions": filtered_unused,
                "unused_count": len(filtered_unused),
                "usage_percentage": (
                    (len(called_functions) / len(all_functions)) * 100 if all_functions else 0
                ),
            }

            output_file = self.results_dir / "enhanced_unused_code_analysis.json"
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(unused_results, f, indent=2, ensure_ascii=False)

            duration = time.time() - start_time

            details = {
                "üî¢ –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π": len(all_functions),
                "‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö": len(called_functions),
                "üóëÔ∏è –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö": len(filtered_unused),
                "üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ": f"{unused_results['usage_percentage']:.1f}%",
                "üîó –†–µ–∑—É–ª—å—Ç–∞—Ç": str(output_file),
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "output_file": str(output_file),
                "data": unused_results,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _generate_reports(self, results: dict[str, Any]) -> dict[str, Any]:
        """–≠—Ç–∞–ø 7: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤"""
        self.print_stage_header(7, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤", "–°–æ–∑–¥–∞–Ω–∏–µ JSON –∏ Markdown –æ—Ç—á—ë—Ç–æ–≤")

        start_time = time.time()
        success = True

        try:
            # –°–æ–∑–¥–∞—ë–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á—ë—Ç
            summary_report = {
                "execution_info": {
                    "start_time": results["start_time"],
                    "end_time": time.time(),
                    "duration": time.time() - results["start_time"],
                    "stages_completed": len(
                        [s for s in results["stages"].values() if s.get("success")]
                    ),
                },
                "analysis_summary": {},
                "recommendations": [],
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞
            for stage_name, stage_data in results["stages"].items():
                if stage_data.get("success"):
                    summary_report["analysis_summary"][stage_name] = {
                        "duration": stage_data["duration"],
                        "output_file": stage_data.get("output_file"),
                        "key_metrics": stage_data.get("statistics", {}),
                    }

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            summary_report["recommendations"] = self._generate_recommendations(results)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –æ—Ç—á—ë—Ç
            json_report_file = self.results_dir / "enhanced_master_report.json"
            with open(json_report_file, "w", encoding="utf-8") as f:
                json.dump(summary_report, f, indent=2, ensure_ascii=False)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown –æ—Ç—á—ë—Ç
            md_report_file = self.results_dir / "enhanced_master_report.md"
            self._generate_markdown_report(summary_report, md_report_file)

            duration = time.time() - start_time

            details = {
                "üìÑ JSON –æ—Ç—á—ë—Ç": str(json_report_file),
                "üìù Markdown –æ—Ç—á—ë—Ç": str(md_report_file),
                "üìä –≠—Ç–∞–ø–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ": summary_report["execution_info"]["stages_completed"],
                "‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è": f"{summary_report['execution_info']['duration']:.1f}—Å",
            }

            self.print_stage_result(duration, success, details)

            return {
                "success": success,
                "duration": duration,
                "json_report": str(json_report_file),
                "markdown_report": str(md_report_file),
                "data": summary_report,
            }

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    async def _create_dashboard(self, results: dict[str, Any]) -> dict[str, Any]:
        """–≠—Ç–∞–ø 8: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞"""
        self.print_stage_header(
            8, "–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–∞—à–±–æ—Ä–¥–∞", "HTML –¥–∞—à–±–æ—Ä–¥ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"
        )

        start_time = time.time()
        success = True

        try:
            # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π HTML –¥–∞—à–±–æ—Ä–¥
            dashboard_html = self._generate_dashboard_html(results)

            dashboard_file = self.results_dir / "enhanced_testing_dashboard.html"
            with open(dashboard_file, "w", encoding="utf-8") as f:
                f.write(dashboard_html)

            duration = time.time() - start_time

            details = {
                "üåê –î–∞—à–±–æ—Ä–¥": str(dashboard_file),
                "üîó –û—Ç–∫—Ä—ã—Ç—å": f"firefox {dashboard_file}",
                "üìä –°–µ–∫—Ü–∏–π": "8",
                "üìà –ì—Ä–∞—Ñ–∏–∫–æ–≤": "4",
            }

            self.print_stage_result(duration, success, details)

            return {"success": success, "duration": duration, "dashboard_file": str(dashboard_file)}

        except Exception as e:
            duration = time.time() - start_time
            success = False
            self.print_stage_result(duration, success, {"‚ùå –û—à–∏–±–∫–∞": str(e)})

            return {"success": success, "duration": duration, "error": str(e)}

    def _generate_summary(self, results: dict[str, Any]) -> dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É"""
        total_duration = time.time() - results["start_time"]
        successful_stages = len([s for s in results["stages"].values() if s.get("success")])
        success_rate = (successful_stages / self.total_stages) * 100

        return {
            "total_duration": total_duration,
            "successful_stages": successful_stages,
            "total_stages": self.total_stages,
            "success_rate": success_rate,
            "performance": f"{self.total_stages / total_duration:.1f} stages/min",
        }

    def _generate_recommendations(self, results: dict[str, Any]) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –¥–∞—ë–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if "coverage_analysis" in results["stages"]:
            coverage_data = results["stages"]["coverage_analysis"]
            if coverage_data.get("coverage_percent", 0) < 80:
                recommendations.append(
                    "–ü–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–¥–∞ –º–µ–Ω–µ–µ 80% - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Ç–µ—Å—Ç–æ–≤"
                )

        if "unused_code" in results["stages"]:
            unused_data = results["stages"]["unused_code"].get("data", {})
            if unused_data.get("unused_count", 0) > 100:
                recommendations.append(
                    "–ù–∞–π–¥–µ–Ω–æ –º–Ω–æ–≥–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ –∫–æ–¥–∞ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥"
                )

        if "import_analysis" in results["stages"]:
            import_data = results["stages"]["import_analysis"].get("data", {})
            if len(import_data.get("import_issues", [])) > 10:
                recommendations.append("–ú–Ω–æ–≥–æ –ø—Ä–æ–±–ª–µ–º —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")

        return recommendations

    def _generate_markdown_report(self, report_data: dict, output_file: Path):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Markdown –æ—Ç—á—ë—Ç"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π Markdown –æ—Ç—á—ë—Ç
        markdown_content = f"""# Enhanced BOT_AI_V3 Analysis Report
        
## Execution Summary
- **Duration**: {report_data['execution_info']['duration']:.1f} seconds
- **Stages Completed**: {report_data['execution_info']['stages_completed']}/{self.total_stages}
- **Start Time**: {time.ctime(report_data['execution_info']['start_time'])}

## Analysis Results
"""

        for stage_name, stage_data in report_data["analysis_summary"].items():
            markdown_content += f"\n### {stage_name.replace('_', ' ').title()}\n"
            markdown_content += f"- Duration: {stage_data['duration']:.2f}s\n"
            if stage_data.get("output_file"):
                markdown_content += f"- Output: `{stage_data['output_file']}`\n"

        if report_data["recommendations"]:
            markdown_content += "\n## Recommendations\n"
            for rec in report_data["recommendations"]:
                markdown_content += f"- {rec}\n"

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(markdown_content)

    def _generate_dashboard_html(self, results: dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–∞—à–±–æ—Ä–¥"""
        # –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π HTML –¥–∞—à–±–æ—Ä–¥
        return f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enhanced BOT_AI_V3 Testing Dashboard</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; text-align: center; }}
        .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0; }}
        .metric {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .metric h3 {{ color: #2c3e50; margin-top: 0; }}
        .metric .value {{ font-size: 2em; font-weight: bold; color: #3498db; }}
        .stages {{ background: white; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .stage {{ display: flex; justify-content: space-between; padding: 10px; border-bottom: 1px solid #eee; }}
        .stage.success {{ background: #d4edda; }}
        .stage.error {{ background: #f8d7da; }}
        .footer {{ text-align: center; color: #7f8c8d; margin-top: 20px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üöÄ Enhanced BOT_AI_V3 Testing Dashboard</h1>
            <p>Advanced Code Analysis & Testing System</p>
        </div>
        
        <div class="metrics">
            <div class="metric">
                <h3>üìä Success Rate</h3>
                <div class="value">{results.get('summary', {}).get('success_rate', 0):.1f}%</div>
            </div>
            <div class="metric">
                <h3>‚è±Ô∏è Total Duration</h3>
                <div class="value">{results.get('summary', {}).get('total_duration', 0):.1f}s</div>
            </div>
            <div class="metric">
                <h3>‚úÖ Completed Stages</h3>
                <div class="value">{results.get('summary', {}).get('successful_stages', 0)}/{self.total_stages}</div>
            </div>
            <div class="metric">
                <h3>üöÄ Performance</h3>
                <div class="value">{results.get('summary', {}).get('performance', 'N/A')}</div>
            </div>
        </div>
        
        <div class="stages">
            <h2>üìã Analysis Stages</h2>
            {self._generate_stages_html(results)}
        </div>
        
        <div class="footer">
            <p>Generated at {time.ctime()} | BOT_AI_V3 Enhanced Testing System</p>
        </div>
    </div>
</body>
</html>"""

    def _generate_stages_html(self, results: dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –¥–ª—è —ç—Ç–∞–ø–æ–≤"""
        stages_html = ""

        stage_names = {
            "ast_analysis": "üîç AST Analysis",
            "class_analysis": "üèóÔ∏è Class Relationships",
            "test_generation": "üß™ Test Generation",
            "coverage_analysis": "üìä Coverage Analysis",
            "import_analysis": "üì¶ Import Analysis",
            "unused_code": "üóëÔ∏è Unused Code",
            "reports": "üìÑ Reports",
            "dashboard": "üåê Dashboard",
        }

        for stage_key, stage_name in stage_names.items():
            stage_data = results.get("stages", {}).get(stage_key, {})
            success = stage_data.get("success", False)
            duration = stage_data.get("duration", 0)

            css_class = "success" if success else "error"
            status = "‚úÖ Success" if success else "‚ùå Error"

            stages_html += f"""
            <div class="stage {css_class}">
                <span>{stage_name}</span>
                <span>{status} ({duration:.2f}s)</span>
            </div>
            """

        return stages_html

    def _print_final_summary(self, results: dict[str, Any]):
        """–ü–µ—á–∞—Ç–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É"""
        summary = results["summary"]

        print("\n" + "üéâ " + "ENHANCED MASTER TEST RUNNER - –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–Å–¢".center(70) + " üéâ")
        print("=" * 72)

        print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['total_duration']:.1f}—Å")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤: {summary['successful_stages']}/{summary['total_stages']}")
        print(f"üìä –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {summary['success_rate']:.1f}%")
        print(f"üöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {summary['performance']}")

        print("=" * 72)
        print("üèÜ ENHANCED –°–ò–°–¢–ï–ú–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ù–ê–°–¢–†–û–ï–ù–ê!")

        # –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\nüìÇ –ì–î–ï –ò–°–ö–ê–¢–¨ –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print("‚îÄ" * 40)

        print("üåê Enhanced –¥–∞—à–±–æ—Ä–¥:")
        print(f"   firefox {self.results_dir}/enhanced_testing_dashboard.html")
        print("   üìä –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ")

        print("\nüìÑ JSON –æ—Ç—á—ë—Ç—ã:")
        for stage_name, stage_data in results["stages"].items():
            if stage_data.get("success") and stage_data.get("output_file"):
                print(f"   üìã {stage_name}: {stage_data['output_file']}")

        if results.get("summary", {}).get("success_rate", 0) >= 80:
            print("\nüéä –ü–û–ó–î–†–ê–í–õ–Ø–ï–ú! Enhanced —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
        else:
            print("\n‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —ç—Ç–∞–ø—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–∞–º–∏ - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏")

        print("\n" + "=" * 72)


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description="Enhanced Master Test Runner –¥–ª—è BOT_AI_V3")
    parser.add_argument(
        "--mode",
        choices=[
            "full",
            "ast",
            "classes",
            "tests",
            "coverage",
            "imports",
            "unused",
            "reports",
            "dashboard",
        ],
        default="full",
        help="–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞",
    )
    parser.add_argument("--project-root", type=str, help="–ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞")

    args = parser.parse_args()

    project_root = Path(args.project_root) if args.project_root else PROJECT_ROOT

    runner = EnhancedMasterTestRunner(project_root)

    try:
        results = await runner.run_enhanced_analysis(args.mode)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        final_results_file = runner.results_dir / "enhanced_final_results.json"
        with open(final_results_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\nüíæ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {final_results_file}")

        return results

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return None
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
        return None


if __name__ == "__main__":
    asyncio.run(main())
