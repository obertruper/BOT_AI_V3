#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ 3 –º–µ—Å—è—Ü–∞
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML —Å–∏—Å—Ç–µ–º—ã
"""

import asyncio
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List

import asyncpg
import ccxt.pro as ccxt
from dotenv import load_dotenv

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.config.config_manager import ConfigManager
from core.logger import setup_logger

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

logger = setup_logger("load_3months_data")

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
DB_USER = os.getenv("PGUSER", "obertruper")
DB_PASSWORD = os.getenv("PGPASSWORD", "")
DB_NAME = os.getenv("PGDATABASE", "bot_trading_v3")
DB_PORT = os.getenv("PGPORT", "5555")
DB_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@localhost:{DB_PORT}/{DB_NAME}"


async def create_tables(pool):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    async with pool.acquire() as conn:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        result = await conn.fetchrow(
            """
            SELECT COUNT(*) as count
            FROM information_schema.tables
            WHERE table_name = 'raw_market_data'
        """
        )

        if result["count"] > 0:
            logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ raw_market_data —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        else:
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            await conn.execute(
                """
                CREATE TABLE raw_market_data (
                    id BIGSERIAL PRIMARY KEY,
                    symbol VARCHAR(20) NOT NULL,
                    timestamp BIGINT NOT NULL,
                    datetime TIMESTAMP WITH TIME ZONE NOT NULL,
                    open DECIMAL(20, 8) NOT NULL,
                    high DECIMAL(20, 8) NOT NULL,
                    low DECIMAL(20, 8) NOT NULL,
                    close DECIMAL(20, 8) NOT NULL,
                    volume DECIMAL(20, 8) NOT NULL,
                    turnover DECIMAL(20, 8),
                    interval_minutes INTEGER NOT NULL,
                    market_type markettype,
                    exchange VARCHAR(50),
                    open_interest DECIMAL(20, 8),
                    funding_rate DECIMAL(10, 8),
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    updated_at TIMESTAMP WITH TIME ZONE
                )
            """
            )
            logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ raw_market_data —Å–æ–∑–¥–∞–Ω–∞")

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∏—Ö –µ—â–µ –Ω–µ—Ç)
        try:
            await conn.execute(
                """
                CREATE INDEX IF NOT EXISTS idx_raw_market_data_symbol_datetime_interval
                ON raw_market_data(symbol, datetime DESC, interval_minutes)
            """
            )
            logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å—ã –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã/—Å–æ–∑–¥–∞–Ω—ã")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å—ã —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç: {e}")

        # –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        await conn.execute(
            """
            CREATE TABLE IF NOT EXISTS data_maintenance_log (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(50) NOT NULL,
                exchange VARCHAR(50) NOT NULL,
                interval_minutes INTEGER NOT NULL,
                start_date TIMESTAMP WITH TIME ZONE NOT NULL,
                end_date TIMESTAMP WITH TIME ZONE NOT NULL,
                records_loaded INTEGER NOT NULL,
                gaps_found INTEGER DEFAULT 0,
                execution_time_seconds FLOAT,
                status VARCHAR(20) NOT NULL,
                error_message TEXT,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            )
        """
        )

        logger.info("‚úÖ –¢–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")


async def check_existing_data(
    pool, symbol: str, exchange: str, interval_minutes: int
) -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
    async with pool.acquire() as conn:
        result = await conn.fetchrow(
            """
            SELECT
                COUNT(*) as count,
                MIN(datetime) as min_date,
                MAX(datetime) as max_date
            FROM raw_market_data
            WHERE symbol = $1 AND exchange = $2 AND interval_minutes = $3
        """,
            symbol,
            exchange,
            interval_minutes,
        )

        return {
            "count": result["count"],
            "min_date": result["min_date"],
            "max_date": result["max_date"],
        }


async def find_data_gaps(
    pool,
    symbol: str,
    exchange: str,
    interval_minutes: int,
    start_date: datetime,
    end_date: datetime,
) -> List[Dict]:
    """–ü–æ–∏—Å–∫ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö"""
    async with pool.acquire() as conn:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        rows = await conn.fetch(
            """
            SELECT datetime
            FROM raw_market_data
            WHERE symbol = $1 AND exchange = $2 AND interval_minutes = $3
                AND datetime >= $4 AND datetime <= $5
            ORDER BY datetime
        """,
            symbol,
            exchange,
            interval_minutes,
            start_date,
            end_date,
        )

        if len(rows) < 2:
            return []

        gaps = []
        expected_delta = timedelta(minutes=interval_minutes)

        for i in range(1, len(rows)):
            prev_time = rows[i - 1]["datetime"]
            curr_time = rows[i]["datetime"]
            actual_delta = curr_time - prev_time

            if actual_delta > expected_delta * 1.5:  # –ü—Ä–æ–ø—É—Å–∫ –±–æ–ª—å—à–µ 1.5 –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
                gaps.append(
                    {
                        "start": prev_time,
                        "end": curr_time,
                        "missing_candles": int(
                            actual_delta.total_seconds() / 60 / interval_minutes
                        )
                        - 1,
                    }
                )

        return gaps


async def load_symbol_data(
    exchange,
    symbol: str,
    interval_minutes: int,
    start_date: datetime,
    end_date: datetime,
    pool,
) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤"""
    start_time = datetime.now()
    stats = {
        "symbol": symbol,
        "loaded": 0,
        "gaps_filled": 0,
        "errors": 0,
        "status": "success",
    }

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        existing = await check_existing_data(pool, symbol, "bybit", interval_minutes)
        logger.info(f"üìä {symbol}: –Ω–∞–π–¥–µ–Ω–æ {existing['count']} –∑–∞–ø–∏—Å–µ–π")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        if existing["count"] > 0 and existing["max_date"]:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
            gaps = await find_data_gaps(
                pool,
                symbol,
                "bybit",
                interval_minutes,
                start_date,
                existing["max_date"],
            )

            if gaps:
                logger.warning(f"‚ö†Ô∏è {symbol}: –Ω–∞–π–¥–µ–Ω–æ {len(gaps)} –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if existing["max_date"] < end_date:
                load_start = existing["max_date"] + timedelta(minutes=interval_minutes)
            else:
                logger.info(f"‚úÖ {symbol}: –¥–∞–Ω–Ω—ã–µ —É–∂–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã")
                return stats
        else:
            load_start = start_date
            gaps = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–∞—Å—Ç—è–º–∏
        current_start = load_start
        all_candles = []

        while current_start < end_date:
            since = int(current_start.timestamp() * 1000)

            try:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º interval_minutes –≤ timeframe
                timeframe_str = f"{interval_minutes}m"
                candles = await exchange.fetch_ohlcv(
                    symbol, timeframe=timeframe_str, since=since, limit=1000
                )

                if not candles:
                    break

                all_candles.extend(candles)

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é
                last_timestamp = candles[-1][0]
                current_start = datetime.fromtimestamp(
                    last_timestamp / 1000
                ) + timedelta(minutes=interval_minutes)

                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                logger.error(f"‚ùå {symbol}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
                stats["errors"] += 1
                await asyncio.sleep(1)
                continue

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        if all_candles:
            async with pool.acquire() as conn:
                values = []
                for candle in all_candles:
                    timestamp_ms = candle[0]
                    timestamp_dt = datetime.fromtimestamp(timestamp_ms / 1000)
                    values.append(
                        (
                            symbol,
                            timestamp_ms,  # timestamp as bigint
                            timestamp_dt,  # datetime as timestamptz
                            float(candle[1]),  # open
                            float(candle[2]),  # high
                            float(candle[3]),  # low
                            float(candle[4]),  # close
                            float(candle[5]),  # volume
                            interval_minutes,
                            "bybit",  # exchange
                        )
                    )

                # –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                result = await conn.executemany(
                    """
                    INSERT INTO raw_market_data
                    (symbol, timestamp, datetime, open, high, low, close, volume, interval_minutes, exchange)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                    ON CONFLICT (symbol, timestamp, interval_minutes, exchange) DO NOTHING
                """,
                    values,
                )

                stats["loaded"] = len(all_candles)
                logger.info(f"‚úÖ {symbol}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {stats['loaded']} –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π")

        # –õ–æ–≥–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é
        execution_time = (datetime.now() - start_time).total_seconds()
        async with pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO data_maintenance_log
                (symbol, exchange, interval_minutes, start_date, end_date,
                 records_loaded, gaps_found, execution_time_seconds, status)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
            """,
                symbol,
                "bybit",
                interval_minutes,
                load_start,
                end_date,
                stats["loaded"],
                len(gaps),
                execution_time,
                stats["status"],
            )

    except Exception as e:
        logger.error(f"‚ùå {symbol}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        stats["status"] = "error"
        stats["error"] = str(e)

        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
        async with pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO data_maintenance_log
                (symbol, exchange, interval_minutes, start_date, end_date,
                 records_loaded, execution_time_seconds, status, error_message)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
            """,
                symbol,
                "bybit",
                interval_minutes,
                start_date,
                end_date,
                0,
                0,
                "error",
                str(e),
            )

    return stats


async def load_symbols_batch(
    exchange,
    symbols: List[str],
    interval_minutes: int,
    start_date: datetime,
    end_date: datetime,
    pool,
    batch_size: int = 5,
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤ –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    all_stats = []

    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
    for i in range(0, len(symbols), batch_size):
        batch = symbols[i : i + batch_size]
        logger.info(
            f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞—Ç—á–∞ {i // batch_size + 1}/{(len(symbols) + batch_size - 1) // batch_size}"
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = []
        for symbol in batch:
            task = load_symbol_data(
                exchange, symbol, interval_minutes, start_date, end_date, pool
            )
            tasks.append(task)

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –±–∞—Ç—á–∞
        batch_stats = await asyncio.gather(*tasks)
        all_stats.extend(batch_stats)

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
        if i + batch_size < len(symbols):
            await asyncio.sleep(2)

    return all_stats


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ 3 –º–µ—Å—è—Ü–∞")
    logger.info(f"üìä –ë–î: {DB_NAME} –Ω–∞ –ø–æ—Ä—Ç—É {DB_PORT}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_manager = ConfigManager()
    await config_manager.initialize()

    # –ü–æ–ª—É—á–∞–µ–º —Å–∏–º–≤–æ–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    ml_config = config_manager.get_ml_config()
    symbols = ml_config.get("symbols", [])

    if not symbols:
        logger.error("‚ùå –ù–µ—Ç —Å–∏–º–≤–æ–ª–æ–≤ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!")
        return

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)  # 3 –º–µ—Å—è—Ü–∞
    interval_minutes = 15  # 15-–º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏

    logger.info(
        f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}"
    )
    logger.info(f"üìà –°–∏–º–≤–æ–ª—ã ({len(symbols)}): {', '.join(symbols[:5])}...")
    logger.info(f"‚è±Ô∏è –ò–Ω—Ç–µ—Ä–≤–∞–ª: {interval_minutes} –º–∏–Ω—É—Ç")

    # –°–æ–∑–¥–∞–µ–º –ø—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ –ë–î
    pool = await asyncpg.create_pool(DB_URL, min_size=5, max_size=20)

    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
        await create_tables(pool)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∏—Ä–∂—É
        exchange = ccxt.bybit(
            {
                "enableRateLimit": True,
                "options": {
                    "defaultType": "linear",  # USDT perpetual
                },
            }
        )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç–∞–º–∏
        logger.info("\nüîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö...")
        all_stats = await load_symbols_batch(
            exchange,
            symbols,
            interval_minutes,
            start_date,
            end_date,
            pool,
            batch_size=5,
        )

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_loaded = sum(s["loaded"] for s in all_stats)
        successful = sum(1 for s in all_stats if s["status"] == "success")
        failed = sum(1 for s in all_stats if s["status"] == "error")

        logger.info("\n" + "=" * 60)
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"‚ùå –° –æ—à–∏–±–∫–∞–º–∏: {failed} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"üìà –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å–≤–µ—á–µ–π: {total_loaded:,}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –ë–î
        async with pool.acquire() as conn:
            result = await conn.fetchrow(
                """
                SELECT
                    COUNT(DISTINCT symbol) as symbols,
                    COUNT(*) as total_records,
                    MIN(datetime) as min_date,
                    MAX(datetime) as max_date
                FROM raw_market_data
                WHERE interval_minutes = $1
            """,
                interval_minutes,
            )

            logger.info("\nüìä –°–û–°–¢–û–Ø–ù–ò–ï –ë–ê–ó–´ –î–ê–ù–ù–´–•:")
            logger.info(f"üìà –°–∏–º–≤–æ–ª–æ–≤: {result['symbols']}")
            logger.info(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {result['total_records']:,}")
            logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {result['min_date']} - {result['max_date']}")

        await exchange.close()

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
    finally:
        await pool.close()

    logger.info("\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    asyncio.run(main())
