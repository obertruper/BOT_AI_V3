#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã —Å –¥—É–±–ª–∏—Ä—É—é—â–∏–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
"""

import asyncio
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.logger import setup_logger
from database.connections.postgres import AsyncPGPool

logger = setup_logger("fix_duplicates")


async def fix_duplicate_signals():
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""

    logger.info("üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤...")

    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        await AsyncPGPool.get_pool()

        # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ —Å–∏–≥–Ω–∞–ª—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        duplicate_query = """
        WITH duplicates AS (
            SELECT
                symbol,
                signal_type,
                strength,
                confidence,
                created_at,
                ROW_NUMBER() OVER (
                    PARTITION BY symbol, signal_type, strength, confidence
                    ORDER BY created_at DESC
                ) as rn
            FROM signals
            WHERE created_at > NOW() - INTERVAL '24 hours'
        )
        SELECT * FROM duplicates WHERE rn > 1
        """

        duplicates = await AsyncPGPool.fetch(duplicate_query)

        if duplicates:
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(duplicates)} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤:")

            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            delete_query = """
            DELETE FROM signals
            WHERE id IN (
                SELECT id FROM (
                    SELECT
                        id,
                        ROW_NUMBER() OVER (
                            PARTITION BY symbol, signal_type, strength, confidence
                            ORDER BY created_at DESC
                        ) as rn
                    FROM signals
                    WHERE created_at > NOW() - INTERVAL '24 hours'
                ) t WHERE rn > 1
            )
            """

            result = await AsyncPGPool.execute(delete_query)
            logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {result} –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
            unique_query = """
            SELECT
                symbol,
                signal_type,
                strength,
                confidence,
                COUNT(*) as count,
                MIN(created_at) as first_seen,
                MAX(created_at) as last_seen
            FROM signals
            WHERE created_at > NOW() - INTERVAL '24 hours'
            GROUP BY symbol, signal_type, strength, confidence
            ORDER BY last_seen DESC
            """

            unique_signals = await AsyncPGPool.fetch(unique_query)

            logger.info("üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:")
            for signal in unique_signals:
                logger.info(
                    f"  {signal['symbol']}: {signal['signal_type']} strength={signal['strength']} confidence={signal['confidence']} (count={signal['count']})"
                )
        else:
            logger.info("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä–¥–µ—Ä–∞, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –æ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        duplicate_orders_query = """
        SELECT
            symbol,
            side,
            order_type,
            status,
            quantity,
            COUNT(*) as count
        FROM orders
        WHERE created_at > NOW() - INTERVAL '24 hours'
        GROUP BY symbol, side, order_type, status, quantity
        HAVING COUNT(*) > 1
        ORDER BY count DESC
        """

        duplicate_orders = await AsyncPGPool.fetch(duplicate_orders_query)

        if duplicate_orders:
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(duplicate_orders)} —Ç–∏–ø–æ–≤ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –æ—Ä–¥–µ—Ä–æ–≤:")
            for order in duplicate_orders:
                logger.info(
                    f"  {order['symbol']}: {order['side']} {order['order_type']} {order['status']} {order['quantity']} (count={order['count']})"
                )
        else:
            logger.info("‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö –æ—Ä–¥–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")

    finally:
        await AsyncPGPool.close_pool()


async def add_signal_uniqueness_constraint():
    """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤"""

    logger.info("üîí –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤...")

    try:
        await AsyncPGPool.get_pool()

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–±–µ–∑ DATE_TRUNC)
        index_query = """
        CREATE UNIQUE INDEX IF NOT EXISTS idx_signals_unique
        ON signals (symbol, signal_type, strength, confidence)
        """

        await AsyncPGPool.execute(index_query)
        logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {e}")

    finally:
        await AsyncPGPool.close_pool()


if __name__ == "__main__":
    asyncio.run(fix_duplicate_signals())
    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    asyncio.run(add_signal_uniqueness_constraint())
