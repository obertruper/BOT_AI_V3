#!/usr/bin/env python3
"""
Real-time —Ä–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""

import asyncio
from datetime import UTC, datetime
from decimal import Decimal
from typing import Any

import numpy as np
import pandas as pd
from sqlalchemy import desc, select
from sqlalchemy.dialects.postgresql import insert

from core.logger import setup_logger
from database.connections import get_async_db
from database.models.market_data import ProcessedMarketData, RawMarketData
from ml.config.features_240 import REQUIRED_FEATURES_240
from ml.logic.feature_engineering_v2 import FeatureEngineer

logger = setup_logger(__name__)


class RealTimeIndicatorCalculator:
    """
    –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
    """

    def __init__(
        self,
        cache_ttl: int = 900,
        config: dict[str, Any] | None = None,
        use_inference_mode: bool = True,
    ):
        """
        Args:
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
            use_inference_mode: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ inference mode –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        # –ü–µ—Ä–µ–¥–∞–µ–º inference_mode –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é FeatureEngineer
        engineer_config = config or {}
        engineer_config["inference_mode"] = use_inference_mode

        self.feature_engineer = FeatureEngineer(engineer_config, inference_mode=use_inference_mode)
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å async –æ–ø–µ—Ä–∞—Ü–∏–∏
        self.feature_engineer.disable_progress = False  # –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        self.cache = {}  # –ö–µ—à —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self.cache_ttl = cache_ttl
        self._lock = asyncio.Lock()
        self.use_inference_mode = use_inference_mode

        logger.info(
            f"RealTimeIndicatorCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (inference_mode={use_inference_mode})"
        )

    async def calculate_indicators(
        self, symbol: str, ohlcv_df: pd.DataFrame, save_to_db: bool = True
    ) -> dict[str, Any]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–º–≤–æ–ª
            ohlcv_df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 240 —Å–≤–µ—á–µ–π)
            save_to_db: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            logger.info(f"üîç Starting calculate_indicators for {symbol}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            cache_key = f"{symbol}_{ohlcv_df.index[-1]}"
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–µ—à –¥–ª—è {symbol}")
                return cached_result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if len(ohlcv_df) < 96:
                logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(ohlcv_df)} < 96")
                return {}

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            logger.info(f"–†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol} –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏...")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            logger.info(
                f"About to call create_features for {symbol} (inference_mode={self.use_inference_mode})"
            )
            features_result = self.feature_engineer.create_features(
                df, inference_mode=self.use_inference_mode
            )
            logger.info(
                f"create_features returned type: {type(features_result)}, shape: {getattr(features_result, 'shape', 'no shape')}"
            )

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if isinstance(features_result, pd.DataFrame):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_240
                available_cols = features_result.columns.tolist()
                selected_features = []

                # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏–∑ REQUIRED_FEATURES_240
                for feature in REQUIRED_FEATURES_240:
                    if feature in available_cols:
                        selected_features.append(feature)
                    else:
                        # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
                        logger.warning(f"–ü—Ä–∏–∑–Ω–∞–∫ {feature} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ä–æ–≤–Ω–æ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                if len(selected_features) != 240:
                    logger.error(f"–ü–æ–ª—É—á–µ–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–º–µ—Å—Ç–æ 240!")
                    # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –º–µ–Ω—å—à–µ 240
                    while len(selected_features) < 240:
                        selected_features.append("padding_0")
                        features_result["padding_0"] = 0.0

                features_array = features_result[selected_features[:240]].values
                feature_names = selected_features[:240]
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
                feature_names = [f"feature_{i}" for i in range(features_array.shape[1])]
            else:
                logger.error(f"create_features returned unexpected type: {type(features_result)}")
                return {}

            # feature_names —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤—ã—à–µ

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array, –∑–∞—Ç–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dict
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[-1]  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array
                current_features = {
                    feature_names[i]: float(last_features[i]) for i in range(len(last_features))
                }
            else:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}")
                return {}

            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = self._structure_indicators(current_features, ohlcv_df)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result["metadata"] = {
                "symbol": symbol,
                "timestamp": int(ohlcv_df.index[-1].timestamp() * 1000),
                "datetime": ohlcv_df.index[-1],
                "features_count": len(current_features),
                "calculation_time": datetime.now(UTC),
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if save_to_db:
                await self._save_to_database(symbol, result)

            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self._add_to_cache(cache_key, result)

            logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω–æ {len(current_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}")

            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol}: {e}")
            return {}

    async def calculate_indicators_batch(
        self, symbols: list[str], ohlcv_data: dict[str, pd.DataFrame]
    ) -> dict[str, dict[str, Any]]:
        """
        –ü–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
            ohlcv_data: –°–ª–æ–≤–∞—Ä—å {symbol: DataFrame}

        Returns:
            –°–ª–æ–≤–∞—Ä—å {symbol: indicators}
        """
        results = {}

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
        tasks = []
        for symbol in symbols:
            if symbol in ohlcv_data:
                task = self.calculate_indicators(symbol, ohlcv_data[symbol])
                tasks.append((symbol, task))

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
        for symbol, task in tasks:
            try:
                result = await task
                results[symbol] = result
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–ª—è {symbol}: {e}")
                results[symbol] = {}

        return results

    def _prepare_dataframe(self, ohlcv_df: pd.DataFrame, symbol: str = "BTCUSDT") -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç DataFrame –¥–ª—è FeatureEngineer
        """
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = ["open", "high", "low", "close", "volume"]

        df = ohlcv_df.copy()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        for col in required_columns:
            if col not in df.columns:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if "turnover" not in df.columns:
            df["turnover"] = df["close"] * df["volume"]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É symbol (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "symbol" not in df.columns:
            df["symbol"] = symbol

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ datetime –∫–æ–ª–æ–Ω–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "datetime" in df.columns:
            # –ï—Å–ª–∏ datetime —É–∂–µ –µ—Å—Ç—å –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
            pass
        elif hasattr(df.index, "name") and df.index.name == "datetime":
            # –ï—Å–ª–∏ datetime —ç—Ç–æ –∏–º—è –∏–Ω–¥–µ–∫—Å–∞, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ –∫–æ–ª–æ–Ω–∫—É
            df = df.reset_index()
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç datetime –Ω–∏ –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∏ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å–∞, —Å–æ–∑–¥–∞–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            df["datetime"] = df.index

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        df = df.sort_index()

        return df

    def _structure_indicators(
        self, features: dict[str, float], ohlcv_df: pd.DataFrame
    ) -> dict[str, Any]:
        """
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
        """
        # –ë–∞–∑–æ–≤—ã–µ OHLCV
        last_candle = ohlcv_df.iloc[-1]

        result = {
            "ohlcv": {
                "open": float(last_candle["open"]),
                "high": float(last_candle["high"]),
                "low": float(last_candle["low"]),
                "close": float(last_candle["close"]),
                "volume": float(last_candle["volume"]),
            }
        }

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        technical_indicators = {}
        microstructure_features = {}
        ml_features = features.copy()

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        tech_indicators_list = [
            "sma_",
            "ema_",
            "rsi_",
            "macd_",
            "bb_",
            "atr_",
            "stoch_",
            "adx_",
            "cci_",
            "williams_",
            "mfi_",
            "obv",
        ]

        for key, value in features.items():
            for indicator in tech_indicators_list:
                if key.startswith(indicator):
                    technical_indicators[key] = value
                    break

            # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if any(x in key for x in ["spread", "imbalance", "pressure", "flow"]):
                microstructure_features[key] = value

        result["technical_indicators"] = technical_indicators
        result["microstructure_features"] = microstructure_features
        result["ml_features"] = ml_features

        return result

    async def _save_to_database(self, symbol: str, indicators: dict[str, Any]):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            async with get_async_db() as session:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –∏–∑ raw_market_data
                stmt = (
                    select(RawMarketData)
                    .where(RawMarketData.symbol == symbol)
                    .order_by(desc(RawMarketData.timestamp))
                    .limit(1)
                )

                result = await session.execute(stmt)
                raw_data = result.scalar_one_or_none()

                if not raw_data:
                    logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã raw –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
                    return

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                metadata = indicators.get("metadata", {})
                ohlcv = indicators.get("ohlcv", {})

                processed_data = {
                    "raw_data_id": raw_data.id,
                    "symbol": symbol,
                    "timestamp": metadata.get("timestamp", raw_data.timestamp),
                    "datetime": metadata.get("datetime", raw_data.datetime),
                    "open": Decimal(str(ohlcv.get("open", raw_data.open))),
                    "high": Decimal(str(ohlcv.get("high", raw_data.high))),
                    "low": Decimal(str(ohlcv.get("low", raw_data.low))),
                    "close": Decimal(str(ohlcv.get("close", raw_data.close))),
                    "volume": Decimal(str(ohlcv.get("volume", raw_data.volume))),
                    "technical_indicators": indicators.get("technical_indicators", {}),
                    "microstructure_features": indicators.get("microstructure_features", {}),
                    "ml_features": indicators.get("ml_features", {}),
                    "processing_version": "2.0",  # Real-time –≤–µ—Ä—Å–∏—è
                    "model_version": "patchtst_v1",
                }

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert
                stmt = insert(ProcessedMarketData).values(**processed_data)
                stmt = stmt.on_conflict_do_update(
                    constraint="_symbol_timestamp_processed_uc",
                    set_={
                        "technical_indicators": stmt.excluded.technical_indicators,
                        "microstructure_features": stmt.excluded.microstructure_features,
                        "ml_features": stmt.excluded.ml_features,
                        "updated_at": datetime.now(UTC),
                    },
                )

                await session.execute(stmt)
                await session.commit()

                logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol} –≤ –ë–î")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î –¥–ª—è {symbol}: {e}")

    def _get_from_cache(self, cache_key: str) -> dict[str, Any] | None:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã"""
        if cache_key not in self.cache:
            return None

        cached_data, timestamp = self.cache[cache_key]

        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if not isinstance(timestamp, datetime):
            logger.warning(
                f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø timestamp –≤ –∫–µ—à–µ: {type(timestamp)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {timestamp}"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø timestamp –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(timestamp, (int, float)):
            # –ï—Å–ª–∏ timestamp —ç—Ç–æ Unix timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            if timestamp > 1e10:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                timestamp = datetime.fromtimestamp(timestamp / 1000, tz=UTC)
            else:  # –°–µ–∫—É–Ω–¥—ã
                timestamp = datetime.fromtimestamp(timestamp, tz=UTC)
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
            self.cache[cache_key] = (cached_data, timestamp)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
        if (datetime.now(UTC) - timestamp).total_seconds() > self.cache_ttl:
            del self.cache[cache_key]
            return None

        return cached_data

    def _add_to_cache(self, cache_key: str, data: dict[str, Any]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫–µ—à"""
        self.cache[cache_key] = (data, datetime.now(UTC))

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –µ—Å–ª–∏ –∫–µ—à —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        if len(self.cache) > 100:
            self._cleanup_cache()

    def _cleanup_cache(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫–µ—à–∞"""
        current_time = datetime.now(UTC)
        keys_to_remove = []

        for key, (data, timestamp) in self.cache.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø timestamp –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if isinstance(timestamp, (int, float)):
                # –ï—Å–ª–∏ timestamp —ç—Ç–æ Unix timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                if timestamp > 1e10:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    timestamp = datetime.fromtimestamp(timestamp / 1000, tz=UTC)
                else:  # –°–µ–∫—É–Ω–¥—ã
                    timestamp = datetime.fromtimestamp(timestamp, tz=UTC)
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
                self.cache[key] = (data, timestamp)

            if (current_time - timestamp).total_seconds() > self.cache_ttl:
                keys_to_remove.append(key)

        for key in keys_to_remove:
            del self.cache[key]

    async def get_features_for_ml(self, symbol: str, ohlcv_df: pd.DataFrame) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ

        Returns:
            Numpy –º–∞—Å—Å–∏–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ FeatureEngineer –±–µ–∑ async
            logger.info(f"üöÄ get_features_for_ml: Direct feature calculation for {symbol}")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –ü—Ä—è–º–æ –≤—ã–∑—ã–≤–∞–µ–º create_features (—ç—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
            features_result = self.feature_engineer.create_features(
                df, inference_mode=self.use_inference_mode
            )

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if isinstance(features_result, pd.DataFrame):
                logger.info(
                    f"üîß get_features_for_ml: DataFrame shape {features_result.shape}, columns: {len(features_result.columns)}"
                )

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_240
                available_cols = features_result.columns.tolist()
                selected_features = []

                for feature in REQUIRED_FEATURES_240:
                    if feature in available_cols:
                        selected_features.append(feature)
                    else:
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                        selected_features.append(feature)
                        features_result[feature] = 0.0
                        logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –Ω—É–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫: {feature}")

                # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                logger.info(
                    f"üîß get_features_for_ml: selected_features={len(selected_features)}, required={len(REQUIRED_FEATURES_240)}"
                )
                assert len(selected_features) == 240, (
                    f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(selected_features)}"
                )
                features_array = features_result[selected_features].values
                logger.info(
                    f"üîß get_features_for_ml: final features_array shape: {features_array.shape}"
                )
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
            else:
                logger.error(
                    f"create_features returned {type(features_result)}, expected DataFrame or np.ndarray"
                )
                return np.array([])

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[-1]  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–∑–º–µ—Ä–æ–º 240
                logger.info(
                    f"‚úÖ get_features_for_ml: Extracted {len(last_features)} features for {symbol}"
                )
                assert len(last_features) == 240, (
                    f"–û–∂–∏–¥–∞–ª–æ—Å—å 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(last_features)}"
                )
                return last_features
            else:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}")
                return np.array([])

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ get_features_for_ml –¥–ª—è {symbol}: {e}")
            return np.array([])

    async def prepare_ml_input(
        self, symbol: str, ohlcv_df: pd.DataFrame, lookback: int = 96
    ) -> tuple[np.ndarray, dict[str, Any]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∏–Ω–∏–º—É–º lookback + 144 —Å–≤–µ—á–µ–π)
            lookback: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –º–æ–¥–µ–ª–∏

        Returns:
            (features_array, metadata)
        """
        logger.info(
            f"üöÄ –ù–ê–ß–ò–ù–ê–ï–ú prepare_ml_input –¥–ª—è {symbol}, –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)}, inference_mode: {self.use_inference_mode}"
        )

        if len(ohlcv_df) < lookback:  # –ú–∏–Ω–∏–º—É–º –Ω—É–∂–Ω–æ lookback —Å–≤–µ—á–µ–π
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)} < {lookback}")

        # –ü–†–ê–í–ò–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame —Å—Ä–∞–∑—É
        # FeatureEngineer —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å rolling windows
        logger.info(f"üîÑ –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}, –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)}")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
        df = self._prepare_dataframe(ohlcv_df, symbol)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame
        # FeatureEngineer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ (n_samples, n_features)
        features_result = self.feature_engineer.create_features(
            df, inference_mode=self.use_inference_mode
        )

        if isinstance(features_result, pd.DataFrame):
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_240
            available_cols = features_result.columns.tolist()
            logger.debug(f"üîß DataFrame –æ—Ç FeatureEngineer: {len(available_cols)} –∫–æ–ª–æ–Ω–æ–∫")
            logger.debug(f"üîß –ü–µ—Ä–≤—ã–µ 10 –∫–æ–ª–æ–Ω–æ–∫: {available_cols[:10]}")

            selected_features = []

            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏–∑ REQUIRED_FEATURES_240
            for feature in REQUIRED_FEATURES_240:
                if feature in available_cols:
                    selected_features.append(feature)
                else:
                    # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤–æ–π
                    selected_features.append(feature)
                    features_result[feature] = 0.0
                    logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –Ω—É–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫: {feature}")

            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            logger.debug(
                f"üîß prepare_ml_input: selected_features={len(selected_features)}, required={len(REQUIRED_FEATURES_240)}"
            )
            assert len(selected_features) == 240, (
                f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(selected_features)}"
            )
            features_array = features_result[selected_features].values
            logger.info(
                f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ—á–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ REQUIRED_FEATURES_240"
            )
            logger.debug(f"üîß features_array shape –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {features_array.shape}")
        elif isinstance(features_result, np.ndarray):
            logger.info(
                f"üîß prepare_ml_input: FeatureEngineer –≤–µ—Ä–Ω—É–ª np.ndarray shape: {features_result.shape}"
            )
            features_array = features_result
        else:
            raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(features_result)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        if features_array.ndim != 2:
            raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_array.shape}")

        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
        if len(features_array) < lookback:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ, –¥–æ–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            padding_size = lookback - len(features_array)
            padding = np.tile(features_array[0], (padding_size, 1))
            features_array = np.vstack([padding, features_array])
        else:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
            features_array = features_array[-lookback:]

        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension: (lookback, features) -> (1, lookback, features)
        features_array = features_array.reshape(1, lookback, -1)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –æ—à–∏–±–∫–∏ sqrt
        try:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ numpy
            features_sample = np.asarray(features_array[0], dtype=np.float64)
            feature_std = np.std(features_sample, axis=0)
            non_zero_std = np.sum(feature_std > 1e-6)
        except (TypeError, ValueError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            # Fallback - –ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑ std
            non_zero_std = (
                features_array.shape[2] if features_array.ndim > 2 else features_array.shape[1]
            )

        logger.info(f"üìä ML –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {symbol}: shape={features_array.shape}")
        logger.info(
            f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π: {non_zero_std}/{features_array.shape[2]}"
        )
        logger.debug(
            f"   –î–∏—Å–ø–µ—Ä—Å–∏—è: min={feature_std.min():.6f}, max={feature_std.max():.6f}, mean={feature_std.mean():.6f}"
        )

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "symbol": symbol,
            "last_timestamp": ohlcv_df.index[-1],
            "last_price": float(ohlcv_df["close"].iloc[-1]),
            "lookback": lookback,
            "features_count": features_array.shape[2],
            "non_zero_variance_features": int(non_zero_std),
        }

        return features_array, metadata
