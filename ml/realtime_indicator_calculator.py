#!/usr/bin/env python3
"""
Real-time —Ä–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""

import asyncio
from datetime import UTC, datetime
from decimal import Decimal
from typing import Any

import numpy as np
import pandas as pd
from sqlalchemy import desc, select
from sqlalchemy.dialects.postgresql import insert

from core.logger import setup_logger
from database.connections import get_async_db
from database.models.market_data import ProcessedMarketData, RawMarketData
from ml.logic.feature_engineering_production import ProductionFeatureEngineer as FeatureEngineer
from production_features_config import PRODUCTION_FEATURES as REQUIRED_FEATURES_231

logger = setup_logger(__name__)


class RealTimeIndicatorCalculator:
    """
    –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
    """

    def __init__(
        self,
        cache_ttl: int = 900,
        config: dict[str, Any] | None = None,
        use_inference_mode: bool = True,
    ):
        """
        Args:
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
            use_inference_mode: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ inference mode –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        # –ü–µ—Ä–µ–¥–∞–µ–º inference_mode –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é FeatureEngineer
        # ProductionFeatureEngineer —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        # –ü–µ—Ä–µ–¥–∞–µ–º –ø—É—Å—Ç—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, –∫–æ–¥ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ —ç—Ç–æ
        engineer_config = {}

        self.feature_engineer = FeatureEngineer(engineer_config)
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å async –æ–ø–µ—Ä–∞—Ü–∏–∏
        self.feature_engineer.disable_progress = False  # –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        self.cache = {}  # –ö–µ—à —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self.cache_ttl = cache_ttl
        self._lock = asyncio.Lock()
        self.use_inference_mode = use_inference_mode

        logger.info(
            f"RealTimeIndicatorCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (inference_mode={use_inference_mode})"
        )

    async def calculate_indicators(
        self, symbol: str, ohlcv_df: pd.DataFrame, save_to_db: bool = True
    ) -> dict[str, Any]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–º–≤–æ–ª
            ohlcv_df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 150 —Å–≤–µ—á–µ–π)
            save_to_db: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            logger.info(f"üîç Starting calculate_indicators for {symbol}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            cache_key = f"{symbol}_{ohlcv_df.index[-1]}"
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–µ—à –¥–ª—è {symbol}")
                return cached_result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if len(ohlcv_df) < 96:
                logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(ohlcv_df)} < 96")
                return {}

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            logger.info(f"–†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol} –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏...")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            logger.info(f"About to call create_features for {symbol}")
            # ProductionFeatureEngineer –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç inference_mode, –Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç use_enhanced_features
            features_result = self.feature_engineer.create_features(df, use_enhanced_features=True)
            logger.info(
                f"create_features returned type: {type(features_result)}, shape: {getattr(features_result, 'shape', 'no shape')}"
            )

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            if isinstance(features_result, pd.DataFrame):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_231
                available_cols = features_result.columns.tolist()
                selected_features = []

                # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏–∑ REQUIRED_FEATURES_231
                for feature in REQUIRED_FEATURES_231:
                    if feature in available_cols:
                        selected_features.append(feature)
                    else:
                        # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
                        logger.warning(f"–ü—Ä–∏–∑–Ω–∞–∫ {feature} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ä–æ–≤–Ω–æ 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                if len(selected_features) != 231:
                    logger.error(f"–ü–æ–ª—É—á–µ–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–º–µ—Å—Ç–æ 231!")
                    # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –º–µ–Ω—å—à–µ 231
                    while len(selected_features) < 231:
                        selected_features.append("padding_0")
                        features_result["padding_0"] = 0.0

                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –º–∞—Å—Å–∏–≤–∞
                numeric_features = []
                for feature in selected_features[:231]:
                    if feature in features_result.columns:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                        if pd.api.types.is_numeric_dtype(features_result[feature]):
                            numeric_features.append(feature)
                        else:
                            logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ-—á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É: {feature}")
                            # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –∑–∞–≥–ª—É—à–∫—É
                            features_result[f"{feature}_numeric"] = 0.0
                            numeric_features.append(f"{feature}_numeric")
                    else:
                        # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
                        features_result[f"{feature}_missing"] = 0.0
                        numeric_features.append(f"{feature}_missing")

                features_array = features_result[numeric_features].values
                feature_names = numeric_features
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
                feature_names = [f"feature_{i}" for i in range(features_array.shape[1])]
            else:
                logger.error(f"create_features returned unexpected type: {type(features_result)}")
                return {}

            # feature_names —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤—ã—à–µ

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array, –∑–∞—Ç–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dict
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[-1]  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array
                current_features = {
                    feature_names[i]: float(last_features[i]) for i in range(len(last_features))
                }
            else:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}")
                return {}

            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = self._structure_indicators(current_features, ohlcv_df)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result["metadata"] = {
                "symbol": symbol,
                "timestamp": int(ohlcv_df.index[-1].timestamp() * 1000),
                "datetime": ohlcv_df.index[-1],
                "features_count": len(current_features),
                "calculation_time": datetime.now(UTC),
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if save_to_db:
                await self._save_to_database(symbol, result)

            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self._add_to_cache(cache_key, result)

            logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω–æ {len(current_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}")

            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol}: {e}")
            return {}

    async def calculate_indicators_batch(
        self, symbols: list[str], ohlcv_data: dict[str, pd.DataFrame]
    ) -> dict[str, dict[str, Any]]:
        """
        –ü–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
            ohlcv_data: –°–ª–æ–≤–∞—Ä—å {symbol: DataFrame}

        Returns:
            –°–ª–æ–≤–∞—Ä—å {symbol: indicators}
        """
        results = {}

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
        tasks = []
        for symbol in symbols:
            if symbol in ohlcv_data:
                task = self.calculate_indicators(symbol, ohlcv_data[symbol])
                tasks.append((symbol, task))

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
        for symbol, task in tasks:
            try:
                result = await task
                results[symbol] = result
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–ª—è {symbol}: {e}")
                results[symbol] = {}

        return results

    def _prepare_dataframe(self, ohlcv_df: pd.DataFrame, symbol: str = "BTCUSDT") -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç DataFrame –¥–ª—è FeatureEngineer
        """
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = ["open", "high", "low", "close", "volume"]

        df = ohlcv_df.copy()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        for col in required_columns:
            if col not in df.columns:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if "turnover" not in df.columns:
            df["turnover"] = df["close"] * df["volume"]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É symbol (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "symbol" not in df.columns:
            df["symbol"] = symbol

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ datetime –∫–æ–ª–æ–Ω–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "datetime" in df.columns:
            # –ï—Å–ª–∏ datetime —É–∂–µ –µ—Å—Ç—å –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
            pass
        elif hasattr(df.index, "name") and df.index.name == "datetime":
            # –ï—Å–ª–∏ datetime —ç—Ç–æ –∏–º—è –∏–Ω–¥–µ–∫—Å–∞, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ –∫–æ–ª–æ–Ω–∫—É
            df = df.reset_index()
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç datetime –Ω–∏ –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∏ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å–∞, —Å–æ–∑–¥–∞–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            df["datetime"] = df.index

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        df = df.sort_index()

        return df

    def _structure_indicators(
        self, features: dict[str, float], ohlcv_df: pd.DataFrame
    ) -> dict[str, Any]:
        """
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
        """
        # –ë–∞–∑–æ–≤—ã–µ OHLCV
        last_candle = ohlcv_df.iloc[-1]

        result = {
            "ohlcv": {
                "open": float(last_candle["open"]),
                "high": float(last_candle["high"]),
                "low": float(last_candle["low"]),
                "close": float(last_candle["close"]),
                "volume": float(last_candle["volume"]),
            }
        }

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        technical_indicators = {}
        microstructure_features = {}
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        ml_features = {
            k: v
            for k, v in features.items()
            if isinstance(v, (int, float, np.integer, np.floating)) and not isinstance(v, str)
        }

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        tech_indicators_list = [
            "sma_",
            "ema_",
            "rsi_",
            "macd_",
            "bb_",
            "atr_",
            "stoch_",
            "adx_",
            "cci_",
            "williams_",
            "mfi_",
            "obv",
        ]

        for key, value in features.items():
            for indicator in tech_indicators_list:
                if key.startswith(indicator):
                    technical_indicators[key] = value
                    break

            # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if any(x in key for x in ["spread", "imbalance", "pressure", "flow"]):
                microstructure_features[key] = value

        result["technical_indicators"] = technical_indicators
        result["microstructure_features"] = microstructure_features
        result["ml_features"] = ml_features

        return result

    async def _save_to_database(self, symbol: str, indicators: dict[str, Any]):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            async with get_async_db() as session:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –∏–∑ raw_market_data
                stmt = (
                    select(RawMarketData)
                    .where(RawMarketData.symbol == symbol)
                    .order_by(desc(RawMarketData.timestamp))
                    .limit(1)
                )

                result = await session.execute(stmt)
                raw_data = result.scalar_one_or_none()

                if not raw_data:
                    logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã raw –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
                    return

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                metadata = indicators.get("metadata", {})
                ohlcv = indicators.get("ohlcv", {})

                processed_data = {
                    "raw_data_id": raw_data.id,
                    "symbol": symbol,
                    "timestamp": metadata.get("timestamp", raw_data.timestamp),
                    "datetime": metadata.get("datetime", raw_data.datetime),
                    "open": Decimal(str(ohlcv.get("open", raw_data.open))),
                    "high": Decimal(str(ohlcv.get("high", raw_data.high))),
                    "low": Decimal(str(ohlcv.get("low", raw_data.low))),
                    "close": Decimal(str(ohlcv.get("close", raw_data.close))),
                    "volume": Decimal(str(ohlcv.get("volume", raw_data.volume))),
                    "technical_indicators": indicators.get("technical_indicators", {}),
                    "microstructure_features": indicators.get("microstructure_features", {}),
                    "ml_features": indicators.get("ml_features", {}),
                    "processing_version": "2.0",  # Real-time –≤–µ—Ä—Å–∏—è
                    "model_version": "patchtst_v1",
                }

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert
                stmt = insert(ProcessedMarketData).values(**processed_data)
                stmt = stmt.on_conflict_do_update(
                    constraint="_symbol_timestamp_processed_uc",
                    set_={
                        "technical_indicators": stmt.excluded.technical_indicators,
                        "microstructure_features": stmt.excluded.microstructure_features,
                        "ml_features": stmt.excluded.ml_features,
                        "updated_at": datetime.now(UTC),
                    },
                )

                await session.execute(stmt)
                await session.commit()

                logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol} –≤ –ë–î")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î –¥–ª—è {symbol}: {e}")

    def _get_from_cache(self, cache_key: str) -> dict[str, Any] | None:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã"""
        if cache_key not in self.cache:
            return None

        cached_data, timestamp = self.cache[cache_key]

        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if not isinstance(timestamp, datetime):
            logger.warning(
                f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø timestamp –≤ –∫–µ—à–µ: {type(timestamp)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {timestamp}"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø timestamp –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if isinstance(timestamp, (int, float)):
            # –ï—Å–ª–∏ timestamp —ç—Ç–æ Unix timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            if timestamp > 1e10:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                timestamp = datetime.fromtimestamp(timestamp / 1000, tz=UTC)
            else:  # –°–µ–∫—É–Ω–¥—ã
                timestamp = datetime.fromtimestamp(timestamp, tz=UTC)
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
            self.cache[cache_key] = (cached_data, timestamp)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
        if (datetime.now(UTC) - timestamp).total_seconds() > self.cache_ttl:
            del self.cache[cache_key]
            return None

        return cached_data

    def _add_to_cache(self, cache_key: str, data: dict[str, Any]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫–µ—à"""
        self.cache[cache_key] = (data, datetime.now(UTC))

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –µ—Å–ª–∏ –∫–µ—à —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        if len(self.cache) > 100:
            self._cleanup_cache()

    def _cleanup_cache(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫–µ—à–∞"""
        current_time = datetime.now(UTC)
        keys_to_remove = []

        for key, (data, timestamp) in self.cache.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø timestamp –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if isinstance(timestamp, (int, float)):
                # –ï—Å–ª–∏ timestamp —ç—Ç–æ Unix timestamp –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –∏–ª–∏ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
                if timestamp > 1e10:  # –ú–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    timestamp = datetime.fromtimestamp(timestamp / 1000, tz=UTC)
                else:  # –°–µ–∫—É–Ω–¥—ã
                    timestamp = datetime.fromtimestamp(timestamp, tz=UTC)
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
                self.cache[key] = (data, timestamp)

            if (current_time - timestamp).total_seconds() > self.cache_ttl:
                keys_to_remove.append(key)

        for key in keys_to_remove:
            del self.cache[key]

    async def get_features_for_ml(self, symbol: str, ohlcv_df: pd.DataFrame) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ

        Returns:
            Numpy –º–∞—Å—Å–∏–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ FeatureEngineer –±–µ–∑ async
            logger.info(f"üöÄ get_features_for_ml: Direct feature calculation for {symbol}")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –ü—Ä—è–º–æ –≤—ã–∑—ã–≤–∞–µ–º create_features (—ç—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
            features_result = self.feature_engineer.create_features(df, use_enhanced_features=True)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if isinstance(features_result, pd.DataFrame):
                logger.info(
                    f"üîß get_features_for_ml: DataFrame shape {features_result.shape}, columns: {len(features_result.columns)}"
                )

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_231
                available_cols = features_result.columns.tolist()
                selected_features = []

                for feature in REQUIRED_FEATURES_231:
                    if feature in available_cols:
                        selected_features.append(feature)
                    else:
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                        selected_features.append(feature)
                        features_result[feature] = 0.0
                        logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –Ω—É–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫: {feature}")

                # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Ä–æ–≤–Ω–æ 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                logger.info(
                    f"üîß get_features_for_ml: selected_features={len(selected_features)}, required={len(REQUIRED_FEATURES_231)}"
                )
                assert (
                    len(selected_features) == 231
                ), f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(selected_features)}"
                features_array = features_result[selected_features].values
                logger.info(
                    f"üîß get_features_for_ml: final features_array shape: {features_array.shape}"
                )
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
            else:
                logger.error(
                    f"create_features returned {type(features_result)}, expected DataFrame or np.ndarray"
                )
                return np.array([])

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[-1]  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–∑–º–µ—Ä–æ–º 240
                logger.info(
                    f"‚úÖ get_features_for_ml: Extracted {len(last_features)} features for {symbol}"
                )
                assert (
                    len(last_features) == 231
                ), f"–û–∂–∏–¥–∞–ª–æ—Å—å 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(last_features)}"
                return last_features
            else:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}")
                return np.array([])

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ get_features_for_ml –¥–ª—è {symbol}: {e}")
            return np.array([])

    async def prepare_ml_input(
        self, symbol: str, ohlcv_df: pd.DataFrame, lookback: int = 96
    ) -> tuple[np.ndarray, dict[str, Any]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∏–Ω–∏–º—É–º lookback + 144 —Å–≤–µ—á–µ–π)
            lookback: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –º–æ–¥–µ–ª–∏

        Returns:
            (features_array, metadata)
        """
        logger.info(
            f"üöÄ –ù–ê–ß–ò–ù–ê–ï–ú prepare_ml_input –¥–ª—è {symbol}, –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)}, inference_mode: {self.use_inference_mode}"
        )

        if len(ohlcv_df) < lookback:  # –ú–∏–Ω–∏–º—É–º –Ω—É–∂–Ω–æ lookback —Å–≤–µ—á–µ–π
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)} < {lookback}")

        # –ü–†–ê–í–ò–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame —Å—Ä–∞–∑—É
        # FeatureEngineer —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å rolling windows
        logger.info(f"üîÑ –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}, –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)}")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
        df = self._prepare_dataframe(ohlcv_df, symbol)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame
        # FeatureEngineer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ (n_samples, n_features)
        # ProductionFeatureEngineer –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç inference_mode
        features_result = self.feature_engineer.create_features(df, use_enhanced_features=True)

        if isinstance(features_result, pd.DataFrame):
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML –º–æ–¥–µ–ª–∏
            available_cols = features_result.columns.tolist()
            logger.info(f"üîß DataFrame –æ—Ç FeatureEngineer: {len(available_cols)} –∫–æ–ª–æ–Ω–æ–∫")

            # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
            exclude_cols = [
                "datetime",
                "symbol",
                "open",
                "high",
                "low",
                "close",
                "volume",
                "quote_volume",
                "turnover",
                "sector",
            ]

            # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (—Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Ç—Ä–æ–∫–∏ 'UP', 'DOWN', 'FLAT')
            target_patterns = ["direction_", "future_return_", "target_tp_", "target_sl_"]
            for col in available_cols:
                if any(pattern in col for pattern in target_patterns):
                    exclude_cols.append(col)

            # –ë–µ—Ä–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫—Ä–æ–º–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö
            all_features = [col for col in available_cols if col not in exclude_cols]

            # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –¥–æ –ø–µ—Ä–≤—ã—Ö 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏)
            selected_features = all_features[:240]
            logger.info(f"üéØ –í—Å–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(all_features)}")
            logger.info(f"üéØ –í—ã–±—Ä–∞–Ω–æ –¥–ª—è ML –º–æ–¥–µ–ª–∏: {len(selected_features)} (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ 240)")

            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å enhanced features
            enhanced_features = [
                col
                for col in selected_features
                if any(
                    x in col
                    for x in [
                        "trend_strength",
                        "regime",
                        "volatility_ratio",
                        "ofi",
                        "trade_intensity",
                    ]
                )
            ]
            if enhanced_features:
                logger.info(f"‚úÖ Enhanced features –∞–∫—Ç–∏–≤–Ω—ã: {len(enhanced_features)} –Ω–∞–π–¥–µ–Ω–æ")
                logger.info(f"   Enhanced features: {enhanced_features}")
            else:
                logger.warning("‚ö†Ô∏è Enhanced features –ù–ï –Ω–∞–π–¥–µ–Ω—ã!")

            # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_array = features_result[selected_features].values
            logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(selected_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏")
            logger.info(f"üîß features_array shape: {features_array.shape}")
        elif isinstance(features_result, np.ndarray):
            logger.info(
                f"üîß prepare_ml_input: FeatureEngineer –≤–µ—Ä–Ω—É–ª np.ndarray shape: {features_result.shape}"
            )
            features_array = features_result
        else:
            raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(features_result)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        if features_array.ndim != 2:
            raise ValueError(f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_array.shape}")

        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
        if len(features_array) < lookback:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ, –¥–æ–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            padding_size = lookback - len(features_array)
            padding = np.tile(features_array[0], (padding_size, 1))
            features_array = np.vstack([padding, features_array])
        else:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
            features_array = features_array[-lookback:]

        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension: (lookback, features) -> (1, lookback, features)
        features_array = features_array.reshape(1, lookback, -1)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –æ—à–∏–±–∫–∏ sqrt
        try:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ numpy - —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            features_sample = features_array[0]
            if features_sample.dtype.kind not in ["i", "u", "f"]:  # integer, unsigned, float
                logger.debug("–ú–∞—Å—Å–∏–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ-—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
                non_zero_std = (
                    features_array.shape[2] if features_array.ndim > 2 else features_array.shape[1]
                )
                feature_std = None
            else:
                feature_std = np.std(features_sample, axis=0)
                non_zero_std = np.sum(feature_std > 1e-6)
        except (TypeError, ValueError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            # Fallback - –ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑ std
            non_zero_std = (
                features_array.shape[2] if features_array.ndim > 2 else features_array.shape[1]
            )
            feature_std = None

        logger.info(f"üìä ML –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {symbol}: shape={features_array.shape}")
        logger.info(
            f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π: {non_zero_std}/{features_array.shape[2]}"
        )
        if feature_std is not None:
            logger.debug(
                f"   –î–∏—Å–ø–µ—Ä—Å–∏—è: min={feature_std.min():.6f}, max={feature_std.max():.6f}, mean={feature_std.mean():.6f}"
            )
        else:
            logger.debug("   –î–∏—Å–ø–µ—Ä—Å–∏—è: –Ω–µ –≤—ã—á–∏—Å–ª–µ–Ω–∞ (–Ω–µ-—á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)")

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "symbol": symbol,
            "last_timestamp": ohlcv_df.index[-1],
            "last_price": float(ohlcv_df["close"].iloc[-1]),
            "lookback": lookback,
            "features_count": features_array.shape[2],
            "non_zero_variance_features": int(non_zero_std),
        }

        return features_array, metadata
