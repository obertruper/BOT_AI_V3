#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Real-time —Ä–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
"""

import asyncio
from datetime import datetime, timezone
from decimal import Decimal
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sqlalchemy import desc, select
from sqlalchemy.dialects.postgresql import insert

from core.logger import setup_logger
from database.connections import get_async_db
from database.models.market_data import ProcessedMarketData, RawMarketData
from ml.logic.feature_engineering import FeatureEngineer

logger = setup_logger(__name__)


class RealTimeIndicatorCalculator:
    """
    –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
    """

    def __init__(self, cache_ttl: int = 900, config: Optional[Dict[str, Any]] = None):
        """
        Args:
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        """
        self.feature_engineer = FeatureEngineer(config or {})
        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å async –æ–ø–µ—Ä–∞—Ü–∏–∏
        self.feature_engineer.disable_progress = False  # –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        self.cache = {}  # –ö–µ—à —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        self.cache_ttl = cache_ttl
        self._lock = asyncio.Lock()

        logger.info("RealTimeIndicatorCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    async def calculate_indicators(
        self, symbol: str, ohlcv_df: pd.DataFrame, save_to_db: bool = True
    ) -> Dict[str, Any]:
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

        Args:
            symbol: –¢–æ—Ä–≥–æ–≤—ã–π —Å–∏–º–≤–æ–ª
            ohlcv_df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∏–Ω–∏–º—É–º 240 —Å–≤–µ—á–µ–π)
            save_to_db: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        try:
            logger.info(f"üîç Starting calculate_indicators for {symbol}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            cache_key = f"{symbol}_{ohlcv_df.index[-1]}"
            cached_result = self._get_from_cache(cache_key)
            if cached_result:
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫–µ—à –¥–ª—è {symbol}")
                return cached_result

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            if len(ohlcv_df) < 96:
                logger.warning(
                    f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(ohlcv_df)} < 96"
                )
                return {}

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á–µ—Ä–µ–∑ FeatureEngineer
            logger.info(f"–†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol} –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏...")

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            logger.info(f"About to call create_features for {symbol}")
            features_result = self.feature_engineer.create_features(df)
            logger.info(
                f"create_features returned type: {type(features_result)}, shape: {getattr(features_result, 'shape', 'no shape')}"
            )

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ç feature_engineering_v2
            if isinstance(features_result, pd.DataFrame):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–∏—Å–∫–ª—é—á–∞–µ–º datetime, symbol –∏ –¥—Ä—É–≥–∏–µ –Ω–µ-—á–∏—Å–ª–æ–≤—ã–µ)
                numeric_cols = features_result.select_dtypes(
                    include=[np.number]
                ).columns.tolist()
                features_array = features_result[numeric_cols].values
                feature_names = numeric_cols
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
                feature_names = [f"feature_{i}" for i in range(features_array.shape[1])]
            else:
                logger.error(
                    f"create_features returned unexpected type: {type(features_result)}"
                )
                return {}

            # feature_names —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –≤—ã—à–µ

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array, –∑–∞—Ç–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dict
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[
                    -1
                ]  # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ numpy array
                current_features = {
                    feature_names[i]: float(last_features[i])
                    for i in range(len(last_features))
                }
            else:
                logger.error(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}"
                )
                return {}

            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = self._structure_indicators(current_features, ohlcv_df)

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            result["metadata"] = {
                "symbol": symbol,
                "timestamp": int(ohlcv_df.index[-1].timestamp() * 1000),
                "datetime": ohlcv_df.index[-1],
                "features_count": len(current_features),
                "calculation_time": datetime.now(timezone.utc),
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if save_to_db:
                await self._save_to_database(symbol, result)

            # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self._add_to_cache(cache_key, result)

            logger.info(f"–†–∞—Å—Å—á–∏—Ç–∞–Ω–æ {len(current_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}")

            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol}: {e}")
            return {}

    async def calculate_indicators_batch(
        self, symbols: List[str], ohlcv_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, Dict[str, Any]]:
        """
        –ü–∞–∫–µ—Ç–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
            ohlcv_data: –°–ª–æ–≤–∞—Ä—å {symbol: DataFrame}

        Returns:
            –°–ª–æ–≤–∞—Ä—å {symbol: indicators}
        """
        results = {}

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
        tasks = []
        for symbol in symbols:
            if symbol in ohlcv_data:
                task = self.calculate_indicators(symbol, ohlcv_data[symbol])
                tasks.append((symbol, task))

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–∞—Å—á–µ—Ç–æ–≤
        for symbol, task in tasks:
            try:
                result = await task
                results[symbol] = result
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–ª—è {symbol}: {e}")
                results[symbol] = {}

        return results

    def _prepare_dataframe(
        self, ohlcv_df: pd.DataFrame, symbol: str = "BTCUSDT"
    ) -> pd.DataFrame:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç DataFrame –¥–ª—è FeatureEngineer
        """
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –µ—Å—Ç—å –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = ["open", "high", "low", "close", "volume"]

        df = ohlcv_df.copy()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        for col in required_columns:
            if col not in df.columns:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if "turnover" not in df.columns:
            df["turnover"] = df["close"] * df["volume"]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É symbol (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "symbol" not in df.columns:
            df["symbol"] = symbol

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ datetime –∫–æ–ª–æ–Ω–∫–∏ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è FeatureEngineer)
        if "datetime" in df.columns:
            # –ï—Å–ª–∏ datetime —É–∂–µ –µ—Å—Ç—å –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
            pass
        elif hasattr(df.index, "name") and df.index.name == "datetime":
            # –ï—Å–ª–∏ datetime —ç—Ç–æ –∏–º—è –∏–Ω–¥–µ–∫—Å–∞, –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ –∫–æ–ª–æ–Ω–∫—É
            df = df.reset_index()
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç datetime –Ω–∏ –∫–∞–∫ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∏ –∫–∞–∫ –∏–Ω–¥–µ–∫—Å–∞, —Å–æ–∑–¥–∞–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            df["datetime"] = df.index

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        df = df.sort_index()

        return df

    def _structure_indicators(
        self, features: Dict[str, float], ohlcv_df: pd.DataFrame
    ) -> Dict[str, Any]:
        """
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
        """
        # –ë–∞–∑–æ–≤—ã–µ OHLCV
        last_candle = ohlcv_df.iloc[-1]

        result = {
            "ohlcv": {
                "open": float(last_candle["open"]),
                "high": float(last_candle["high"]),
                "low": float(last_candle["low"]),
                "close": float(last_candle["close"]),
                "volume": float(last_candle["volume"]),
            }
        }

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        technical_indicators = {}
        microstructure_features = {}
        ml_features = features.copy()

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        tech_indicators_list = [
            "sma_",
            "ema_",
            "rsi_",
            "macd_",
            "bb_",
            "atr_",
            "stoch_",
            "adx_",
            "cci_",
            "williams_",
            "mfi_",
            "obv",
        ]

        for key, value in features.items():
            for indicator in tech_indicators_list:
                if key.startswith(indicator):
                    technical_indicators[key] = value
                    break

            # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if any(x in key for x in ["spread", "imbalance", "pressure", "flow"]):
                microstructure_features[key] = value

        result["technical_indicators"] = technical_indicators
        result["microstructure_features"] = microstructure_features
        result["ml_features"] = ml_features

        return result

    async def _save_to_database(self, symbol: str, indicators: Dict[str, Any]):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            async with get_async_db() as session:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –∏–∑ raw_market_data
                stmt = (
                    select(RawMarketData)
                    .where(RawMarketData.symbol == symbol)
                    .order_by(desc(RawMarketData.timestamp))
                    .limit(1)
                )

                result = await session.execute(stmt)
                raw_data = result.scalar_one_or_none()

                if not raw_data:
                    logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã raw –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
                    return

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                metadata = indicators.get("metadata", {})
                ohlcv = indicators.get("ohlcv", {})

                processed_data = {
                    "raw_data_id": raw_data.id,
                    "symbol": symbol,
                    "timestamp": metadata.get("timestamp", raw_data.timestamp),
                    "datetime": metadata.get("datetime", raw_data.datetime),
                    "open": Decimal(str(ohlcv.get("open", raw_data.open))),
                    "high": Decimal(str(ohlcv.get("high", raw_data.high))),
                    "low": Decimal(str(ohlcv.get("low", raw_data.low))),
                    "close": Decimal(str(ohlcv.get("close", raw_data.close))),
                    "volume": Decimal(str(ohlcv.get("volume", raw_data.volume))),
                    "technical_indicators": indicators.get("technical_indicators", {}),
                    "microstructure_features": indicators.get(
                        "microstructure_features", {}
                    ),
                    "ml_features": indicators.get("ml_features", {}),
                    "processing_version": "2.0",  # Real-time –≤–µ—Ä—Å–∏—è
                    "model_version": "patchtst_v1",
                }

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert
                stmt = insert(ProcessedMarketData).values(**processed_data)
                stmt = stmt.on_conflict_do_update(
                    constraint="_symbol_timestamp_processed_uc",
                    set_={
                        "technical_indicators": stmt.excluded.technical_indicators,
                        "microstructure_features": stmt.excluded.microstructure_features,
                        "ml_features": stmt.excluded.ml_features,
                        "updated_at": datetime.now(timezone.utc),
                    },
                )

                await session.execute(stmt)
                await session.commit()

                logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol} –≤ –ë–î")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î –¥–ª—è {symbol}: {e}")

    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∞ –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã"""
        if cache_key not in self.cache:
            return None

        cached_data, timestamp = self.cache[cache_key]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
        if (datetime.now(timezone.utc) - timestamp).total_seconds() > self.cache_ttl:
            del self.cache[cache_key]
            return None

        return cached_data

    def _add_to_cache(self, cache_key: str, data: Dict[str, Any]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫–µ—à"""
        self.cache[cache_key] = (data, datetime.now(timezone.utc))

        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –µ—Å–ª–∏ –∫–µ—à —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
        if len(self.cache) > 100:
            self._cleanup_cache()

    def _cleanup_cache(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫–µ—à–∞"""
        current_time = datetime.now(timezone.utc)
        keys_to_remove = []

        for key, (data, timestamp) in self.cache.items():
            if (current_time - timestamp).total_seconds() > self.cache_ttl:
                keys_to_remove.append(key)

        for key in keys_to_remove:
            del self.cache[key]

    async def get_features_for_ml(
        self, symbol: str, ohlcv_df: pd.DataFrame
    ) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ

        Returns:
            Numpy –º–∞—Å—Å–∏–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ FeatureEngineer –±–µ–∑ async
            logger.info(
                f"üöÄ get_features_for_ml: Direct feature calculation for {symbol}"
            )

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
            df = self._prepare_dataframe(ohlcv_df, symbol)

            # –ü—Ä—è–º–æ –≤—ã–∑—ã–≤–∞–µ–º create_features (—ç—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
            features_result = self.feature_engineer.create_features(df)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ - –º–æ–∂–µ—Ç –±—ã—Ç—å DataFrame –∏–ª–∏ numpy array
            if isinstance(features_result, pd.DataFrame):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                numeric_cols = features_result.select_dtypes(
                    include=[np.number]
                ).columns.tolist()
                features_array = features_result[numeric_cols].values
            elif isinstance(features_result, np.ndarray):
                features_array = features_result
            else:
                logger.error(
                    f"create_features returned {type(features_result)}, expected DataFrame or np.ndarray"
                )
                return np.array([])

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞
            if features_array.ndim == 2 and features_array.shape[0] > 0:
                last_features = features_array[-1]  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞
                logger.info(
                    f"‚úÖ get_features_for_ml: Extracted {len(last_features)} features for {symbol}"
                )
                return last_features
            else:
                logger.error(
                    f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ features_array: {features_array.shape}"
                )
                return np.array([])

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ get_features_for_ml –¥–ª—è {symbol}: {e}")
            return np.array([])

    async def prepare_ml_input(
        self, symbol: str, ohlcv_df: pd.DataFrame, lookback: int = 96
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML –º–æ–¥–µ–ª–∏

        Args:
            symbol: –°–∏–º–≤–æ–ª
            ohlcv_df: OHLCV –¥–∞–Ω–Ω—ã–µ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∏–Ω–∏–º—É–º lookback + 144 —Å–≤–µ—á–µ–π)
            lookback: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –º–æ–¥–µ–ª–∏

        Returns:
            (features_array, metadata)
        """
        if len(ohlcv_df) < lookback:  # –ú–∏–Ω–∏–º—É–º –Ω—É–∂–Ω–æ lookback —Å–≤–µ—á–µ–π
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)} < {lookback}")

        # –ü–†–ê–í–ò–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame —Å—Ä–∞–∑—É
        # FeatureEngineer —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å rolling windows
        logger.info(f"üîÑ –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol}, –¥–∞–Ω–Ω—ã—Ö: {len(ohlcv_df)}")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º DataFrame
        df = self._prepare_dataframe(ohlcv_df, symbol)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—Å–µ–≥–æ DataFrame
        # FeatureEngineer –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ (n_samples, n_features)
        features_result = self.feature_engineer.create_features(df)

        if isinstance(features_result, pd.DataFrame):
            # –ï—Å–ª–∏ DataFrame, –±–µ—Ä–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            numeric_cols = features_result.select_dtypes(
                include=[np.number]
            ).columns.tolist()
            features_array = features_result[numeric_cols].values
        elif isinstance(features_result, np.ndarray):
            features_array = features_result
        else:
            raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(features_result)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
        if features_array.ndim != 2:
            raise ValueError(
                f"–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {features_array.shape}"
            )

        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
        if len(features_array) < lookback:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ, –¥–æ–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            padding_size = lookback - len(features_array)
            padding = np.tile(features_array[0], (padding_size, 1))
            features_array = np.vstack([padding, features_array])
        else:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback —Ç–æ—á–µ–∫
            features_array = features_array[-lookback:]

        # –î–æ–±–∞–≤–ª—è–µ–º batch dimension: (lookback, features) -> (1, lookback, features)
        features_array = features_array.reshape(1, lookback, -1)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_std = np.std(features_array[0], axis=0)
        non_zero_std = np.sum(feature_std > 1e-6)

        logger.info(f"üìä ML –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {symbol}: shape={features_array.shape}")
        logger.info(
            f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–µ–Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π: {non_zero_std}/{features_array.shape[2]}"
        )
        logger.debug(
            f"   –î–∏—Å–ø–µ—Ä—Å–∏—è: min={feature_std.min():.6f}, max={feature_std.max():.6f}, mean={feature_std.mean():.6f}"
        )

        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            "symbol": symbol,
            "last_timestamp": ohlcv_df.index[-1],
            "last_price": float(ohlcv_df["close"].iloc[-1]),
            "lookback": lookback,
            "features_count": features_array.shape[2],
            "non_zero_variance_features": int(non_zero_std),
        }

        return features_array, metadata
