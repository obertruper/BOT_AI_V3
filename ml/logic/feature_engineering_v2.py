"""
–ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö - BOT_AI_V3 –≤–µ—Ä—Å–∏—è
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω –∏–∑ LLM TRANSFORM –ø—Ä–æ–µ–∫—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
- RobustScaler –≤–º–µ—Å—Ç–æ StandardScaler
- Walk-forward validation
- Crypto-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ NaN/Inf
"""

import warnings

import numpy as np
import pandas as pd
import ta
from sklearn.preprocessing import RobustScaler
from tqdm import tqdm

# –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º

warnings.filterwarnings("ignore")

# BOT_AI_V3 imports
from core.logger import setup_logger


class FeatureEngineer:
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è - BOT_AI_V3 –≤–µ—Ä—Å–∏—è"""

    def __init__(self, config: dict, inference_mode: bool = False):
        self.config = config
        self.logger = setup_logger(__name__)
        self.feature_config = config.get("features", {})
        self.scalers = {}
        self.process_position = None  # –ü–æ–∑–∏—Ü–∏—è –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤ –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
        self.disable_progress = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤

        # –°—Ä–∞–∑—É –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –µ—Å–ª–∏ inference_mode –≤–∫–ª—é—á–µ–Ω
        if inference_mode:
            try:
                from ml.config.features_240 import REQUIRED_FEATURES_240

                self._required_features = REQUIRED_FEATURES_240
                self.logger.info(
                    f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ø–∏—Å–æ–∫ –∏–∑ {len(REQUIRED_FEATURES_240)} —Ç—Ä–µ–±—É–µ–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference mode"
                )
            except ImportError:
                self.logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å REQUIRED_FEATURES_240")
                self._required_features = None

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥—ã-–∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∫–æ–¥–æ–º
        if not hasattr(self.logger, "start_stage"):
            self.logger.start_stage = lambda *args, **kwargs: self.logger.info(
                f"Starting stage: {args[0] if args else 'unknown'}"
            )
        if not hasattr(self.logger, "end_stage"):
            self.logger.end_stage = lambda *args, **kwargs: self.logger.info(
                f"Completed stage: {args[0] if args else 'unknown'}"
            )

    @staticmethod
    def safe_divide(
        numerator: pd.Series,
        denominator: pd.Series,
        fill_value=0.0,
        max_value=1000.0,
        min_denominator=1e-8,
    ) -> pd.Series:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –º–∞–ª—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å
        safe_denominator = denominator.copy()

        # –ó–∞–º–µ–Ω—è–µ–º –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        mask_small = safe_denominator.abs() < min_denominator
        safe_denominator[mask_small] = min_denominator

        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–ª–µ–Ω–∏–µ
        result = numerator / safe_denominator

        # –ö–ª–∏–ø–ø–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        result = result.clip(lower=-max_value, upper=max_value)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ inf –∏ nan
        result = result.replace([np.inf, -np.inf], [fill_value, fill_value])
        result = result.fillna(fill_value)

        return result

    def calculate_vwap(self, df: pd.DataFrame) -> pd.Series:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç VWAP —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç VWAP
        vwap = self.safe_divide(df["turnover"], df["volume"], fill_value=df["close"])

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: VWAP –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç close
        # –ï—Å–ª–∏ VWAP —Å–ª–∏—à–∫–æ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç close (–±–æ–ª–µ–µ —á–µ–º –≤ 2 —Ä–∞–∑–∞), –∏—Å–ø–æ–ª—å–∑—É–µ–º close
        mask_invalid = (vwap < df["close"] * 0.5) | (vwap > df["close"] * 2.0)
        vwap[mask_invalid] = df["close"][mask_invalid]

        return vwap

    def create_features(
        self,
        df: pd.DataFrame,
        train_end_date: str | None = None,
        use_enhanced_features: bool = False,
        inference_mode: bool = False,
    ) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å walk-forward –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π

        Args:
            df: DataFrame —Å raw –¥–∞–Ω–Ω—ã–º–∏
            train_end_date: –¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è walk-forward –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            use_enhanced_features: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è direction prediction
            inference_mode: –µ—Å–ª–∏ True, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è inference
        """
        if not self.disable_progress:
            mode_str = " (inference mode - 240 features)" if inference_mode else ""
            self.logger.info(
                f"üîß –ù–∞—á–∏–Ω–∞–µ–º feature engineering –¥–ª—è {df['symbol'].nunique()} —Å–∏–º–≤–æ–ª–æ–≤{mode_str}"
            )

        # –í inference mode –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        if inference_mode and not hasattr(self, "_required_features"):
            try:
                from ml.config.features_240 import REQUIRED_FEATURES_240

                self._required_features = REQUIRED_FEATURES_240
            except ImportError:
                self.logger.warning(
                    "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å REQUIRED_FEATURES_240, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
                )
                inference_mode = False
                self._required_features = None

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        self._validate_data(df)

        featured_dfs = []
        all_symbols_data = {}  # –î–ª—è enhanced features

        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ - –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for symbol in df["symbol"].unique():
            symbol_data = df[df["symbol"] == symbol].copy()
            symbol_data = symbol_data.sort_values("datetime")

            symbol_data = self._create_basic_features(symbol_data)
            symbol_data = self._create_technical_indicators(symbol_data)
            symbol_data = self._create_microstructure_features(symbol_data)
            symbol_data = self._create_rally_detection_features(symbol_data)
            symbol_data = self._create_signal_quality_features(symbol_data)
            symbol_data = self._create_futures_specific_features(symbol_data)
            symbol_data = self._create_ml_optimized_features(symbol_data)
            symbol_data = self._create_temporal_features(symbol_data)
            symbol_data = self._create_target_variables(symbol_data)

            featured_dfs.append(symbol_data)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è enhanced features
            if use_enhanced_features:
                all_symbols_data[symbol] = symbol_data.copy()

        result_df = pd.concat(featured_dfs, ignore_index=True)

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: cross-asset features –Ω—É–∂–Ω—ã –≤—Å–µ —Å–∏–º–≤–æ–ª—ã, –Ω–æ –µ—Å–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ –æ–¥–Ω–æ–º—É - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        # –ï—Å–ª–∏ –≤ df –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ - —Å–æ–∑–¥–∞–µ–º cross-asset features
        if df["symbol"].nunique() > 1:
            result_df = self._create_cross_asset_features(result_df)

        # –î–æ–±–∞–≤–ª—è–µ–º enhanced features –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
        if use_enhanced_features:
            result_df = self._add_enhanced_features(result_df, all_symbols_data)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π
        result_df = self._handle_missing_values(result_df)

        # Walk-forward –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –¥–∞—Ç–∞ (–∏–Ω–∞—á–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç –≤ prepare_trading_data.py)
        if train_end_date:
            result_df = self._normalize_walk_forward(result_df, train_end_date)

        # –í inference mode –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if inference_mode and hasattr(self, "_required_features"):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_cols = ["symbol", "datetime", "open", "high", "low", "close", "volume"]
            keep_cols = metadata_cols.copy()

            if not self.disable_progress:
                self.logger.info(
                    f"üîß Inference mode –∞–∫—Ç–∏–≤–µ–Ω: —Ç—Ä–µ–±—É–µ—Ç—Å—è {len(self._required_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
                )
                self.logger.info(f"üîß –î–æ—Å—Ç—É–ø–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: {len(result_df.columns)}")

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ REQUIRED_FEATURES_240, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ DataFrame
            missing_features = []
            for feature in self._required_features:
                if feature in result_df.columns:
                    keep_cols.append(feature)
                else:
                    # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                    result_df[feature] = 0.0
                    keep_cols.append(feature)
                    missing_features.append(feature)

            if missing_features and not self.disable_progress:
                self.logger.warning(
                    f"üîß –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(missing_features)}): {missing_features[:10]}..."
                )

            # –§–∏–ª—å—Ç—Ä—É–µ–º DataFrame
            result_df = result_df[keep_cols]

            if not self.disable_progress:
                self.logger.info(
                    f"üìä Inference mode: –æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(keep_cols) - len(metadata_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {len(self._required_features)} —Ç—Ä–µ–±—É–µ–º—ã—Ö"
                )
        elif inference_mode and not hasattr(self, "_required_features"):
            self.logger.error("‚ùå Inference mode –≤–∫–ª—é—á–µ–Ω, –Ω–æ _required_features –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!")

        self._log_feature_statistics(result_df)

        if not self.disable_progress:
            feature_count = (
                len(result_df.columns) - 7 if inference_mode else len(result_df.columns)
            )  # –í—ã—á–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.logger.info(
                f"‚úÖ Feature engineering –∑–∞–≤–µ—Ä—à–µ–Ω. –°–æ–∑–¥–∞–Ω–æ {feature_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(result_df)} –∑–∞–ø–∏—Å–µ–π"
            )

        return result_df

    def _validate_data(self, df: pd.DataFrame):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
        numeric_columns = ["open", "high", "low", "close", "volume", "turnover"]
        for col in numeric_columns:
            if col in df.columns:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø, –∑–∞–º–µ–Ω—è—è –æ—à–∏–±–∫–∏ –Ω–∞ NaN
                df[col] = pd.to_numeric(df[col], errors="coerce")
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                df[col] = df[col].ffill().bfill()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        if df.isnull().any().any():
            if not self.disable_progress:
                self.logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã
        price_changes = df.groupby("symbol")["close"].pct_change()
        extreme_moves = abs(price_changes) > 0.15  # >15% –∑–∞ 15 –º–∏–Ω—É—Ç

        if extreme_moves.sum() > 0:
            if not self.disable_progress:
                self.logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {extreme_moves.sum()} —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π —Ü–µ–Ω—ã")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≥—ç–ø–æ–≤ (—Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑—Ä—ã–≤—ã > 2 —á–∞—Å–æ–≤)
        for symbol in df["symbol"].unique():
            symbol_data = df[df["symbol"] == symbol]
            time_diff = symbol_data["datetime"].diff()
            expected_diff = pd.Timedelta("15 minutes")
            # –°—á–∏—Ç–∞–µ–º –±–æ–ª—å—à–∏–º–∏ —Ç–æ–ª—å–∫–æ —Ä–∞–∑—Ä—ã–≤—ã –±–æ–ª—å—à–µ 2 —á–∞—Å–æ–≤ (8 –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤)
            large_gaps = time_diff > expected_diff * 8

            if large_gaps.sum() > 0:
                if not self.disable_progress:
                    self.logger.warning(
                        f"–°–∏–º–≤–æ–ª {symbol}: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ {large_gaps.sum()} –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–∑—Ä—ã–≤–æ–≤ (> 2 —á–∞—Å–æ–≤)"
                    )

    def _create_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ OHLCV –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ look-ahead bias"""
        df["returns"] = np.log(df["close"] / df["close"].shift(1))

        # –î–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∑–∞ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã (–†–ê–°–®–ò–†–ï–ù–û –¥–ª—è REQUIRED_FEATURES_240)
        returns_periods = [1, 2, 3, 5, 10, 15, 20, 30, 45, 60, 90, 120]
        for period in returns_periods:
            df[f"returns_{period}"] = np.log(df["close"] / df["close"].shift(period))

        # –¶–µ–Ω–æ–≤—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        df["high_low_ratio"] = df["high"] / df["low"]
        df["close_open_ratio"] = df["close"] / df["open"]

        # –ü–æ–∑–∏—Ü–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        df["close_position"] = (df["close"] - df["low"]) / (df["high"] - df["low"] + 1e-10)

        # –û–±—ä–µ–º–Ω—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        df["volume_ratio"] = self.safe_divide(
            df["volume"], df["volume"].rolling(20, min_periods=20).mean(), fill_value=1.0
        )
        df["turnover_ratio"] = self.safe_divide(
            df["turnover"], df["turnover"].rolling(20, min_periods=20).mean(), fill_value=1.0
        )

        # VWAP —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ä–∞—Å—á–µ—Ç–æ–º
        df["vwap"] = self.calculate_vwap(df)

        # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Ä–∞—Å—á–µ—Ç close_vwap_ratio
        # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ close/vwap –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–∫–æ–ª–æ 1.0
        # VWAP —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –≤ calculate_vwap()

        # –ü—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π —Ä–∞—Å—á–µ—Ç
        df["close_vwap_ratio"] = df["close"] / df["vwap"]

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç (¬±30%)
        # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –º–æ–≥—É—Ç –æ—Ç–∫–ª–æ–Ω—è—Ç—å—Å—è –æ—Ç VWAP –Ω–∞ 20-50% –≤ –ø–µ—Ä–∏–æ–¥—ã –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        df["close_vwap_ratio"] = df["close_vwap_ratio"].clip(lower=0.7, upper=1.3)

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç VWAP
        df["vwap_extreme_deviation"] = (
            (df["close_vwap_ratio"] < 0.85) | (df["close_vwap_ratio"] > 1.15)
        ).astype(int)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏
        # –ï—Å–ª–∏ ratio –≤—Å–µ –µ—â–µ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ 1.0
        mask_invalid = (df["close_vwap_ratio"] < 0.95) | (df["close_vwap_ratio"] > 1.05)
        if mask_invalid.sum() > 0:
            self.logger.debug(f"–ó–∞–º–µ–Ω–µ–Ω–æ {mask_invalid.sum()} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö close_vwap_ratio –Ω–∞ 1.0")
            df.loc[mask_invalid, "close_vwap_ratio"] = 1.0

        return df

    def _create_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –í–°–ï —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–∑ REQUIRED_FEATURES_240"""

        # ========== RSI - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        rsi_periods = [5, 14, 21]  # –ò–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ features_240.py
        for period in rsi_periods:
            rsi_indicator = ta.momentum.RSIIndicator(df["close"], window=period)
            df[f"rsi_{period}"] = rsi_indicator.rsi()

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ RSI –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        for period in [7, 30, 50, 70, 100]:
            rsi_indicator = ta.momentum.RSIIndicator(df["close"], window=period)
            df[f"rsi_{period}"] = rsi_indicator.rsi()

        # ========== SMA - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        sma_periods = [5, 10, 20, 50, 100, 200]  # –ò–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ features_240.py
        for period in sma_periods:
            df[f"sma_{period}"] = ta.trend.sma_indicator(df["close"], period)

        # ========== EMA - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        ema_periods = [5, 10, 20, 50, 100, 200]  # –ò–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ features_240.py
        for period in ema_periods:
            df[f"ema_{period}"] = ta.trend.ema_indicator(df["close"], period)
            # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ü–µ–Ω—ã –¥–æ EMA (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ)
            df[f"ema_distance_{period}"] = self.safe_divide(
                df["close"] - df[f"ema_{period}"], df["close"], fill_value=0.0
            )

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ EMA –ø–µ—Ä–∏–æ–¥—ã
        for period in [15, 30, 150, 250]:
            df[f"ema_{period}"] = ta.trend.ema_indicator(df["close"], period)
            df[f"ema_distance_{period}"] = self.safe_divide(
                df["close"] - df[f"ema_{period}"], df["close"], fill_value=0.0
            )

        # ========== MACD - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ==========
        macd_configs = [
            (5, 13, 5),  # –ë—ã—Å—Ç—Ä—ã–π MACD
            (5, 35, 5),  # –¢–†–ï–ë–£–ï–¢–°–Ø: –¥–ª—è REQUIRED_FEATURES_240
            (8, 21, 5),  # –°—Ä–µ–¥–Ω–∏–π MACD
            (12, 26, 9),  # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π MACD
            (19, 39, 9),  # –ú–µ–¥–ª–µ–Ω–Ω—ã–π MACD
            (50, 100, 20),  # –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π MACD
        ]

        for fast, slow, signal in macd_configs:
            macd = ta.trend.MACD(
                df["close"], window_fast=fast, window_slow=slow, window_sign=signal
            )
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º MACD –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—ã
            df[f"macd_{fast}_{slow}"] = self.safe_divide(macd.macd(), df["close"], fill_value=0.0)
            df[f"macd_signal_{fast}_{slow}"] = self.safe_divide(
                macd.macd_signal(), df["close"], fill_value=0.0
            )
            df[f"macd_hist_{fast}_{slow}"] = self.safe_divide(
                macd.macd_diff(), df["close"], fill_value=0.0
            )

        # ========== Bollinger Bands - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        bb_periods = [10, 20, 30, 50, 100]
        for period in bb_periods:
            bb = ta.volatility.BollingerBands(df["close"], window=period, window_dev=2)
            df[f"bb_upper_{period}"] = bb.bollinger_hband()
            df[f"bb_middle_{period}"] = bb.bollinger_mavg()
            df[f"bb_lower_{period}"] = bb.bollinger_lband()

            # BB width (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è)
            df[f"bb_width_{period}"] = self.safe_divide(
                bb.bollinger_hband() - bb.bollinger_lband(), df["close"], fill_value=0.02
            )

            # BB position (–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ü–µ–Ω–∞ –≤–Ω—É—Ç—Ä–∏ –ø–æ–ª–æ—Å)
            bb_range = bb.bollinger_hband() - bb.bollinger_lband()
            df[f"bb_position_{period}"] = self.safe_divide(
                df["close"] - bb.bollinger_lband(), bb_range, fill_value=0.5
            ).clip(0, 1)

        # ========== ATR - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        atr_periods = [7, 14, 21, 30, 50, 100]
        for period in atr_periods:
            atr = ta.volatility.AverageTrueRange(df["high"], df["low"], df["close"], window=period)
            df[f"atr_{period}"] = atr.average_true_range()

        # ========== ADX - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        adx_periods = [14, 21, 20, 30]  # –î–æ–±–∞–≤–ª–µ–Ω –ø–µ—Ä–∏–æ–¥ 21 –¥–ª—è REQUIRED_FEATURES_240
        for period in adx_periods:
            adx = ta.trend.ADXIndicator(df["high"], df["low"], df["close"], window=period)
            df[f"adx_{period}"] = adx.adx()
            df[f"plus_di_{period}"] = adx.adx_pos()
            df[f"minus_di_{period}"] = adx.adx_neg()
            df[f"dx_{period}"] = df[f"plus_di_{period}"] - df[f"minus_di_{period}"]

        # ========== CCI - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        cci_periods = [14, 20, 30]
        for period in cci_periods:
            cci = ta.trend.CCIIndicator(df["high"], df["low"], df["close"], window=period)
            df[f"cci_{period}"] = cci.cci()

        # ========== Stochastic - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        stoch_configs = [(14, 3), (21, 3)]  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ 3 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        for k_period, d_period in stoch_configs:
            stoch = ta.momentum.StochasticOscillator(
                df["high"], df["low"], df["close"], window=k_period, smooth_window=d_period
            )
            df[f"stoch_k_{k_period}"] = stoch.stoch()  # –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±–∏—Ä–∞–µ–º d_period –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            df[f"stoch_d_{k_period}"] = (
                stoch.stoch_signal()
            )  # –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±–∏—Ä–∞–µ–º d_period –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ stochastic —Å –ø–µ—Ä–∏–æ–¥–æ–º 21 –¥–ª—è D-–ª–∏–Ω–∏–∏
        stoch_21 = ta.momentum.StochasticOscillator(
            df["high"], df["low"], df["close"], window=21, smooth_window=3
        )
        df["stoch_k_21"] = stoch_21.stoch()
        df["stoch_d_21"] = stoch_21.stoch_signal()

        # ========== Williams %R - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        willr_periods = [14, 21, 28]
        for period in willr_periods:
            willr = ta.momentum.WilliamsRIndicator(df["high"], df["low"], df["close"], lbp=period)
            df[f"williams_r_{period}"] = willr.williams_r()

        # –î–û–ë–ê–í–õ–ï–ù–û: Williams %R –¥–ª—è –≤—Å–µ—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏–∑ REQUIRED_FEATURES_240

        # ========== MFI - –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–∏–æ–¥—ã ==========
        mfi_periods = [14, 21, 20, 30]  # –î–æ–±–∞–≤–ª–µ–Ω –ø–µ—Ä–∏–æ–¥ 21 –¥–ª—è REQUIRED_FEATURES_240
        for period in mfi_periods:
            mfi = ta.volume.MFIIndicator(
                df["high"], df["low"], df["close"], df["volume"], window=period
            )
            df[f"mfi_{period}"] = mfi.money_flow_index()

        # ========== OBV –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ ==========
        obv = ta.volume.OnBalanceVolumeIndicator(df["close"], df["volume"])
        df["obv"] = obv.on_balance_volume()

        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π OBV
        df["obv_norm"] = self.safe_divide(
            df["obv"] - df["obv"].rolling(50).mean(), df["obv"].rolling(50).std(), fill_value=0.0
        )

        # OBV SMA –∏ EMA
        df["obv_sma_20"] = ta.trend.sma_indicator(df["obv"], 20)
        df["obv_ema_20"] = ta.trend.ema_indicator(df["obv"], 20)

        # ========== –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ==========

        # Aroon
        for period in [14, 25]:
            aroon = ta.trend.AroonIndicator(df["high"], df["low"], window=period)
            df[f"aroon_up_{period}"] = aroon.aroon_up()
            df[f"aroon_down_{period}"] = aroon.aroon_down()

        # DPO (Detrended Price Oscillator)
        for period in [14, 20]:
            dpo = ta.trend.DPOIndicator(df["close"], window=period)
            df[f"dpo_{period}"] = dpo.dpo()

        # CMO (Chande Momentum Oscillator)
        for period in [14, 20]:
            cmo = ta.momentum.PercentageVolumeOscillator(
                df["volume"], window_slow=period * 2, window_fast=period
            )
            df[f"cmo_{period}"] = cmo.pvo()

        # ROC (Rate of Change)
        for period in [10, 20, 30, 50]:
            roc = ta.momentum.ROCIndicator(df["close"], window=period)
            df[f"roc_{period}"] = roc.roc()

        # RVI (Relative Vigor Index)
        for period in [10, 14]:
            # –ü—Ä–æ—Å—Ç–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è RVI
            df[f"rvi_{period}"] = self.safe_divide(
                (df["close"] - df["open"]).rolling(period).mean(),
                (df["high"] - df["low"]).rolling(period).mean(),
                fill_value=0.0,
            )

        # TRIX
        for period in [14, 21, 30]:
            # –¢—Ä–æ–π–Ω–∞—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è
            ema1 = ta.trend.ema_indicator(df["close"], period)
            ema2 = ta.trend.ema_indicator(ema1, period)
            ema3 = ta.trend.ema_indicator(ema2, period)
            df[f"trix_{period}"] = ema3.pct_change()

        # PPO (Percentage Price Oscillator)
        ppo = ta.momentum.PercentagePriceOscillator(df["close"])
        df["ppo"] = ppo.ppo()
        df["ppo_signal"] = ppo.ppo_signal()
        df["ppo_hist"] = ppo.ppo_hist()

        # Mass Index
        mass_index = ta.trend.MassIndex(df["high"], df["low"])
        df["mass_index"] = mass_index.mass_index()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è crypto
        self._add_crypto_specific_indicators(df)

        return df

    def _add_crypto_specific_indicators(self, df: pd.DataFrame):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫—Ä–∏–ø—Ç–æ—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã"""

        # Stochastic
        stoch = ta.momentum.StochasticOscillator(
            df["high"], df["low"], df["close"], window=14, smooth_window=3
        )
        df["stoch_k"] = stoch.stoch()
        df["stoch_d"] = stoch.stoch_signal()

        # ADX
        adx = ta.trend.ADXIndicator(df["high"], df["low"], df["close"])
        df["adx_14"] = adx.adx()
        df["adx"] = df["adx_14"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        df["adx_pos"] = adx.adx_pos()
        df["adx_neg"] = adx.adx_neg()

        # Parabolic SAR
        psar = ta.trend.PSARIndicator(df["high"], df["low"], df["close"])
        df["psar"] = psar.psar()
        # –í–º–µ—Å—Ç–æ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö psar_up –∏ psar_down, —Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        df["psar_trend"] = (df["close"] > df["psar"]).astype(float)

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ PSAR –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –î–µ–ª–µ–Ω–∏–µ –Ω–∞ ATR –¥–µ–ª–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É —Å—Ä–∞–≤–Ω–∏–º–æ–π –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏
        df["psar_distance"] = (df["close"] - df["psar"]) / df["close"]
        if "atr" in df.columns:
            df["psar_distance_normalized"] = (df["close"] - df["psar"]) / (df["atr"] + 1e-10)
        else:
            df["psar_distance_normalized"] = df["psar_distance"]

        # ===== –ù–û–í–´–ï –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ (2024 best practices) =====

        # 1. Ichimoku Cloud - –ø–æ–ø—É–ª—è—Ä–Ω—ã–π –≤ –∫—Ä–∏–ø—Ç–æ
        try:
            ichimoku = ta.trend.IchimokuIndicator(
                high=df["high"],
                low=df["low"],
                window1=9,  # Tenkan-sen
                window2=26,  # Kijun-sen
                window3=52,  # Senkou Span B
            )
            df["ichimoku_tenkan"] = ichimoku.ichimoku_conversion_line()  # Tenkan-sen
            df["ichimoku_kijun"] = ichimoku.ichimoku_base_line()  # Kijun-sen
            df["ichimoku_conversion"] = df["ichimoku_tenkan"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["ichimoku_base"] = df["ichimoku_kijun"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["ichimoku_span_a"] = ichimoku.ichimoku_a()
            df["ichimoku_span_b"] = ichimoku.ichimoku_b()
            # –û–±–ª–∞–∫–æ - —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É span A –∏ B
            df["ichimoku_cloud_thickness"] = (df["ichimoku_span_a"] - df["ichimoku_span_b"]) / df[
                "close"
            ]
            # –ü–æ–∑–∏—Ü–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±–ª–∞–∫–∞
            df["price_vs_cloud"] = (
                df["close"] - (df["ichimoku_span_a"] + df["ichimoku_span_b"]) / 2
            ) / df["close"]
        except:
            pass

        # 2. Keltner Channels - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Bollinger Bands
        try:
            keltner = ta.volatility.KeltnerChannel(
                high=df["high"], low=df["low"], close=df["close"], window=20, window_atr=10
            )
            df["keltner_upper_20"] = keltner.keltner_channel_hband()
            df["keltner_middle_20"] = keltner.keltner_channel_mband()
            df["keltner_lower_20"] = keltner.keltner_channel_lband()
            df["keltner_position_20"] = (df["close"] - df["keltner_lower_20"]) / (
                df["keltner_upper_20"] - df["keltner_lower_20"]
            )
            # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["keltner_upper"] = df["keltner_upper_20"]
            df["keltner_middle"] = df["keltner_middle_20"]
            df["keltner_lower"] = df["keltner_lower_20"]
            df["keltner_position"] = df["keltner_position_20"]
        except:
            pass

        # 3. Donchian Channels - –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ—Ä—ã–≤–æ–≤
        try:
            donchian = ta.volatility.DonchianChannel(
                high=df["high"], low=df["low"], close=df["close"], window=20
            )
            df["donchian_upper_20"] = donchian.donchian_channel_hband()
            df["donchian_middle_20"] = donchian.donchian_channel_mband()
            df["donchian_lower_20"] = donchian.donchian_channel_lband()
            df["donchian_position_20"] = (df["close"] - df["donchian_lower_20"]) / (
                df["donchian_upper_20"] - df["donchian_lower_20"]
            )
            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ—Ä—ã–≤–∞
            df["donchian_breakout"] = (
                (df["close"] > df["donchian_upper_20"].shift(1))
                | (df["close"] < df["donchian_lower_20"].shift(1))
            ).astype(int)
            # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["donchian_upper"] = df["donchian_upper_20"]
            df["donchian_middle"] = df["donchian_middle_20"]
            df["donchian_lower"] = df["donchian_lower_20"]
        except:
            pass

        # 4. Volume Weighted Moving Average (VWMA)
        df["vwma_20"] = (df["close"] * df["volume"]).rolling(20).sum() / df["volume"].rolling(
            20
        ).sum()
        df["close_vwma_ratio"] = df["close"] / df["vwma_20"]

        # 5. Money Flow Index (MFI) - –æ–±—ä–µ–º–Ω—ã–π –æ—Å—Ü–∏–ª–ª—è—Ç–æ—Ä
        try:
            mfi = ta.volume.MFIIndicator(
                high=df["high"], low=df["low"], close=df["close"], volume=df["volume"], window=14
            )
            df["mfi_14"] = mfi.money_flow_index()
            df["mfi"] = df["mfi_14"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["mfi_overbought"] = (df["mfi"] > 80).astype(int)
            df["mfi_oversold"] = (df["mfi"] < 20).astype(int)
        except:
            pass

        # 6. Commodity Channel Index (CCI)
        try:
            cci = ta.trend.CCIIndicator(
                high=df["high"], low=df["low"], close=df["close"], window=20
            )
            df["cci_14"] = cci.cci()
            df["cci"] = df["cci_14"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            df["cci_overbought"] = (df["cci"] > 100).astype(int)
            df["cci_oversold"] = (df["cci"] < -100).astype(int)
        except:
            pass

        # 7. Williams %R
        try:
            williams = ta.momentum.WilliamsRIndicator(
                high=df["high"], low=df["low"], close=df["close"], lbp=14
            )
            df["williams_r_14"] = williams.williams_r()
            df["williams_r"] = df["williams_r_14"]  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        except:
            pass

        # 8. On Balance Volume (OBV)
        try:
            obv_indicator = ta.volume.OnBalanceVolumeIndicator(
                close=df["close"], volume=df["volume"]
            )
            df["obv"] = obv_indicator.on_balance_volume()
            # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π OBV
            df["obv_normalized"] = df["obv"] / (df["volume"].rolling(20).mean() + 1e-10)
        except:
            pass

        # 9. Ultimate Oscillator - –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–∏–æ–¥–æ–≤
        try:
            ultimate = ta.momentum.UltimateOscillator(
                high=df["high"], low=df["low"], close=df["close"], window1=7, window2=14, window3=28
            )
            df["ultimate_oscillator"] = ultimate.ultimate_oscillator()
        except:
            pass

        # 9. Accumulation/Distribution Index
        try:
            adl = ta.volume.AccDistIndexIndicator(
                high=df["high"], low=df["low"], close=df["close"], volume=df["volume"]
            )
            df["accumulation_distribution"] = adl.acc_dist_index()
        except:
            pass

        # 10. On Balance Volume (OBV)
        try:
            obv = ta.volume.OnBalanceVolumeIndicator(close=df["close"], volume=df["volume"])
            df["obv"] = obv.on_balance_volume()
            # OBV trend
            df["obv_ema"] = df["obv"].ewm(span=20).mean()
            df["obv_trend"] = (df["obv"] > df["obv_ema"]).astype(int)
        except:
            pass

        # 11. Chaikin Money Flow (CMF)
        try:
            cmf = ta.volume.ChaikinMoneyFlowIndicator(
                high=df["high"], low=df["low"], close=df["close"], volume=df["volume"], window=20
            )
            df["cmf"] = cmf.chaikin_money_flow()
        except:
            pass

        # 12. Average Directional Movement Index Rating (ADXR)
        try:
            adxr = ta.trend.ADXIndicator(
                high=df["high"], low=df["low"], close=df["close"], window=14
            )
            df["adxr"] = adxr.adx().rolling(14).mean()  # ADXR = —Å—Ä–µ–¥–Ω–µ–µ ADX
        except:
            pass

        # 13. Aroon Indicator
        try:
            aroon = ta.trend.AroonIndicator(close=df["close"], window=25)
            df["aroon_up"] = aroon.aroon_up()
            df["aroon_down"] = aroon.aroon_down()
            df["aroon_oscillator"] = df["aroon_up"] - df["aroon_down"]
        except:
            pass

        # 14. Pivot Points (–ø–æ–¥–¥–µ—Ä–∂–∫–∞/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ)
        df["pivot"] = (df["high"] + df["low"] + df["close"]) / 3
        df["resistance1"] = 2 * df["pivot"] - df["low"]
        df["support1"] = 2 * df["pivot"] - df["high"]
        df["resistance2"] = df["pivot"] + (df["high"] - df["low"])
        df["support2"] = df["pivot"] - (df["high"] - df["low"])

        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —É—Ä–æ–≤–Ω–µ–π
        df["dist_to_resistance1"] = (df["resistance1"] - df["close"]) / df["close"]
        df["dist_to_support1"] = (df["close"] - df["support1"]) / df["close"]

        # 15. Rate of Change (ROC)
        try:
            roc = ta.momentum.ROCIndicator(close=df["close"], window=10)
            df["roc"] = roc.roc()
        except:
            pass

        # 16. Trix - —Ç—Ä–æ–π–Ω–æ–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
        try:
            trix = ta.trend.TRIXIndicator(close=df["close"], window=15)
            df["trix"] = trix.trix()
        except:
            pass

        return df

    def _create_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä—ã–Ω–∫–∞"""
        # –°–ø—Ä–µ–¥ high-low
        df["hl_spread"] = self.safe_divide(df["high"] - df["low"], df["close"], fill_value=0.0)
        df["hl_spread_ma"] = df["hl_spread"].rolling(20).mean()

        # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏ –æ–±—ä–µ–º
        df["price_direction"] = np.sign(df["close"] - df["open"])
        df["directed_volume"] = df["volume"] * df["price_direction"]
        df["volume_imbalance"] = (
            df["directed_volume"].rolling(10).sum() / df["volume"].rolling(10).sum()
        )

        # –¶–µ–Ω–æ–≤–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ - —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º dollar volume –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        df["dollar_volume"] = df["volume"] * df["close"]
        # –ò–°–ü–†–ê–í–õ–ï–ù–û v3: –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º price_impact –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
        # –≥–¥–µ dollar_volume –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç $10K –¥–æ $100M+
        # log10($10K) ‚âà 4, log10($1M) ‚âà 6, log10($100M) ‚âà 8
        # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ 100 –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∑–Ω–∞—á–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π price_impact
        df["price_impact"] = self.safe_divide(
            df["returns"].abs() * 100,  # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ 100 –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞
            np.log10(df["dollar_volume"] + 100),  # log10 –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞
            fill_value=0.0,
            max_value=0.1,  # –õ–∏–º–∏—Ç –¥–ª—è –Ω–æ–≤–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∞
        )

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ —Å –ª–æ–≥–∞—Ä–∏—Ñ–º–æ–º –æ–±—ä–µ–º–∞
        df["price_impact_log"] = self.safe_divide(
            df["returns"].abs(),
            np.log(df["volume"] + 10),  # –£–≤–µ–ª–∏—á–µ–Ω —Å–¥–≤–∏–≥ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            fill_value=0.0,
            max_value=10.0,
        )

        # –ò–°–ü–†–ê–í–õ–ï–ù–û v3: –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é —Ñ–æ—Ä–º—É–ª—É –¥–ª—è toxicity
        # toxicity = exp(-price_impact * 20)
        # –° –Ω–æ–≤—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º price_impact:
        # –ü—Ä–∏ price_impact=0.04: toxicity‚âà0.45
        # –ü—Ä–∏ price_impact=0.02: toxicity‚âà0.67
        # –ü—Ä–∏ price_impact=0.01: toxicity‚âà0.82
        df["toxicity"] = np.exp(-df["price_impact"] * 20)
        df["toxicity"] = df["toxicity"].clip(0.3, 1.0)

        # –ê–º–∏—Ö—É–¥ –Ω–µ–ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å - —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞
        # –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞: |returns| / dollar_volume
        # –ù–æ –º—ã –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –Ω–∞ –º–∏–ª–ª–∏–æ–Ω –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∑–Ω–∞—á–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df["amihud_illiquidity"] = self.safe_divide(
            df["returns"].abs() * 1e6,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –Ω–∞ –º–∏–ª–ª–∏–æ–Ω
            df["turnover"],
            fill_value=0.0,
            max_value=100.0,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–º –º–∞–∫—Å–∏–º—É–º–æ–º
        )
        df["amihud_ma"] = df["amihud_illiquidity"].rolling(20).mean()

        # –ö–∞–π–ª –ª—è–º–±–¥–∞ - –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: |price_change| / volume, –∞ –Ω–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ std
        df["kyle_lambda"] = self.safe_divide(
            df["returns"].abs(), np.log(df["volume"] + 1), fill_value=0.0, max_value=10.0
        )

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è - –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–µ–π
        df["volatility_volume_ratio"] = self.safe_divide(
            df["returns"].rolling(10).std(),
            df["volume"].rolling(10).std(),
            fill_value=0.0,
            max_value=10.0,
        )

        # –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å - –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∞–Ω–Ω—É–∞–ª–∏–∑–∞—Ü–∏—è
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –†–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –∞–Ω–Ω—É–∞–ª–∏–∑–∞—Ü–∏–∏
        # –î–ª—è 15-–º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: 96 –ø–µ—Ä–∏–æ–¥–æ–≤ –≤ –¥–µ–Ω—å, 365 –¥–Ω–µ–π –≤ –≥–æ–¥—É
        df["realized_vol_1h"] = df["returns"].rolling(4).std() * np.sqrt(
            96
        )  # –ß–∞—Å–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å -> –¥–Ω–µ–≤–Ω–∞—è
        df["realized_vol_daily"] = df["returns"].rolling(96).std() * np.sqrt(
            96
        )  # –î–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        df["realized_vol_annual"] = df["returns"].rolling(96).std() * np.sqrt(
            96 * 365
        )  # –ì–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å

        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä–æ–µ –∏–º—è
        df["realized_vol"] = df["realized_vol_daily"]

        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –∫ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º log –æ–±—ä–µ–º–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ —Å—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º
        avg_volume = df["volume"].rolling(96).mean()
        normalized_volume = df["volume"] / (avg_volume + 1)  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–º

        df["volume_volatility_ratio"] = self.safe_divide(
            normalized_volume,
            df["realized_vol"] * 100,  # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            fill_value=1.0,
            max_value=100.0,  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç
        )

        return df

    def _create_rally_detection_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–ª–ª–∏ –∏ –∫—Ä—É–ø–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π"""
        if not self.disable_progress:
            self.logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–ª–ª–∏...")
        initial_cols = len(df.columns)
        features_created = []

        # 1. –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ–±—ä–µ–º –∑–∞ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã (8 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
        for hours in [4, 8, 12, 24]:
            periods = hours * 4  # 15-–º–∏–Ω—É—Ç–Ω—ã–µ —Å–≤–µ—á–∏
            col_cumsum = f"volume_cumsum_{hours}h"
            col_ratio = f"volume_cumsum_{hours}h_ratio"

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º log1p –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
            # log1p(x) = log(1 + x), –±–µ–∑–æ–ø–∞—Å–µ–Ω –¥–ª—è x=0
            df[col_cumsum] = np.log1p(df["volume"].rolling(periods).sum())

            # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ —Å—Ä–µ–¥–Ω–µ–º—É –æ–±—ä–µ–º—É –∑–∞ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
            avg_volume_long = df["volume"].rolling(periods * 4).mean()
            df[col_ratio] = self.safe_divide(
                df["volume"].rolling(periods).sum(),
                avg_volume_long * periods,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞ –æ–∂–∏–¥–∞–µ–º—É—é —Å—É–º–º—É
                fill_value=1.0,
                max_value=10.0,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –≤—Å–ø–ª–µ—Å–∫–∏
            )
            features_created.extend([col_cumsum, col_ratio])

        if not self.disable_progress:
            self.logger.info(
                f"  ‚úì –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –æ–±—ä–µ–º: —Å–æ–∑–¥–∞–Ω–æ {len([f for f in features_created if 'volume_cumsum' in f])} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
            )

        # 2. –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –≤—Å–ø–ª–µ—Å–∫–∏ –æ–±—ä–µ–º–∞ (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        volume_mean = df["volume"].rolling(96).mean()  # —Å—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º –∑–∞ 24—á
        volume_std = df["volume"].rolling(96).std()
        df["volume_zscore"] = self.safe_divide(
            df["volume"] - volume_mean,
            volume_std,
            fill_value=0.0,
            max_value=50.0,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í –∫—Ä–∏–ø—Ç–æ Z-score –º–æ–∂–µ—Ç –¥–æ—Å—Ç–∏–≥–∞—Ç—å 20-50
        )
        df["volume_spike"] = (df["volume_zscore"] > 3).astype(int)
        df["volume_spike_magnitude"] = df["volume_zscore"].clip(0, 10)
        features_created.extend(["volume_zscore", "volume_spike", "volume_spike_magnitude"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –≤—Å–ø–ª–µ—Å–∫–∏ –æ–±—ä–µ–º–∞: —Å–æ–∑–¥–∞–Ω–æ 3 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 3. –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è (15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        # –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã –∏ –º–∞–∫—Å–∏–º—É–º—ã
        for window in [20, 50, 100]:  # 5—á, 12.5—á, 25—á
            df[f"local_high_{window}"] = df["high"].rolling(window).max()
            df[f"local_low_{window}"] = df["low"].rolling(window).min()
            df[f"distance_from_high_{window}"] = (df["close"] - df[f"local_high_{window}"]) / df[
                "close"
            ]
            df[f"distance_from_low_{window}"] = (df["close"] - df[f"local_low_{window}"]) / df[
                "close"
            ]
            df[f"position_in_range_{window}"] = self.safe_divide(
                df["close"] - df[f"local_low_{window}"],
                df[f"local_high_{window}"] - df[f"local_low_{window}"],
                fill_value=0.5,  # –°–µ—Ä–µ–¥–∏–Ω–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                max_value=1.0,  # –ü–æ–∑–∏—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç 0 –¥–æ 1
            )
            features_created.extend(
                [
                    f"local_high_{window}",
                    f"local_low_{window}",
                    f"distance_from_high_{window}",
                    f"distance_from_low_{window}",
                    f"position_in_range_{window}",
                ]
            )

        if not self.disable_progress:
            self.logger.info("  ‚úì –£—Ä–æ–≤–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è: —Å–æ–∑–¥–∞–Ω–æ 15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        # 4. –°–∂–∞—Ç–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–ø—Ä–∏–∑–Ω–∞–∫ –±—É–¥—É—â–µ–≥–æ –ø—Ä–æ—Ä—ã–≤–∞) (2 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # Bollinger Bands —É–∂–µ –µ—Å—Ç—å, –¥–æ–±–∞–≤–∏–º Keltner Channels –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        if "atr" in df.columns and "bb_width" in df.columns:
            atr_multiplier = 2.0
            ema20 = df["close"].ewm(span=20, adjust=False).mean()
            kc_upper = ema20 + atr_multiplier * df["atr"]
            kc_lower = ema20 - atr_multiplier * df["atr"]
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —à–∏—Ä–∏–Ω—ã –∫–∞–Ω–∞–ª–æ–≤
            kc_width = (kc_upper - kc_lower) / df["close"]

            df["volatility_squeeze"] = (df["bb_width"] < kc_width).astype(int)
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∂–∞—Ç–∏—è —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–∏–æ–¥–æ–≤ squeeze
            squeeze_group = (df["volatility_squeeze"] != df["volatility_squeeze"].shift()).cumsum()
            df["volatility_squeeze_duration"] = (
                df["volatility_squeeze"].groupby(squeeze_group).cumsum()
            )
            df.loc[df["volatility_squeeze"] == 0, "volatility_squeeze_duration"] = 0
            features_created.extend(["volatility_squeeze", "volatility_squeeze_duration"])

            if not self.disable_progress:
                self.logger.info("  ‚úì –°–∂–∞—Ç–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: —Å–æ–∑–¥–∞–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 5. –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏ RSI/MACD —Å —Ü–µ–Ω–æ–π (4 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        if "rsi" in df.columns:
            # RSI –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
            price_higher = (df["close"] > df["close"].shift(14)) & (
                df["close"].shift(14) > df["close"].shift(28)
            )
            rsi_lower = (df["rsi"] < df["rsi"].shift(14)) & (
                df["rsi"].shift(14) < df["rsi"].shift(28)
            )
            df["bearish_divergence_rsi"] = (price_higher & rsi_lower).astype(int)

            price_lower = (df["close"] < df["close"].shift(14)) & (
                df["close"].shift(14) < df["close"].shift(28)
            )
            rsi_higher = (df["rsi"] > df["rsi"].shift(14)) & (
                df["rsi"].shift(14) > df["rsi"].shift(28)
            )
            df["bullish_divergence_rsi"] = (price_lower & rsi_higher).astype(int)
            features_created.extend(["bearish_divergence_rsi", "bullish_divergence_rsi"])

        if "macd" in df.columns:
            # MACD –¥–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
            macd_lower = (df["macd"] < df["macd"].shift(14)) & (
                df["macd"].shift(14) < df["macd"].shift(28)
            )
            df["bearish_divergence_macd"] = (
                (price_higher & macd_lower).astype(int) if "price_higher" in locals() else 0
            )

            macd_higher = (df["macd"] > df["macd"].shift(14)) & (
                df["macd"].shift(14) > df["macd"].shift(28)
            )
            df["bullish_divergence_macd"] = (
                (price_lower & macd_higher).astype(int) if "price_lower" in locals() else 0
            )
            features_created.extend(["bearish_divergence_macd", "bullish_divergence_macd"])

        if not self.disable_progress:
            self.logger.info(
                f"  ‚úì –î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏ RSI/MACD: —Å–æ–∑–¥–∞–Ω–æ {len([f for f in features_created if 'divergence' in f])} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
            )

        # 6. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è/—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (4 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # On-Balance Volume (OBV)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –º–∞—Å—à—Ç–∞–±–∞
        obv_change = df["volume"] * ((df["close"] > df["close"].shift(1)) * 2 - 1)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ —Å log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        obv_raw = obv_change.rolling(100).sum()  # 100 –ø–µ—Ä–∏–æ–¥–æ–≤ (25 —á–∞—Å–æ–≤)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –º–∞—Å—à—Ç–∞–±–∞
        df["obv"] = np.sign(obv_raw) * np.log1p(np.abs(obv_raw))

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º OBV –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—ä–µ–º–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∞–∫—Ç–∏–≤–∞–º–∏
        avg_volume = df["volume"].rolling(100).mean()
        df["obv_normalized"] = self.safe_divide(
            df["obv"],
            np.log1p(avg_volume),  # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä—É–µ–º –∏ —Å—Ä–µ–¥–Ω–∏–π –æ–±—ä–µ–º
            fill_value=0.0,
            max_value=20.0,
        )

        df["obv_ema"] = df["obv"].ewm(span=20, adjust=False).mean()
        df["obv_divergence"] = df["obv"] - df["obv_ema"]

        # Chaikin Money Flow
        mfm = ((df["close"] - df["low"]) - (df["high"] - df["close"])) / (
            df["high"] - df["low"] + 1e-10
        )
        mfv = mfm * df["volume"]
        df["cmf"] = mfv.rolling(20).sum() / df["volume"].rolling(20).sum()
        features_created.extend(["obv", "obv_normalized", "obv_ema", "obv_divergence", "cmf"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è/—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: —Å–æ–∑–¥–∞–Ω–æ 5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        # 7. Momentum –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ (4 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º groupby –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        df["momentum_1h"] = df.groupby("symbol")["close"].pct_change(4) * 100  # 1 —á–∞—Å
        df["momentum_4h"] = df.groupby("symbol")["close"].pct_change(16) * 100  # 4 —á–∞—Å–∞
        df["momentum_24h"] = df.groupby("symbol")["close"].pct_change(96) * 100  # 24 —á–∞—Å–∞

        # –£—Å–∫–æ—Ä–µ–Ω–∏–µ (–∏–∑–º–µ–Ω–µ–Ω–∏–µ momentum)
        df["momentum_acceleration"] = df.groupby("symbol")["momentum_1h"].transform(
            lambda x: x - x.shift(4)
        )
        features_created.extend(
            ["momentum_1h", "momentum_4h", "momentum_24h", "momentum_acceleration"]
        )

        if not self.disable_progress:
            self.logger.info("  ‚úì Momentum –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: —Å–æ–∑–¥–∞–Ω–æ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 8. –ü–∞—Ç—Ç–µ—Ä–Ω "–ø—Ä—É–∂–∏–Ω–∞" - —Å–∏–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –ø–µ—Ä–µ–¥ –¥–≤–∏–∂–µ–Ω–∏–µ–º (1 –ø—Ä–∏–∑–Ω–∞–∫)
        if (
            "volatility_squeeze" in df.columns
            and "volume_spike" in df.columns
            and "atr_pct" in df.columns
        ):
            df["spring_pattern"] = (
                (df["volatility_squeeze"] == 1)
                & (df["volume_spike"] == 1)
                & (df["atr_pct"].rolling(20).mean() < df["atr_pct"].rolling(100).mean() * 0.7)
            ).astype(int)
            features_created.append("spring_pattern")

            if not self.disable_progress:
                self.logger.info("  ‚úì –ü–∞—Ç—Ç–µ—Ä–Ω '–ø—Ä—É–∂–∏–Ω–∞': —Å–æ–∑–¥–∞–Ω 1 –ø—Ä–∏–∑–Ω–∞–∫")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_created = len(features_created)
        if not self.disable_progress:
            self.logger.info(
                f"‚úÖ Rally detection features: –≤—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {total_created} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
            )

        return df

    def _create_signal_quality_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤"""
        if not self.disable_progress:
            self.logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤...")
        initial_cols = len(df.columns)
        features_created = []

        # 1. –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–≥–Ω–∞–ª—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        indicators_long = []
        indicators_short = []
        indicators_used = []

        # RSI
        if "rsi" in df.columns:
            indicators_long.append((df["rsi"] < 30).astype(int))
            indicators_short.append((df["rsi"] > 70).astype(int))
            indicators_used.append("RSI")

        # MACD
        if "macd_diff" in df.columns:
            indicators_long.append((df["macd_diff"] > 0).astype(int))
            indicators_short.append((df["macd_diff"] < 0).astype(int))
            indicators_used.append("MACD")

        # Bollinger Bands
        if "bb_position" in df.columns:
            indicators_long.append((df["bb_position"] < 0.2).astype(int))
            indicators_short.append((df["bb_position"] > 0.8).astype(int))
            indicators_used.append("Bollinger Bands")

        # Stochastic
        if "stoch_k" in df.columns:
            indicators_long.append((df["stoch_k"] < 20).astype(int))
            indicators_short.append((df["stoch_k"] > 80).astype(int))
            indicators_used.append("Stochastic")

        # ADX (—Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞)
        if "adx" in df.columns and "adx_pos" in df.columns and "adx_neg" in df.columns:
            strong_trend = (df["adx"] > 25).astype(int)
            indicators_long.append(strong_trend & (df["adx_pos"] > df["adx_neg"]))
            indicators_short.append(strong_trend & (df["adx_neg"] > df["adx_pos"]))
            indicators_used.append("ADX")

        # Moving averages
        if "close_sma_20_ratio" in df.columns and "close_sma_50_ratio" in df.columns:
            indicators_long.append(
                (df["close_sma_20_ratio"] > df["close_sma_50_ratio"]).astype(int)
            )
            indicators_short.append(
                (df["close_sma_20_ratio"] < df["close_sma_50_ratio"]).astype(int)
            )
            indicators_used.append("Moving Averages")

        # –°—á–∏—Ç–∞–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        if indicators_long:
            df["indicators_consensus_long"] = sum(indicators_long) / len(indicators_long)
            df["indicators_count_long"] = sum(indicators_long)
        else:
            df["indicators_consensus_long"] = 0
            df["indicators_count_long"] = 0

        if indicators_short:
            df["indicators_consensus_short"] = sum(indicators_short) / len(indicators_short)
            df["indicators_count_short"] = sum(indicators_short)
        else:
            df["indicators_consensus_short"] = 0
            df["indicators_count_short"] = 0

        features_created.extend(
            [
                "indicators_consensus_long",
                "indicators_count_long",
                "indicators_consensus_short",
                "indicators_count_short",
            ]
        )

        if not self.disable_progress:
            self.logger.info("  ‚úì –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: —Å–æ–∑–¥–∞–Ω–æ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞")
            self.logger.info(f"    –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {', '.join(indicators_used)}")

        # 2. –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ —Å—Ç–∞—Ä—à–∏—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞—Ö (4 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç—Ä–µ–Ω–¥—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—ã –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        # –≠–º—É–ª–∏—Ä—É–µ–º 1-—á–∞—Å–æ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º (4 —Å–≤–µ—á–∏ –ø–æ 15 –º–∏–Ω)
        ma_1h = df["close"].rolling(4).mean()
        ma_1h_prev = ma_1h.shift(4)
        df["trend_1h"] = (
            self.safe_divide(
                ma_1h - ma_1h_prev,
                ma_1h_prev,
                fill_value=0.0,
                max_value=0.1,  # –ú–∞–∫—Å–∏–º—É–º 10% –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            )
            * 100
        )  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö

        if "atr_pct" in df.columns:
            df["trend_1h_strength"] = self.safe_divide(
                df["trend_1h"],
                df["atr_pct"].rolling(4).mean() * 100,  # ATR —É–∂–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                fill_value=0.0,
                max_value=10.0,
            )
        else:
            df["trend_1h_strength"] = df["trend_1h"] / 2  # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

        # –≠–º—É–ª–∏—Ä—É–µ–º 4-—á–∞—Å–æ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º (16 —Å–≤–µ—á–µ–π)
        ma_4h = df["close"].rolling(16).mean()
        ma_4h_prev = ma_4h.shift(16)
        df["trend_4h"] = (
            self.safe_divide(
                ma_4h - ma_4h_prev,
                ma_4h_prev,
                fill_value=0.0,
                max_value=0.2,  # –ú–∞–∫—Å–∏–º—É–º 20% –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            )
            * 100
        )  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö

        if "atr_pct" in df.columns:
            df["trend_4h_strength"] = self.safe_divide(
                df["trend_4h"],
                df["atr_pct"].rolling(16).mean() * 100,  # ATR —É–∂–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                fill_value=0.0,
                max_value=10.0,
            )
        else:
            df["trend_4h_strength"] = df["trend_4h"] / 2  # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

        features_created.extend(["trend_1h", "trend_1h_strength", "trend_4h", "trend_4h_strength"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ —Å—Ç–∞—Ä—à–∏—Ö –¢–§: —Å–æ–∑–¥–∞–Ω–æ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 3. –ü–æ–∑–∏—Ü–∏—è –≤ –¥–Ω–µ–≤–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ (7 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        # –î–Ω–µ–≤–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω (96 —Å–≤–µ—á–µ–π = 24 —á–∞—Å–∞)
        df["daily_high"] = df["high"].rolling(96).max()
        df["daily_low"] = df["low"].rolling(96).min()
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: daily_range –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç —Ü–µ–Ω—ã
        df["daily_range"] = self.safe_divide(
            df["daily_high"] - df["daily_low"],
            df["close"],
            fill_value=0.02,  # 2% –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            max_value=0.5,  # –ú–∞–∫—Å–∏–º—É–º 50% –æ—Ç —Ü–µ–Ω—ã
        )
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø–æ–∑–∏—Ü–∏–∏ –≤ –¥–Ω–µ–≤–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        # daily_range —É–∂–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ —Ü–µ–Ω—ã
        daily_range_abs = df["daily_high"] - df["daily_low"]
        df["position_in_daily_range"] = self.safe_divide(
            df["close"] - df["daily_low"], daily_range_abs, fill_value=0.5, max_value=1.0
        )

        # –ë–ª–∏–∑–æ—Å—Ç—å –∫ —ç–∫—Å—Ç—Ä–µ–º—É–º–∞–º
        df["near_daily_high"] = (df["position_in_daily_range"] > 0.9).astype(int)
        df["near_daily_low"] = (df["position_in_daily_range"] < 0.1).astype(int)
        features_created.extend(
            [
                "daily_high",
                "daily_low",
                "daily_range",
                "position_in_daily_range",
                "near_daily_high",
                "near_daily_low",
            ]
        )

        if not self.disable_progress:
            self.logger.info("  ‚úì –ü–æ–∑–∏—Ü–∏—è –≤ –¥–Ω–µ–≤–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ: —Å–æ–∑–¥–∞–Ω–æ 6 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        # 4. –ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä—ã–Ω–∫–∞ (2 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # Higher highs –∏ higher lows –¥–ª—è uptrend
        hh = (df["high"] > df["high"].shift(4)) & (df["high"].shift(4) > df["high"].shift(8))
        hl = (df["low"] > df["low"].shift(4)) & (df["low"].shift(4) > df["low"].shift(8))
        df["uptrend_structure"] = (hh & hl).astype(int)

        # Lower highs –∏ lower lows –¥–ª—è downtrend
        lh = (df["high"] < df["high"].shift(4)) & (df["high"].shift(4) < df["high"].shift(8))
        ll = (df["low"] < df["low"].shift(4)) & (df["low"].shift(4) < df["low"].shift(8))
        df["downtrend_structure"] = (lh & ll).astype(int)
        features_created.extend(["uptrend_structure", "downtrend_structure"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –ö–∞—á–µ—Å—Ç–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä—ã–Ω–∫–∞: —Å–æ–∑–¥–∞–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 5. –†–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π (1 –ø—Ä–∏–∑–Ω–∞–∫)
        # –ê–Ω–æ–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º —á–∞—Å—Ç–æ —Å–≤—è–∑–∞–Ω —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
        if "volume_spike" in df.columns:
            df["news_risk"] = (df["volume_spike"] == 1).astype(int)
            features_created.append("news_risk")

            if not self.disable_progress:
                self.logger.info("  ‚úì –†–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π: —Å–æ–∑–¥–∞–Ω 1 –ø—Ä–∏–∑–Ω–∞–∫")

        # 6. –û—Ü–µ–Ω–∫–∞ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (3 –ø—Ä–∏–∑–Ω–∞–∫–∞)
        # –°—Ä–µ–¥–Ω–∏–π —Å–ø—Ä–µ–¥ –∏ –æ–±—ä–µ–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º high-low —Å–ø—Ä–µ–¥ –≤–º–µ—Å—Ç–æ bid-ask
        df["hl_spread"] = (df["high"] - df["low"]) / df["close"]

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç liquidity_score —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
        hl_spread_mean = df["hl_spread"].rolling(4).mean()
        volume_mean = df["volume"].rolling(4).mean()

        # –ö–ª–∏–ø–ø–∏–Ω–≥ hl_spread –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –æ—á–µ–Ω—å –º–∞–ª—ã–µ —á–∏—Å–ª–∞
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å–ø—Ä–µ–¥ 0.01% (0.0001) –¥–ª—è —Å—Ç–µ–π–±–ª–∫–æ–∏–Ω–æ–≤
        hl_spread_clipped = np.clip(hl_spread_mean, 0.0001, 1.0)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º log-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –º–∞—Å—à—Ç–∞–±–∞
        # liquidity_score —Ç–µ–ø–µ—Ä—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –ø—Ä–∏–º–µ—Ä–Ω–æ [0, 20]
        df["liquidity_score"] = np.log1p(volume_mean / (hl_spread_clipped * 1000))

        # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        df["liquidity_rank"] = df.groupby("datetime")["liquidity_score"].rank(pct=True)
        features_created.extend(["hl_spread", "liquidity_score", "liquidity_rank"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –û—Ü–µ–Ω–∫–∞ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏: —Å–æ–∑–¥–∞–Ω–æ 3 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 6. Signal Strength - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        # –ë–ï–ó –£–¢–ï–ß–ï–ö: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã signal_strength:
        # 1. –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ (ADX)
        trend_strength = df["adx"] / 100 if "adx" in df.columns else pd.Series(0.5, index=df.index)

        # 2. Momentum (RSI –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç 50)
        momentum_strength = (
            np.abs(df["rsi"] - 50) / 50 if "rsi" in df.columns else pd.Series(0.5, index=df.index)
        )

        # 3. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è)
        if "volatility_20" in df.columns:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ, –ù–ï –±—É–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            vol_mean_hist = df.groupby("symbol")["volatility_20"].transform(
                lambda x: x.rolling(100, min_periods=20).mean()
            )
            vol_strength = df["volatility_20"] / (vol_mean_hist + 1e-6)
            vol_strength = np.clip(vol_strength, 0, 2) / 2
        else:
            vol_strength = pd.Series(0.5, index=df.index)

        # 4. Volume (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π)
        if "volume" in df.columns:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ, –ù–ï –±—É–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            vol_mean_hist = df.groupby("symbol")["volume"].transform(
                lambda x: x.rolling(100, min_periods=20).mean()
            )
            volume_strength = df["volume"] / (vol_mean_hist + 1e-6)
            volume_strength = np.clip(volume_strength, 0, 2) / 2
        else:
            volume_strength = pd.Series(0.5, index=df.index)

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ (–ø—Ä–∏–∑–Ω–∞–∫, –Ω–µ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)
        df["signal_strength"] = (
            0.3 * trend_strength
            + 0.3 * momentum_strength
            + 0.2 * vol_strength
            + 0.2 * volume_strength
        )
        df["signal_strength"] = np.clip(df["signal_strength"], 0, 1)
        features_created.append("signal_strength")

        if not self.disable_progress:
            self.logger.info("  ‚úì Signal strength: —Å–æ–∑–¥–∞–Ω 1 –ø—Ä–∏–∑–Ω–∞–∫ (–±–µ–∑ —É—Ç–µ—á–µ–∫)")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_created = len(features_created)
        if not self.disable_progress:
            self.logger.info(f"‚úÖ Signal quality features: –≤—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {total_created} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        return df

    def _create_futures_specific_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ —Ñ—å—é—á–µ—Ä—Å–∞–º–∏ —Å –ø–ª–µ—á–æ–º"""
        if not self.disable_progress:
            self.logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ñ—å—é—á–µ—Ä—Å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏...")
        initial_cols = len(df.columns)
        features_created = []

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–ª–µ—á–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –ë–∞–∑–æ–≤–æ–µ –ø–ª–µ—á–æ 5x, –Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ ATR
        base_leverage = 5

        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–ª–µ—á–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –ß–µ–º –≤—ã—à–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å, —Ç–µ–º –º–µ–Ω—å—à–µ –ø–ª–µ—á–æ
        # ATR –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö —É–∂–µ –µ—Å—Ç—å –≤ df['atr_pct']
        if "atr_pct" in df.columns:
            volatility_factor = df["atr_pct"].rolling(24).mean()  # –°—Ä–µ–¥–Ω—è—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞ 6 —á–∞—Å–æ–≤

            # –ü–ª–µ—á–æ –æ—Ç 3x –¥–æ 10x –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            # –ü—Ä–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ 0.5% -> leverage = 10
            # –ü—Ä–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ 2% -> leverage = 3
            dynamic_leverage = base_leverage * (0.01 / (volatility_factor + 0.001))
            dynamic_leverage = dynamic_leverage.clip(3, 10)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
        else:
            dynamic_leverage = pd.Series(base_leverage, index=df.index)

        # 1. –†–∞—Å—á–µ—Ç –ª–∏–∫–≤–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —Ü–µ–Ω—ã
        # –î–ª—è LONG: Liq Price = Entry Price * (1 - 1/leverage + fees)
        # –î–ª—è SHORT: Liq Price = Entry Price * (1 + 1/leverage - fees)
        maintenance_margin = 0.5 / 100  # 0.5% –¥–ª—è Bybit

        df["long_liquidation_price"] = df["close"] * (1 - 1 / dynamic_leverage + maintenance_margin)
        df["short_liquidation_price"] = df["close"] * (
            1 + 1 / dynamic_leverage - maintenance_margin
        )

        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        df["long_liquidation_distance_pct"] = (
            (df["close"] - df["long_liquidation_price"]) / df["close"]
        ) * 100
        df["short_liquidation_distance_pct"] = (
            (df["short_liquidation_price"] - df["close"]) / df["close"]
        ) * 100

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–ª–µ—á–æ
        df["current_leverage"] = dynamic_leverage
        features_created.extend(
            [
                "long_liquidation_price",
                "short_liquidation_price",
                "long_liquidation_distance_pct",
                "short_liquidation_distance_pct",
                "current_leverage",
            ]
        )

        if not self.disable_progress:
            self.logger.info("  ‚úì –õ–∏–∫–≤–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ü–µ–Ω—ã: —Å–æ–∑–¥–∞–Ω–æ 4 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 2. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞—Å–∞–Ω–∏—è –ª–∏–∫–≤–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —Ü–µ–Ω—ã
        # –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
        max_drawdown_24h = df["low"].rolling(96).min() / df["close"].shift(96) - 1
        max_rally_24h = df["high"].rolling(96).max() / df["close"].shift(96) - 1

        # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–≤–∏–∂–µ–Ω–∏–π
        df["long_liquidation_risk"] = (
            (abs(max_drawdown_24h) > df["long_liquidation_distance_pct"] / 100).rolling(96).mean()
        )
        df["short_liquidation_risk"] = (
            (max_rally_24h > df["short_liquidation_distance_pct"] / 100).rolling(96).mean()
        )
        features_created.extend(["long_liquidation_risk", "short_liquidation_risk"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏: —Å–æ–∑–¥–∞–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 3. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –ø–ª–µ—á–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –ü—Ä–∞–≤–∏–ª–æ: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–ª–µ—á–æ = 20% / (–¥–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)
        daily_volatility = df["returns"].rolling(96).std() * np.sqrt(96)  # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –¥–Ω–µ–≤–Ω–æ–π
        df["optimal_leverage"] = (0.2 / (daily_volatility + 0.01)).clip(1, 10)  # –û—Ç 1x –¥–æ 10x

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–ª–µ—á–æ (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ)
        df["safe_leverage"] = (0.1 / (daily_volatility + 0.01)).clip(1, 5)  # –û—Ç 1x –¥–æ 5x
        features_created.extend(["optimal_leverage", "safe_leverage"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –ø–ª–µ—á–æ: —Å–æ–∑–¥–∞–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 4. –†–∏—Å–∫ –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π
        # –ö–æ–≥–¥–∞ –º–Ω–æ–≥–æ –ø–æ–∑–∏—Ü–∏–π –º–æ–≥—É—Ç –±—ã—Ç—å –ª–∏–∫–≤–∏–¥–∏—Ä–æ–≤–∞–Ω—ã –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: —Ä–µ–∑–∫–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è + –≤—ã—Å–æ–∫–∏–π –æ–±—ä–µ–º
        if "volume_spike" in df.columns:
            df["cascade_risk"] = (
                (df["volume_spike"] == 1)
                & (abs(df["returns"]) > df["returns"].rolling(96).std() * 2)
            ).astype(int)
            features_created.append("cascade_risk")

            if not self.disable_progress:
                self.logger.info("  ‚úì –†–∏—Å–∫ –∫–∞—Å–∫–∞–¥–Ω—ã—Ö –ª–∏–∫–≤–∏–¥–∞—Ü–∏–π: —Å–æ–∑–¥–∞–Ω 1 –ø—Ä–∏–∑–Ω–∞–∫")

        # 5. Funding rate –≤–ª–∏—è–Ω–∏–µ (–¥–ª—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–π)
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–π funding rate (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Å –±–∏—Ä–∂–∏)
        # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π funding = –ª–æ–Ω–≥–∏ –ø–ª–∞—Ç—è—Ç —à–æ—Ä—Ç–∞–º
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É —Å–ø–æ—Ç –∏ —Ñ—å—é—á–µ—Ä—Å –∫–∞–∫ –ø—Ä–æ–∫—Å–∏
        if "momentum_1h" in df.columns:
            df["funding_proxy"] = df["momentum_1h"] * 0.01  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

            # –°—Ç–æ–∏–º–æ—Å—Ç—å —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –¥–µ–Ω—å (3 funding –ø–µ—Ä–∏–æ–¥–∞)
            df["long_holding_cost_daily"] = df["funding_proxy"] * 3
            df["short_holding_cost_daily"] = -df["funding_proxy"] * 3
            features_created.extend(
                ["funding_proxy", "long_holding_cost_daily", "short_holding_cost_daily"]
            )

            if not self.disable_progress:
                self.logger.info("  ‚úì Funding rate –≤–ª–∏—è–Ω–∏–µ: —Å–æ–∑–¥–∞–Ω–æ 3 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # 6. –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏
        # Value at Risk (VaR) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è —Å 95% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        returns_sorted = df["returns"].rolling(96).apply(lambda x: np.percentile(x, 5))
        df["var_95"] = abs(returns_sorted)

        # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ VaR
        max_loss_per_trade = 2.0  # 2% –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è –∫–∞–∫ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        df["recommended_position_size"] = max_loss_per_trade / (df["var_95"] * dynamic_leverage)
        features_created.extend(["var_95", "recommended_position_size"])

        if not self.disable_progress:
            self.logger.info("  ‚úì –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –¥–ª—è –ø–æ–∑–∏—Ü–∏–π: —Å–æ–∑–¥–∞–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_created = len(features_created)
        if not self.disable_progress:
            self.logger.info(
                f"‚úÖ Futures-specific features: –≤—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {total_created} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
            )

        return df

    def _create_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
        df["hour"] = df["datetime"].dt.hour
        df["minute"] = df["datetime"].dt.minute

        # –¶–∏–∫–ª–∏—á–µ—Å–∫–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
        df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)

        df["dayofweek"] = df["datetime"].dt.dayofweek
        df["is_weekend"] = (df["dayofweek"] >= 5).astype(int)

        df["dow_sin"] = np.sin(2 * np.pi * df["dayofweek"] / 7)
        df["dow_cos"] = np.cos(2 * np.pi * df["dayofweek"] / 7)

        df["day"] = df["datetime"].dt.day
        df["month"] = df["datetime"].dt.month

        df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
        df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)

        # –¢–æ—Ä–≥–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏
        df["asian_session"] = ((df["hour"] >= 0) & (df["hour"] < 8)).astype(int)
        df["european_session"] = ((df["hour"] >= 7) & (df["hour"] < 16)).astype(int)
        df["american_session"] = ((df["hour"] >= 13) & (df["hour"] < 22)).astype(int)

        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π
        df["session_overlap"] = (
            (df["asian_session"] + df["european_session"] + df["american_session"]) > 1
        ).astype(int)

        return df

    def _create_ml_optimized_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ ML-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è 2024-2025"""
        if not self.disable_progress:
            self.logger.info("–°–æ–∑–¥–∞–Ω–∏–µ ML-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        # 1. Hurst Exponent - –º–µ—Ä–∞ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–∞
        # >0.5 = —Ç—Ä–µ–Ω–¥, <0.5 = –≤–æ–∑–≤—Ä–∞—Ç –∫ —Å—Ä–µ–¥–Ω–µ–º—É, ~0.5 = —Å–ª—É—á–∞–π–Ω–æ–µ –±–ª—É–∂–¥–∞–Ω–∏–µ
        def hurst_exponent(ts, max_lag=20):
            """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç—ã –•–µ—Ä—Å—Ç–∞"""
            lags = range(2, min(max_lag, len(ts) // 2))
            tau = []

            for lag in lags:
                pp = np.array(ts[:-lag])
                pn = np.array(ts[lag:])
                diff = pn - pp
                tau.append(np.sqrt(np.nanmean(diff**2)))

            if len(tau) > 0 and all(t > 0 for t in tau):
                poly = np.polyfit(np.log(lags), np.log(tau), 1)
                return poly[0] * 2.0
            return 0.5

        # –ü—Ä–∏–º–µ–Ω—è–µ–º Hurst –¥–ª—è close —Å –æ–∫–Ω–æ–º 50
        df["hurst_exponent"] = (
            df["close"].rolling(50).apply(lambda x: hurst_exponent(x) if len(x) == 50 else 0.5)
        )

        # 2. Fractal Dimension - —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Ü–µ–Ω–æ–≤–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        # 1 = –ø—Ä—è–º–∞—è –ª–∏–Ω–∏—è, 2 = –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø–ª–æ—Å–∫–æ—Å—Ç—å
        def fractal_dimension(ts):
            """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–º –•–∏–≥—É—á–∏"""
            N = len(ts)
            if N < 10:
                return 1.5

            kmax = min(5, N // 2)
            L = []

            for k in range(1, kmax + 1):
                Lk = 0
                for m in range(k):
                    Lmk = 0
                    for i in range(1, int((N - m) / k)):
                        Lmk += abs(ts[m + i * k] - ts[m + (i - 1) * k])
                    if int((N - m) / k) > 0:
                        Lmk = Lmk * (N - 1) / (k * int((N - m) / k))
                    Lk += Lmk
                L.append(Lk / k)

            if len(L) > 0 and all(l > 0 for l in L):
                x = np.log(range(1, kmax + 1))
                y = np.log(L)
                poly = np.polyfit(x, y, 1)
                return poly[0]
            return 1.5

        df["fractal_dimension"] = (
            df["close"]
            .rolling(30)
            .apply(lambda x: fractal_dimension(x.values) if len(x) == 30 else 1.5)
        )

        # 3. Market Efficiency Ratio - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã
        # –í—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è = —Å–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥, –Ω–∏–∑–∫–∏–µ = –±–æ–∫–æ–≤–∏–∫
        df["efficiency_ratio"] = self.safe_divide(
            (df["close"] - df["close"].shift(20)).abs(), df["close"].diff().abs().rolling(20).sum()
        )

        # 4. Trend Quality Index - –∫–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–Ω–¥–∞
        # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è ADX, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if "adx" in df.columns and "sma_50" in df.columns and "bb_width" in df.columns:
            df["trend_quality"] = (
                df["adx"]
                / 100  # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞
                * ((df["close"] > df["sma_50"]).astype(float) * 2 - 1)  # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                * (
                    1 - df["bb_width"] / df["bb_width"].rolling(50).max()
                )  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            )
        else:
            df["trend_quality"] = 0

        # 5. Regime Detection Features
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ (—Ç—Ä–µ–Ω–¥/—Ñ–ª—ç—Ç/–≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)
        returns = df["close"].pct_change()

        # Realized volatility
        df["realized_vol_5m"] = returns.rolling(20).std() * np.sqrt(20)
        df["realized_vol_15m"] = returns.rolling(60).std() * np.sqrt(60)
        df["realized_vol_1h"] = returns.rolling(240).std() * np.sqrt(240)

        # GARCH-–ø–æ–¥–æ–±–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        df["garch_vol"] = returns.rolling(20).apply(
            lambda x: np.sqrt(0.94 * x.var() + 0.06 * x.iloc[-1] ** 2) if len(x) > 0 else 0
        )

        # –†–µ–∂–∏–º –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if "atr" in df.columns:
            atr_q25 = df["atr"].rolling(1000).quantile(0.25)
            atr_q75 = df["atr"].rolling(1000).quantile(0.75)
            df["vol_regime"] = 0  # –ù–æ—Ä–º–∞–ª—å–Ω–∞—è
            df.loc[df["atr"] < atr_q25, "vol_regime"] = -1  # –ù–∏–∑–∫–∞—è
            df.loc[df["atr"] > atr_q75, "vol_regime"] = 1  # –í—ã—Å–æ–∫–∞—è

        # 6. Information-theoretic features
        # –≠–Ω—Ç—Ä–æ–ø–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        def shannon_entropy(series, bins=10):
            """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ –®–µ–Ω–Ω–æ–Ω–∞"""
            if len(series) < bins:
                return 0
            counts, _ = np.histogram(series, bins=bins)
            probs = counts / counts.sum()
            probs = probs[probs > 0]
            return -np.sum(probs * np.log(probs))

        df["return_entropy"] = returns.rolling(100).apply(lambda x: shannon_entropy(x))

        # 7. Microstructure features
        # Amihud illiquidity
        if "amihud_illiquidity" not in df.columns:
            df["amihud_illiquidity"] = (
                self.safe_divide(returns.abs(), df["turnover"]).rolling(20).mean()
            )

        # Kyle's lambda (price impact)
        if "kyle_lambda" not in df.columns:
            df["kyle_lambda"] = self.safe_divide(
                returns.abs().rolling(20).mean(), df["volume"].rolling(20).mean()
            )

        # 8. Cross-sectional features (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ BTC)
        if "btc_returns" in df.columns:
            # Beta –∫ BTC
            df["btc_beta"] = (
                returns.rolling(100).cov(df["btc_returns"]) / df["btc_returns"].rolling(100).var()
            )

            # –ò–¥–∏–æ—Å–∏–Ω–∫—Ä–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            df["idio_vol"] = (returns - df["btc_beta"] * df["btc_returns"]).rolling(50).std()

        # 9. Autocorrelation features
        # –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ª–∞–≥–∞—Ö
        df["returns_ac_1"] = returns.rolling(50).apply(
            lambda x: x.autocorr(lag=1) if len(x) > 1 else 0
        )
        df["returns_ac_5"] = returns.rolling(50).apply(
            lambda x: x.autocorr(lag=5) if len(x) > 5 else 0
        )
        df["returns_ac_10"] = returns.rolling(50).apply(
            lambda x: x.autocorr(lag=10) if len(x) > 10 else 0
        )
        df["returns_ac_20"] = returns.rolling(50).apply(
            lambda x: x.autocorr(lag=20) if len(x) > 20 else 0
        )

        # 10. Jump detection
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä—ã–∂–∫–æ–≤ –≤ —Ü–µ–Ω–µ
        df["price_jump"] = (returns.abs() > returns.rolling(100).std() * 3).astype(int)

        df["jump_intensity"] = df["price_jump"].rolling(50).mean()

        # 10a. Volatility clustering - –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        # –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—ã—á–Ω–æ —Å–ª–µ–¥—É–µ—Ç –∑–∞ –≤—ã—Å–æ–∫–æ–π –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å—é
        df["vol_clustering"] = returns.pow(2).rolling(20).mean().rolling(20).std()

        # 10b. Efficiency-adjusted volatility
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è
        if "efficiency_ratio" in df.columns:
            df["efficiency_volatility"] = df["realized_vol_1h"] * (1 - df["efficiency_ratio"])
        else:
            df["efficiency_volatility"] = df["realized_vol_1h"]

        # 10c. Microstructure noise estimation
        # –û—Ü–µ–Ω–∫–∞ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —à—É–º–∞ —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—ã–µ —Ä–∞–∑–Ω–æ—Å—Ç–∏
        df["microstructure_noise"] = (df["close"].diff() / df["close"]).rolling(20).std()

        # 10d. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ ML –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        # –ü–∞—Ä–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –æ–±—ä–µ–º–∞ –∏ —Ü–µ–Ω—ã
        df["vol_price_corr"] = df["volume"].rolling(50).corr(df["close"])
        df["vol_returns_corr"] = df["volume"].rolling(50).corr(returns.abs())

        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (vol of vol)
        df["vol_of_vol"] = returns.rolling(20).std().rolling(20).std()

        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–ª–∞ –∏–Ω–¥–µ–∫—Å–∞ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è)
        gains = returns.where(returns > 0, 0).rolling(14).mean()
        losses = -returns.where(returns < 0, 0).rolling(14).mean()
        df["rsi_alternative"] = 100 - (100 / (1 + gains / (losses + 1e-10)))

        # –¢—Ä–µ–Ω–¥-—Ñ–∏–ª—å—Ç—Ä –•–æ–¥—Ä–∏–∫–∞-–ü—Ä–µ—Å–∫–æ—Ç—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        df["hp_trend"] = df["close"].rolling(100).mean()
        df["hp_cycle"] = (df["close"] - df["hp_trend"]) / df["close"]

        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å —Ç–æ—Ä–≥–æ–≤ (tick rule)
        df["trade_intensity"] = (df["volume"] / df["volume"].rolling(20).mean()) * np.sign(returns)

        # 11. Order flow imbalance persistence
        if "order_flow_imbalance" in df.columns:
            df["ofi_persistence"] = (
                df["order_flow_imbalance"]
                .rolling(20)
                .apply(lambda x: x.autocorr(lag=1) if len(x) > 1 else 0)
            )

        # 12. Volume-synchronized probability of informed trading (VPIN)
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
        df["vpin"] = self.safe_divide(
            (df["volume"] * ((df["close"] > df["open"]).astype(float) - 0.5))
            .rolling(50)
            .sum()
            .abs(),
            df["volume"].rolling(50).sum(),
        )

        # 13. Liquidity-adjusted returns
        if "amihud_illiquidity" in df.columns:
            df["liquidity_adj_returns"] = returns * (
                1 - df["amihud_illiquidity"] / df["amihud_illiquidity"].rolling(100).max()
            )

        # 14. Tail risk measures
        # Conditional Value at Risk (CVaR)
        df["cvar_5pct"] = returns.rolling(100).apply(
            lambda x: (
                x[x <= x.quantile(0.05)].mean()
                if len(x[x <= x.quantile(0.05)]) > 0
                else x.quantile(0.05)
            )
        )

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        ml_features = [
            "hurst_exponent",
            "fractal_dimension",
            "efficiency_ratio",
            "trend_quality",
            "realized_vol_5m",
            "realized_vol_15m",
            "realized_vol_1h",
            "garch_vol",
            "vol_regime",
            "return_entropy",
            "amihud_illiquidity",
            "kyle_lambda",
            "returns_ac_1",
            "returns_ac_5",
            "returns_ac_10",
            "price_jump",
            "jump_intensity",
            "vpin",
            "liquidity_adj_returns",
            "cvar_5pct",
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ª–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ —Å–æ–∑–¥–∞–Ω—ã
        if "btc_beta" in df.columns:
            ml_features.extend(["btc_beta", "idio_vol"])
        if "ofi_persistence" in df.columns:
            ml_features.append("ofi_persistence")

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        for feature in ml_features:
            if feature in df.columns:
                df[feature] = df[feature].fillna(method="ffill").fillna(0)

        return df

    def _handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        if not self.disable_progress:
            self.logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π...")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        info_cols = [
            "id",
            "symbol",
            "timestamp",
            "datetime",
            "open",
            "high",
            "low",
            "close",
            "volume",
            "turnover",
        ]

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processed_dfs = []

        for symbol in df["symbol"].unique():
            symbol_data = df[df["symbol"] == symbol].copy()

            # –î–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
            for col in symbol_data.columns:
                if col in info_cols:
                    continue

                if symbol_data[col].isna().any():
                    # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (Categorical dtype)
                    if hasattr(symbol_data[col], "cat"):
                        # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–ª–∏ 'FLAT'/'HOLD'
                        if "direction" in col:
                            symbol_data[col] = symbol_data[col].fillna("FLAT")
                        else:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥—É (–Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
                            mode = symbol_data[col].mode()
                            if len(mode) > 0:
                                symbol_data[col] = symbol_data[col].fillna(mode.iloc[0])
                    # –î–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º forward fill
                    elif any(
                        indicator in col
                        for indicator in ["sma", "ema", "rsi", "macd", "bb_", "adx"]
                    ):
                        symbol_data[col] = symbol_data[col].ffill()
                    # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º 0
                    else:
                        symbol_data[col] = symbol_data[col].fillna(0)

            # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ –º–æ–≥—É—Ç –±—ã—Ç—å NaN –∏–∑-–∑–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º max_period –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            max_period = 240  # –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è SMA/EMA_200 –∏ –¥—Ä—É–≥–∏—Ö –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if len(symbol_data) > max_period:
                symbol_data = symbol_data.iloc[max_period:].copy()
            else:
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ, –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å
                pass

            processed_dfs.append(symbol_data)

        result_df = pd.concat(processed_dfs, ignore_index=True)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        nan_count = result_df.isna().sum().sum()
        if nan_count > 0:
            if not self.disable_progress:
                self.logger.warning(f"–û—Å—Ç–∞–ª–∏—Å—å {nan_count} NaN –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN
            for col in result_df.columns:
                if result_df[col].isna().any():
                    # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
                    if hasattr(result_df[col], "cat"):
                        if "direction" in col:
                            result_df[col] = result_df[col].fillna("FLAT")
                        else:
                            mode = result_df[col].mode()
                            if len(mode) > 0:
                                result_df[col] = result_df[col].fillna(mode.iloc[0])
                    # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    elif pd.api.types.is_numeric_dtype(result_df[col]):
                        result_df[col] = result_df[col].fillna(0)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        numeric_cols = result_df.select_dtypes(include=[np.number]).columns
        inf_count = np.isinf(result_df[numeric_cols]).sum().sum()
        if inf_count > 0:
            if not self.disable_progress:
                self.logger.warning(
                    f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã {inf_count} –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã–µ"
                )
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ –Ω–∞ 99-–π –ø–µ—Ä—Å–µ–Ω—Ç–∏–ª—å –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
            for col in numeric_cols:
                if np.isinf(result_df[col]).any():
                    # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä—Å–µ–Ω—Ç–∏–ª–∏ –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                    finite_vals = result_df[col][np.isfinite(result_df[col])]
                    if len(finite_vals) > 0:
                        p99 = finite_vals.quantile(0.99)
                        p1 = finite_vals.quantile(0.01)
                        result_df[col] = result_df[col].replace([np.inf, -np.inf], [p99, p1])
                    else:
                        result_df[col] = result_df[col].replace([np.inf, -np.inf], [0, 0])

        if not self.disable_progress:
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {len(result_df)} –∑–∞–ø–∏—Å–µ–π")
        return result_df

    def _create_cross_asset_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ö—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
        if not self.disable_progress:
            self.logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–æ—Å—Å-–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        # BTC –∫–∞–∫ –±–∞–∑–æ–≤—ã–π –∞–∫—Ç–∏–≤
        btc_data = df[df["symbol"] == "BTCUSDT"][["datetime", "close", "returns"]].copy()
        if len(btc_data) > 0:
            btc_data.rename(columns={"close": "btc_close", "returns": "btc_returns"}, inplace=True)

            df = df.merge(btc_data, on="datetime", how="left")

            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å BTC
            for symbol in df["symbol"].unique():
                if symbol != "BTCUSDT":
                    mask = df["symbol"] == symbol
                    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º min_periods –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                    df.loc[mask, "btc_correlation"] = (
                        df.loc[mask, "returns"]
                        .rolling(window=96, min_periods=50)
                        .corr(df.loc[mask, "btc_returns"])
                    )

            df.loc[df["symbol"] == "BTCUSDT", "btc_correlation"] = 1.0

            # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è —Å–∏–ª–∞ –∫ BTC
            df["relative_strength_btc"] = df["close"] / df["btc_close"]
            df["rs_btc_ma"] = df.groupby("symbol")["relative_strength_btc"].transform(
                lambda x: x.rolling(20, min_periods=10).mean()
            )

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è BTC-—Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            df["btc_close"] = df["btc_close"].fillna(method="ffill").fillna(method="bfill")
            df["btc_returns"] = df["btc_returns"].fillna(0.0)
            df["btc_correlation"] = df["btc_correlation"].fillna(0.5)  # –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            df["relative_strength_btc"] = df["relative_strength_btc"].fillna(1.0)
            df["rs_btc_ma"] = df["rs_btc_ma"].fillna(1.0)
        else:
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö BTC
            df["btc_close"] = 0
            df["btc_returns"] = 0
            df["btc_correlation"] = 0
            df["relative_strength_btc"] = 0
            df["rs_btc_ma"] = 0

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–∫—Ç–æ—Ä–∞
        defi_tokens = ["AAVEUSDT", "UNIUSDT", "CAKEUSDT", "DYDXUSDT"]
        layer1_tokens = ["ETHUSDT", "SOLUSDT", "AVAXUSDT", "DOTUSDT", "NEARUSDT"]
        meme_tokens = [
            "DOGEUSDT",
            "FARTCOINUSDT",
            "MELANIAUSDT",
            "TRUMPUSDT",
            "POPCATUSDT",
            "PNUTUSDT",
            "ZEREBROUSDT",
            "WIFUSDT",
        ]

        df["sector"] = "other"
        df.loc[df["symbol"].isin(defi_tokens), "sector"] = "defi"
        df.loc[df["symbol"].isin(layer1_tokens), "sector"] = "layer1"
        df.loc[df["symbol"].isin(meme_tokens), "sector"] = "meme"
        df.loc[df["symbol"] == "BTCUSDT", "sector"] = "btc"

        # –°–µ–∫—Ç–æ—Ä–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        df["sector_returns"] = df.groupby(["datetime", "sector"])["returns"].transform("mean")

        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∫ —Å–µ–∫—Ç–æ—Ä—É
        df["relative_to_sector"] = df["returns"] - df["sector_returns"]

        # –†–∞–Ω–∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        df["returns_rank"] = df.groupby("datetime")["returns"].rank(pct=True)

        # 24-—á–∞—Å–æ–≤–æ–π –º–æ–º–µ–Ω—Ç—É–º - —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –≤ rally_detection_features
        # –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
        if "momentum_24h" in df.columns and df["momentum_24h"].isna().any():
            df["momentum_24h"] = df["momentum_24h"].fillna(0)
        if "momentum_24h" in df.columns:
            df["is_momentum_leader"] = (
                df.groupby("datetime")["momentum_24h"].rank(ascending=False) <= 5
            ).astype(int)

        return df

    def _create_target_variables(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ë–ï–ó –£–¢–ï–ß–ï–ö –î–ê–ù–ù–´–• - –≤–µ—Ä—Å–∏—è 4.0"""
        if not self.disable_progress:
            self.logger.info("üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö v4.0 (–±–µ–∑ —É—Ç–µ—á–µ–∫)...")

        # –ü–µ—Ä–∏–æ–¥—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –±—É–¥—É—â–∏—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ (–≤ —Å–≤–µ—á–∞—Ö –ø–æ 15 –º–∏–Ω—É—Ç)
        return_periods = {
            "15m": 1,  # 15 –º–∏–Ω—É—Ç
            "1h": 4,  # 1 —á–∞—Å
            "4h": 16,  # 4 —á–∞—Å–∞
            "12h": 48,  # 12 —á–∞—Å–æ–≤
        }

        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–´ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–∏–≥–Ω–∞–ª–æ–≤
        direction_thresholds = {
            "15m": 0.0015,  # 0.15% - —É–º–µ–Ω—å—à–∞–µ—Ç —à—É–º –æ—Ç –º–µ–ª–∫–∏—Ö –¥–≤–∏–∂–µ–Ω–∏–π
            "1h": 0.003,  # 0.3% - —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è
            "4h": 0.007,  # 0.7% - —Ñ–æ–∫—É—Å –Ω–∞ –∑–Ω–∞—á–∏–º—ã—Ö –¥–≤–∏–∂–µ–Ω–∏—è—Ö
            "12h": 0.01,  # 1% - –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
        }

        # –£—Ä–æ–≤–Ω–∏ –ø—Ä–∏–±—ã–ª–∏ –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö —Ü–µ–ª–µ–≤—ã—Ö
        profit_levels = {
            "1pct_4h": (0.01, 16),  # 1% –∑–∞ 4 —á–∞—Å–∞
            "2pct_4h": (0.02, 16),  # 2% –∑–∞ 4 —á–∞—Å–∞
            "3pct_12h": (0.03, 48),  # 3% –∑–∞ 12 —á–∞—Å–æ–≤
            "5pct_12h": (0.05, 48),  # 5% –∑–∞ 12 —á–∞—Å–æ–≤
        }

        # Commission and costs
        commission_rate = 0.0006  # 0.06%
        slippage = 0.0005  # 0.05%

        # A. –ë–∞–∑–æ–≤—ã–µ –≤–æ–∑–≤—Ä–∞—Ç—ã (4)
        for period_name, n_candles in return_periods.items():
            df[f"future_return_{period_name}"] = df.groupby("symbol")["close"].transform(
                lambda x: x.shift(-n_candles) / x - 1
            )

        # B. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è (4)
        for period_name in return_periods:
            future_return = df[f"future_return_{period_name}"]
            threshold = direction_thresholds[period_name]

            df[f"direction_{period_name}"] = pd.cut(
                future_return,
                bins=[-np.inf, -threshold, threshold, np.inf],
                labels=["DOWN", "FLAT", "UP"],
            )

        # C. –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø—Ä–∏–±—ã–ª–∏ LONG (4) - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ shift –¥–ª—è –±—É–¥—É—â–∏—Ö —Ü–µ–Ω
        for level_name, (profit_threshold, n_candles) in profit_levels.items():
            # –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç –ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –Ω—É–∂–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
            max_future_returns = pd.DataFrame()
            for i in range(1, n_candles + 1):
                future_high = df.groupby("symbol")["high"].transform(lambda x: x.shift(-i))
                future_return = future_high / df["close"] - 1
                max_future_returns[f"return_{i}"] = future_return

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π return –∑–∞ –ø–µ—Ä–∏–æ–¥
            max_return = max_future_returns.max(axis=1)
            df[f"long_will_reach_{level_name}"] = (max_return >= profit_threshold).astype(int)

        # D. –î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø—Ä–∏–±—ã–ª–∏ SHORT (4)
        for level_name, (profit_threshold, n_candles) in profit_levels.items():
            # –î–ª—è SHORT: –ø—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É
            min_future_returns = pd.DataFrame()
            for i in range(1, n_candles + 1):
                future_low = df.groupby("symbol")["low"].transform(lambda x: x.shift(-i))
                future_return = df["close"] / future_low - 1  # –î–ª—è SHORT –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
                min_future_returns[f"return_{i}"] = future_return

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π return –¥–ª—è SHORT –∑–∞ –ø–µ—Ä–∏–æ–¥
            max_return = min_future_returns.max(axis=1)
            df[f"short_will_reach_{level_name}"] = (max_return >= profit_threshold).astype(int)

        # E. –†–∏—Å–∫-–º–µ—Ç—Ä–∏–∫–∏ (4)
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ (–¥–ª—è LONG)
        for period_name, n_candles in [("1h", 4), ("4h", 16)]:
            min_prices = pd.DataFrame()
            for i in range(1, n_candles + 1):
                future_low = df.groupby("symbol")["low"].transform(lambda x: x.shift(-i))
                min_prices[f"low_{i}"] = future_low

            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥
            min_price = min_prices.min(axis=1)
            df[f"max_drawdown_{period_name}"] = (df["close"] / min_price - 1).fillna(0)

        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç –∑–∞ –ø–µ—Ä–∏–æ–¥ (–¥–ª—è SHORT)
        for period_name, n_candles in [("1h", 4), ("4h", 16)]:
            max_prices = pd.DataFrame()
            for i in range(1, n_candles + 1):
                future_high = df.groupby("symbol")["high"].transform(lambda x: x.shift(-i))
                max_prices[f"high_{i}"] = future_high

            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥
            max_price = max_prices.max(axis=1)
            df[f"max_rally_{period_name}"] = (max_price / df["close"] - 1).fillna(0)

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å —É—Ç–µ—á–∫–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
        # best_action, risk_reward_ratio –∏ optimal_hold_time –±—É–¥—É—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è
        # –≤ trading/signal_generator.py –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏

        # –ü–ï–†–ï–ù–ï–°–ï–ù–û –í –ü–†–ò–ó–ù–ê–ö–ò: signal_strength —Ç–µ–ø–µ—Ä—å feature, –Ω–µ target
        # –≠—Ç–æ –æ—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –±–µ–∑ —É—Ç–µ—á–µ–∫

        # –£–î–ê–õ–ï–ù–û: risk_reward_ratio –∏ optimal_hold_time —Å–æ–¥–µ—Ä–∂–∞–ª–∏ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        # –≠—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –±—É–¥—É—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ trading/signal_generator.py
        # –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏, –∞ –Ω–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö

        # –£–î–ê–õ–ï–ù–û: best_action –∏ –≤—Å–µ legacy –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (best_direction, reached, hit)
        # –í –≤–µ—Ä—Å–∏–∏ 4.0 –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ 20 —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–∑ —É—Ç–µ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö
        # –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã –≤—ã—à–µ

        # –§–∏–∫—Ç–∏–≤–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        df["long_tp1_time"] = 16  # 4 —á–∞—Å–∞
        df["long_tp2_time"] = 16
        df["long_tp3_time"] = 48  # 12 —á–∞—Å–æ–≤
        df["long_sl_time"] = 100
        df["short_tp1_time"] = 16
        df["short_tp2_time"] = 16
        df["short_tp3_time"] = 48
        df["short_sl_time"] = 100

        # Expected value –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        df["long_expected_value"] = df["future_return_4h"] * df["long_will_reach_2pct_4h"] * 2.0
        df["short_expected_value"] = -df["future_return_4h"] * df["short_will_reach_2pct_4h"] * 2.0

        # Optimal entry —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        df["long_optimal_entry_time"] = 1
        df["long_optimal_entry_price"] = df["close"]
        df["long_optimal_entry_improvement"] = 0
        df["short_optimal_entry_time"] = 1
        df["short_optimal_entry_price"] = df["close"]
        df["short_optimal_entry_improvement"] = 0

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if not self.disable_progress:
            self.logger.info("  ‚úÖ –°–æ–∑–¥–∞–Ω–æ 20 —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –±–µ–∑ —É—Ç–µ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö")
            self.logger.info("  üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π:")
            for period in ["15m", "1h", "4h", "12h"]:
                if f"direction_{period}" in df.columns:
                    dist = df[f"direction_{period}"].value_counts(normalize=True) * 100
                    self.logger.info(
                        f"     {period}: UP={dist.get('UP', 0):.1f}%, DOWN={dist.get('DOWN', 0):.1f}%, FLAT={dist.get('FLAT', 0):.1f}%"
                    )

        return df

    def _normalize_walk_forward(self, df: pd.DataFrame, train_end_date: str) -> pd.DataFrame:
        """Walk-forward –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RobustScaler"""
        if not self.disable_progress:
            self.logger.info(f"üìä Walk-forward –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å –≥—Ä–∞–Ω–∏—Ü–µ–π: {train_end_date}")

        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        train_mask = df["datetime"] <= pd.to_datetime(train_end_date)
        test_mask = ~train_mask

        # –°—Ç–æ–ª–±—Ü—ã –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        exclude_cols = [
            "id",
            "symbol",
            "timestamp",
            "datetime",
            "sector",
            "open",
            "high",
            "low",
            "close",
            "volume",
            "turnover",
        ]

        # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        target_cols = [
            col
            for col in df.columns
            if col.startswith(("future_", "direction_", "long_will_reach_", "short_will_reach_"))
        ]
        exclude_cols.extend(target_cols)

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã)
        time_cols = [
            "hour",
            "minute",
            "dayofweek",
            "day",
            "month",
            "is_weekend",
            "asian_session",
            "european_session",
            "american_session",
            "session_overlap",
        ]
        exclude_cols.extend(time_cols)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        feature_cols = [col for col in numeric_cols if col not in exclude_cols]

        if not self.disable_progress:
            self.logger.info(
                f"–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º {len(feature_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {df['symbol'].nunique()} —Å–∏–º–≤–æ–ª–æ–≤"
            )

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        for symbol in df["symbol"].unique():
            symbol_mask = df["symbol"] == symbol
            train_symbol_mask = train_mask & symbol_mask
            test_symbol_mask = test_mask & symbol_mask

            if train_symbol_mask.sum() == 0:
                continue

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RobustScaler –¥–ª—è —Å–∏–º–≤–æ–ª–∞
            if symbol not in self.scalers:
                self.scalers[symbol] = RobustScaler()

            # –ü–æ–ª—É—á–∞–µ–º train –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è scaler
            train_data = df.loc[train_symbol_mask, feature_cols].dropna()

            if len(train_data) > 0:
                # –û–±—É—á–∞–µ–º scaler —Ç–æ–ª—å–∫–æ –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö
                self.scalers[symbol].fit(train_data)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ train –¥–∞–Ω–Ω—ã–º
                if train_symbol_mask.sum() > 0:
                    train_to_scale = df.loc[train_symbol_mask, feature_cols].fillna(0)
                    df.loc[train_symbol_mask, feature_cols] = self.scalers[symbol].transform(
                        train_to_scale
                    )

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ test –¥–∞–Ω–Ω—ã–º
                if test_symbol_mask.sum() > 0:
                    test_to_scale = df.loc[test_symbol_mask, feature_cols].fillna(0)
                    df.loc[test_symbol_mask, feature_cols] = self.scalers[symbol].transform(
                        test_to_scale
                    )

        if not self.disable_progress:
            self.logger.info("‚úÖ Walk-forward –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

        return df

    def _log_feature_statistics(self, df: pd.DataFrame):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º"""
        if not self.disable_progress:
            feature_counts = {
                "basic": len(
                    [
                        col
                        for col in df.columns
                        if col in ["returns", "high_low_ratio", "close_open_ratio", "volume_ratio"]
                    ]
                ),
                "technical": len(
                    [
                        col
                        for col in df.columns
                        if any(ind in col for ind in ["sma", "ema", "rsi", "macd", "bb", "atr"])
                    ]
                ),
                "microstructure": len(
                    [
                        col
                        for col in df.columns
                        if any(
                            ms in col for ms in ["spread", "imbalance", "toxicity", "illiquidity"]
                        )
                    ]
                ),
                "temporal": len(
                    [
                        col
                        for col in df.columns
                        if any(t in col for t in ["hour", "day", "month", "session"])
                    ]
                ),
                "cross_asset": len(
                    [
                        col
                        for col in df.columns
                        if any(ca in col for ca in ["btc_", "sector", "rank", "momentum"])
                    ]
                ),
            }

            self.logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {feature_counts}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            missing_counts = df.isnull().sum()
            if missing_counts.sum() > 0:
                self.logger.warning(
                    f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ {missing_counts[missing_counts > 0].shape[0]} –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö"
                )

    def get_feature_names(self, include_targets: bool = False) -> list[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        return []

    def save_scalers(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ"""
        import pickle

        with open(path, "wb") as f:
            pickle.dump(self.scalers, f)

        if not self.disable_progress:
            self.logger.info(f"–°–∫–µ–π–ª–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {path}")

    def load_scalers(self, path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤"""
        import pickle

        with open(path, "rb") as f:
            self.scalers = pickle.load(f)

        if not self.disable_progress:
            self.logger.info(f"–°–∫–µ–π–ª–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {path}")

    def _add_enhanced_features(
        self, df: pd.DataFrame, all_symbols_data: dict[str, pd.DataFrame]
    ) -> pd.DataFrame:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è direction prediction

        Args:
            df: DataFrame —Å –±–∞–∑–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            all_symbols_data: —Å–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è cross-asset features

        Returns:
            DataFrame —Å enhanced features
        """
        try:
            from data.enhanced_features import EnhancedFeatureEngineer
        except ImportError:
            self.logger.warning(
                "‚ö†Ô∏è –ú–æ–¥—É–ª—å enhanced_features –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º enhanced features"
            )
            return df

        self.logger.info("üöÄ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ enhanced features –¥–ª—è direction prediction...")

        enhanced_engineer = EnhancedFeatureEngineer()
        enhanced_dfs = []

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª
        for symbol in tqdm(
            df["symbol"].unique(), desc="Enhanced features", disable=self.disable_progress
        ):
            symbol_data = df[df["symbol"] == symbol].copy()

            # –ü—Ä–∏–º–µ–Ω—è–µ–º enhanced features
            enhanced_data = enhanced_engineer.create_enhanced_features(
                symbol_data, all_symbols_data if len(all_symbols_data) > 1 else None
            )

            enhanced_dfs.append(enhanced_data)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        result_df = pd.concat(enhanced_dfs, ignore_index=True)

        # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        original_cols = set(df.columns)
        new_cols = set(result_df.columns) - original_cols

        if new_cols:
            self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_cols)} enhanced features")

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            categories = {
                "market_regime": [col for col in new_cols if "regime" in col or "wyckoff" in col],
                "microstructure": [
                    col for col in new_cols if any(x in col for x in ["ofi", "tick", "imbalance"])
                ],
                "cross_asset": [
                    col for col in new_cols if any(x in col for x in ["btc_", "sector_", "beta_"])
                ],
                "sentiment": [
                    col
                    for col in new_cols
                    if any(x in col for x in ["fear_greed", "panic", "euphoria"])
                ],
            }

            for category, cols in categories.items():
                if cols:
                    self.logger.info(f"  - {category}: {len(cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        return result_df
