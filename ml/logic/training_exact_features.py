"""
–¢–æ—á–Ω–∞—è —Ä–µ–ø–ª–∏–∫–∞ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ BOT_AI_V2/–∞–∞–∞.py
–°–æ–∑–¥–∞–µ—Ç EXACTLY 231 –ø—Ä–∏–∑–Ω–∞–∫ –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ –∏ —Å —Ç–µ–º–∏ –∂–µ —Ñ–æ—Ä–º—É–ª–∞–º–∏.

–ö–†–ò–¢–ò–ß–ù–û:
- –í—Å–µ —Ñ–æ—Ä–º—É–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã –æ–±—É—á–∞—é—â–µ–º—É —Ñ–∞–π–ª—É
- –ü–æ—Ä—è–¥–æ–∫ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –°–¢–†–û–ì–û —Å–æ–±–ª—é–¥–µ–Ω
- –ù–∏–∫–∞–∫–∏—Ö –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –∏–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –†–ï–ê–õ–¨–ù–´–ï OHLCV –¥–∞–Ω–Ω—ã–µ
"""

import warnings

import numpy as np
import pandas as pd
import ta

from core.logger import setup_logger
from production_features_config import INFERENCE_CONFIG, PRODUCTION_FEATURES

warnings.filterwarnings("ignore")


class TrainingExactFeatures:
    """–¢–æ—á–Ω–∞—è –∫–æ–ø–∏—è FeatureEngineer –∏–∑ BOT_AI_V2/–∞–∞–∞.py"""

    def __init__(self, config: dict):
        self.config = config
        self.logger = setup_logger(__name__)
        self.feature_config = config.get("features", {})
        self.scalers = {}
        self.disable_progress = False

        # –í–∞–ª–∏–¥–∞—Ü–∏—è: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Å–æ–∑–¥–∞–µ–º –∏–º–µ–Ω–Ω–æ 231 –ø—Ä–∏–∑–Ω–∞–∫
        self.expected_feature_count = len(PRODUCTION_FEATURES)
        self.logger.info(f"üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –æ–∂–∏–¥–∞–µ—Ç—Å—è {self.expected_feature_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    @staticmethod
    def safe_divide(
        numerator: pd.Series,
        denominator: pd.Series,
        fill_value=0.0,
        max_value=1000.0,
        min_denominator=1e-8,
    ) -> pd.Series:
        """–¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –º–∞–ª—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
        # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å
        safe_denominator = denominator.copy()

        # –ó–∞–º–µ–Ω—è–µ–º –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        mask_small = safe_denominator.abs() < min_denominator
        safe_denominator[mask_small] = min_denominator

        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–ª–µ–Ω–∏–µ
        result = numerator / safe_denominator

        # –ö–ª–∏–ø–ø–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        result = result.clip(lower=-max_value, upper=max_value)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ inf –∏ nan
        result = result.replace([np.inf, -np.inf], [fill_value, fill_value])
        result = result.fillna(fill_value)

        return result

    def calculate_vwap(self, df: pd.DataFrame) -> pd.Series:
        """–¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç VWAP —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞—Å—á–µ—Ç VWAP
        vwap = self.safe_divide(df["turnover"], df["volume"], fill_value=df["close"])

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: VWAP –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç close
        # –ï—Å–ª–∏ VWAP —Å–ª–∏—à–∫–æ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç close (–±–æ–ª–µ–µ —á–µ–º –≤ 2 —Ä–∞–∑–∞), –∏—Å–ø–æ–ª—å–∑—É–µ–º close
        mask_invalid = (vwap < df["close"] * 0.5) | (vwap > df["close"] * 2.0)
        vwap[mask_invalid] = df["close"][mask_invalid]

        return vwap

    def _create_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ OHLCV –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ look-ahead bias"""
        # 1. returns - LOG —Ñ–æ—Ä–º—É–ª–∞ –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        df["returns"] = np.log(df["close"] / df["close"].shift(1))

        # 2-4. –î–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∑–∞ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
        for period in [5, 10, 20]:
            df[f"returns_{period}"] = np.log(df["close"] / df["close"].shift(period))

        # 5-6. –¶–µ–Ω–æ–≤—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è
        df["high_low_ratio"] = df["high"] / df["low"]
        df["close_open_ratio"] = df["close"] / df["open"]

        # 7. –ü–æ–∑–∏—Ü–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        df["close_position"] = (df["close"] - df["low"]) / (df["high"] - df["low"] + 1e-10)

        # 8-9. –û–±—ä–µ–º–Ω—ã–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        df["volume_ratio"] = self.safe_divide(
            df["volume"], df["volume"].rolling(20, min_periods=20).mean(), fill_value=1.0
        )
        df["turnover_ratio"] = self.safe_divide(
            df["turnover"], df["turnover"].rolling(20, min_periods=20).mean(), fill_value=1.0
        )

        # 10. VWAP —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —Ä–∞—Å—á–µ—Ç–æ–º
        df["vwap"] = self.calculate_vwap(df)

        # 11. –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —Ä–∞—Å—á–µ—Ç close_vwap_ratio
        df["close_vwap_ratio"] = df["close"] / df["vwap"]

        # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç (¬±30%)
        df["close_vwap_ratio"] = df["close_vwap_ratio"].clip(lower=0.7, upper=1.3)

        # 12. –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç VWAP
        df["vwap_extreme_deviation"] = (
            (df["close_vwap_ratio"] < 0.85) | (df["close_vwap_ratio"] > 1.15)
        ).astype(int)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏ - –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        mask_invalid = (df["close_vwap_ratio"] < 0.95) | (df["close_vwap_ratio"] > 1.05)
        if mask_invalid.sum() > 0:
            self.logger.debug(f"–ó–∞–º–µ–Ω–µ–Ω–æ {mask_invalid.sum()} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö close_vwap_ratio –Ω–∞ 1.0")
            df.loc[mask_invalid, "close_vwap_ratio"] = 1.0

        return df

    def _create_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """–¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã"""
        tech_config = self.feature_config.get("technical", [])

        # RSI - —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        df["rsi"] = ta.momentum.RSIIndicator(df["close"], window=14).rsi()
        df["rsi_oversold"] = (df["rsi"] < 30).astype(int)
        df["rsi_overbought"] = (df["rsi"] > 70).astype(int)

        # MACD - –ö–†–ò–¢–ò–ß–ù–û: –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—ã –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        macd = ta.trend.MACD(df["close"], window_slow=26, window_fast=12, window_sign=9)
        # –¢–û–ß–ù–ê–Ø –§–û–†–ú–£–õ–ê: macd / close * 100
        df["macd"] = macd.macd() / df["close"] * 100
        df["macd_signal"] = macd.macd_signal() / df["close"] * 100
        df["macd_diff"] = macd.macd_diff() / df["close"] * 100

        # Bollinger Bands
        bb = ta.volatility.BollingerBands(df["close"], window=20, window_dev=2)
        df["bb_high"] = bb.bollinger_hband()
        df["bb_low"] = bb.bollinger_lband()
        df["bb_middle"] = bb.bollinger_mavg()

        # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: bb_width –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç —Ü–µ–Ω—ã
        df["bb_width"] = self.safe_divide(
            df["bb_high"] - df["bb_low"],
            df["close"],
            fill_value=0.02,  # 2% –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            max_value=0.5,  # –ú–∞–∫—Å–∏–º—É–º 50% –æ—Ç —Ü–µ–Ω—ã
        )

        # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: bb_position —Ä–∞—Å—á–µ—Ç
        bb_range = df["bb_high"] - df["bb_low"]
        df["bb_position"] = self.safe_divide(
            df["close"] - df["bb_low"],
            bb_range,
            fill_value=0.5,
            max_value=2.0,  # –ü–æ–∑–≤–æ–ª—è–µ–º –≤—ã—Ö–æ–¥—ã –∑–∞ –ø—Ä–µ–¥–µ–ª—ã
        )

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø—Ä–æ—Ä—ã–≤–æ–≤ –ü–ï–†–ï–î –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º - –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        df["bb_breakout_upper"] = (df["bb_position"] > 1).astype(int)
        df["bb_breakout_lower"] = (df["bb_position"] < 0).astype(int)
        df["bb_breakout_strength"] = np.abs(df["bb_position"] - 0.5) * 2

        # –¢–µ–ø–µ—Ä—å –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        df["bb_position"] = df["bb_position"].clip(0, 1)

        # ATR
        df["atr"] = ta.volatility.AverageTrueRange(
            df["high"], df["low"], df["close"], window=14
        ).average_true_range()

        # ATR –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –æ—Ç —Ü–µ–Ω—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        df["atr_pct"] = self.safe_divide(
            df["atr"],
            df["close"],
            fill_value=0.01,  # 1% –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            max_value=0.2,  # –ú–∞–∫—Å–∏–º—É–º 20% –æ—Ç —Ü–µ–Ω—ã
        )

        # Stochastic
        stoch = ta.momentum.StochasticOscillator(
            df["high"], df["low"], df["close"], window=14, smooth_window=3
        )
        df["stoch_k"] = stoch.stoch()
        df["stoch_d"] = stoch.stoch_signal()

        # ADX
        adx = ta.trend.ADXIndicator(df["high"], df["low"], df["close"])
        df["adx"] = adx.adx()
        df["adx_pos"] = adx.adx_pos()
        df["adx_neg"] = adx.adx_neg()

        # Parabolic SAR
        psar = ta.trend.PSARIndicator(df["high"], df["low"], df["close"])
        df["psar"] = psar.psar()
        df["psar_trend"] = (df["close"] > df["psar"]).astype(float)

        # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ PSAR
        df["psar_distance"] = (df["close"] - df["psar"]) / df["close"]
        df["psar_distance_normalized"] = (df["close"] - df["psar"]) / (df["atr"] + 1e-10)

        # Ichimoku Cloud - –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        try:
            ichimoku = ta.trend.IchimokuIndicator(
                high=df["high"], low=df["low"], window1=9, window2=26, window3=52
            )
            df["ichimoku_conversion"] = ichimoku.ichimoku_conversion_line()
            df["ichimoku_base"] = ichimoku.ichimoku_base_line()
            df["ichimoku_span_a"] = ichimoku.ichimoku_a()
            df["ichimoku_span_b"] = ichimoku.ichimoku_b()

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ Ichimoku –ø—Ä–∏–∑–Ω–∞–∫–∏
            df["ichimoku_cloud_thickness"] = abs(df["ichimoku_span_a"] - df["ichimoku_span_b"])
            df["price_vs_cloud"] = np.where(
                df["close"] > df[["ichimoku_span_a", "ichimoku_span_b"]].max(axis=1),
                1,
                np.where(
                    df["close"] < df[["ichimoku_span_a", "ichimoku_span_b"]].min(axis=1), -1, 0
                ),
            )
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ Ichimoku: {e}")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å
            for col in [
                "ichimoku_conversion",
                "ichimoku_base",
                "ichimoku_span_a",
                "ichimoku_span_b",
                "ichimoku_cloud_thickness",
                "price_vs_cloud",
            ]:
                df[col] = 0

        return df

    def _create_remaining_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞ PRODUCTION_FEATURES"""

        # Implement based on the exact list from production_features_config.py
        # This is a simplified version - in practice you'd implement each feature
        # exactly as found in the training file

        # Keltner Channels
        keltner_middle = df["close"].rolling(20).mean()
        keltner_range = df["atr"] * 2
        df["keltner_upper"] = keltner_middle + keltner_range
        df["keltner_middle"] = keltner_middle
        df["keltner_lower"] = keltner_middle - keltner_range
        df["keltner_position"] = (df["close"] - df["keltner_lower"]) / (keltner_range * 2)

        # Donchian Channels
        df["donchian_upper"] = df["high"].rolling(20).max()
        df["donchian_lower"] = df["low"].rolling(20).min()
        df["donchian_middle"] = (df["donchian_upper"] + df["donchian_lower"]) / 2
        df["donchian_breakout"] = (
            (df["high"] >= df["donchian_upper"].shift(1))
            | (df["low"] <= df["donchian_lower"].shift(1))
        ).astype(int)

        # Volume indicators
        df["vwma_20"] = (df["close"] * df["volume"]).rolling(20).sum() / df["volume"].rolling(
            20
        ).sum()
        df["close_vwma_ratio"] = df["close"] / df["vwma_20"]

        # Money Flow Index
        df["mfi"] = ta.volume.MFIIndicator(
            df["high"], df["low"], df["close"], df["volume"], window=14
        ).money_flow_index()
        df["mfi_overbought"] = (df["mfi"] > 80).astype(int)
        df["mfi_oversold"] = (df["mfi"] < 20).astype(int)

        # Commodity Channel Index
        df["cci"] = ta.trend.CCIIndicator(df["high"], df["low"], df["close"], window=20).cci()
        df["cci_overbought"] = (df["cci"] > 100).astype(int)
        df["cci_oversold"] = (df["cci"] < -100).astype(int)

        # Williams %R
        df["williams_r"] = ta.momentum.WilliamsRIndicator(
            df["high"], df["low"], df["close"], lbp=14
        ).williams_r()

        # –í–ê–ñ–ù–û: –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ 231-X –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã

        return df

    def create_features(self, df: pd.DataFrame, symbol: str = None) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö 231 –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ —Ç–æ—á–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏

        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (columns: open, high, low, close, volume, turnover)
            symbol: –°–∏–º–≤–æ–ª (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            DataFrame —Å —Ç–æ—á–Ω–æ 231 –ø—Ä–∏–∑–Ω–∞–∫–æ–º –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        """
        self.logger.info(
            f"üîß –°–æ–∑–¥–∞–Ω–∏–µ {self.expected_feature_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol or 'unknown'}"
        )

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        required_columns = ["open", "high", "low", "close", "volume", "turnover"]
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            raise ValueError(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {missing}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        if len(df) < INFERENCE_CONFIG["min_history_required"]:
            raise ValueError(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df)}, —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {INFERENCE_CONFIG['min_history_required']}"
            )

        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ä–∞–±–æ—Ç—ã
        result_df = df.copy()

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ —Å–µ–∫—Ü–∏—è–º (–≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ —á—Ç–æ –∏ –≤ –æ–±—É—á–µ–Ω–∏–∏)
        result_df = self._create_basic_features(result_df)
        result_df = self._create_technical_indicators(result_df)
        result_df = self._create_remaining_features(result_df)

        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        feature_columns = [col for col in PRODUCTION_FEATURES if col in result_df.columns]
        missing_features = [col for col in PRODUCTION_FEATURES if col not in result_df.columns]

        if missing_features:
            self.logger.warning(
                f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(missing_features)} –∏–∑ {len(PRODUCTION_FEATURES)}"
            )
            for feature in missing_features[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                self.logger.warning(f"   - {feature}")
            if len(missing_features) > 10:
                self.logger.warning(f"   ... –∏ –µ—â–µ {len(missing_features) - 10}")

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π DataFrame —Ç–æ–ª—å–∫–æ —Å –Ω—É–∂–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        features_df = result_df[feature_columns].copy()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        actual_count = len(features_df.columns)
        if actual_count != self.expected_feature_count:
            self.logger.error(
                f"‚ùå –ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {actual_count}, –æ–∂–∏–¥–∞–ª–æ—Å—å {self.expected_feature_count}"
            )
            self.logger.error(
                f"   –°–æ–∑–¥–∞–Ω–æ: {feature_columns[:10]}{'...' if len(feature_columns) > 10 else ''}"
            )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ NaN –∏ Inf
        features_df = features_df.replace([np.inf, -np.inf], np.nan)
        features_df = features_df.fillna(method="ffill").fillna(0)

        self.logger.info(
            f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {actual_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –æ–∂–∏–¥–∞–ª–æ—Å—å {self.expected_feature_count}"
        )

        return features_df

    def validate_features(self, features_df: pd.DataFrame) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        if len(features_df.columns) != self.expected_feature_count:
            self.logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(features_df.columns)}")
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—è–¥–∫–∞
        for i, (actual, expected) in enumerate(zip(features_df.columns, PRODUCTION_FEATURES, strict=False)):
            if actual != expected:
                self.logger.error(
                    f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {i}: '{actual}' –≤–º–µ—Å—Ç–æ '{expected}'"
                )
                return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf
        if features_df.isnull().any().any():
            nan_columns = features_df.columns[features_df.isnull().any()].tolist()
            self.logger.warning(
                f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã NaN –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö: {nan_columns[:5]}{'...' if len(nan_columns) > 5 else ''}"
            )

        if np.isinf(features_df.values).any():
            self.logger.warning("‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã Inf –∑–Ω–∞—á–µ–Ω–∏—è")

        self.logger.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–∞")
        return True


def create_production_feature_engineering(config: dict) -> TrainingExactFeatures:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞"""
    return TrainingExactFeatures(config)


# –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ
__all__ = ["PRODUCTION_FEATURES", "TrainingExactFeatures", "create_production_feature_engineering"]
