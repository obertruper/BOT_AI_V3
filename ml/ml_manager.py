#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ML Manager –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è PatchTST –º–æ–¥–µ–ª—å—é –≤ BOT Trading v3
"""

import os
import pickle
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Union

import numpy as np
import pandas as pd
import torch

from core.logger import setup_logger
from ml.logic.feature_engineering import (  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å 240+ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    FeatureEngineer,
)
from ml.logic.patchtst_model import create_unified_model

logger = setup_logger("ml_manager")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ GPU –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
if torch.cuda.is_available():
    try:
        # Benchmark mode –¥–ª—è cudnn
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.enabled = True

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ float32 matmul precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö GPU
        # torch.set_float32_matmul_precision('high')  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ –∏–∑-–∑–∞ warning

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Ampere+ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (RTX 5090)
        # torch.backends.cuda.matmul.allow_tf32 = True  # Deprecated
        # torch.backends.cudnn.allow_tf32 = True  # Deprecated

        logger.info("‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã")
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")


class MLManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è ML –º–æ–¥–µ–ª—è–º–∏ –≤ —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ.
    –†–∞–±–æ—Ç–∞–µ—Ç —Å PatchTST –º–æ–¥–µ–ª—å—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏–π —Ä—ã–Ω–∫–∞.
    """

    def __init__(self, config: Dict[str, Any]):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–µ–Ω–µ–¥–∂–µ—Ä–∞.

        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        """
        self.config = config
        self.model = None
        self.scaler = None
        self.feature_engineer = None
        # –ü–æ–ª—É—á–∞–µ–º device –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        device_config = config.get("ml", {}).get("model", {}).get("device", "auto")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPU —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        if device_config == "auto":
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CUDA
                if torch.cuda.is_available():
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
                    gpu_count = torch.cuda.device_count()
                    if gpu_count > 0:
                        # –í—ã–±–∏—Ä–∞–µ–º GPU —Å –Ω–∞–∏–º–µ–Ω—å—à–µ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –ø–∞–º—è—Ç–∏
                        best_gpu = 0
                        min_memory_used = float("inf")

                        for i in range(gpu_count):
                            try:
                                torch.cuda.set_device(i)
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å GPU
                                props = torch.cuda.get_device_properties(i)
                                logger.info(
                                    f"GPU {i}: {props.name}, "
                                    f"Compute Capability: {props.major}.{props.minor}, "
                                    f"Memory: {props.total_memory / 1024**3:.1f}GB"
                                )

                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
                                if torch.cuda.memory_allocated(i) < min_memory_used:
                                    min_memory_used = torch.cuda.memory_allocated(i)
                                    best_gpu = i
                            except Exception as gpu_error:
                                logger.warning(f"GPU {i} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_error}")
                                continue

                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª—É—á—à–∏–π GPU
                        torch.cuda.set_device(best_gpu)
                        self.device = torch.device(f"cuda:{best_gpu}")

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å GPU —Ç–µ—Å—Ç–æ–≤—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º
                        test_tensor = torch.zeros(1, 1).to(self.device)
                        _ = test_tensor * 2  # –ü—Ä–æ—Å—Ç–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

                        # RTX 5090 (Blackwell) –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
                        # - GPU –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ–Ω –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ —Å–∏—Å—Ç–µ–º—ã
                        # - torch.compile –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É sm_120
                        # - –≠—Ç–æ –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
                        gpu_name = props.name.upper()
                        if "RTX 5090" in gpu_name or props.major >= 12:
                            logger.info(
                                f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω RTX 5090 ({gpu_name}, sm_{props.major}{props.minor})"
                            )
                            logger.warning(
                                "‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è RTX 5090 (sm_120) - –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π PyTorch. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –∏ –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å."
                            )
                            # –û—Ç–∫–ª—é—á–∞–µ–º –∫–æ–º–ø–∏–ª—è—Ü–∏—é –¥–ª—è –Ω–æ–≤—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
                            os.environ["TORCH_COMPILE_DISABLE"] = "1"

                        logger.info(
                            f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω GPU {best_gpu} ({props.name})"
                        )
                        logger.info(
                            f"üíæ GPU –ø–∞–º—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞: {props.total_memory / 1024**3:.2f} GB"
                        )
                    else:
                        logger.warning("CUDA –¥–æ—Å—Ç—É–ø–Ω–∞, –Ω–æ GPU –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                        self.device = torch.device("cpu")
                else:
                    logger.info("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                    self.device = torch.device("cpu")

            except Exception as e:
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GPU: {type(e).__name__}: {e}")
                logger.info("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ CPU")
                self.device = torch.device("cpu")

                # –û—á–∏—â–∞–µ–º CUDA –∫–µ—à –ø—Ä–∏ –æ—à–∏–±–∫–µ
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        else:
            # –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ device
            try:
                self.device = torch.device(device_config)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
                if "cuda" in device_config:
                    test_tensor = torch.zeros(1, 1).to(self.device)
                    _ = test_tensor * 2
                logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω device: {device_config}")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å device {device_config}: {e}")
                self.device = torch.device("cpu")

        # –§–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self._initialized = False

        # –ö—ç—à –º–æ–¥–µ–ª–µ–π (–¥–ª—è MLManager —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏)
        self._model_cache = {}
        self._cache_size = config.get("ml", {}).get("model_cache_size", 3)
        self._memory_limit = config.get("ml", {}).get("memory_limit_mb", 1024)

        # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏
        base_dir = Path(__file__).parent.parent  # –ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
        model_dir = base_dir / config.get("ml", {}).get(
            "model_directory", "models/saved"
        )
        self.model_path = model_dir / "best_model_20250728_215703.pth"
        self.scaler_path = model_dir / "data_scaler.pkl"

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.context_length = 96  # 24 —á–∞—Å–∞ –ø—Ä–∏ 15-–º–∏–Ω—É—Ç–Ω—ã—Ö —Å–≤–µ—á–∞—Ö
        self.num_features = 240  # –í–µ—Ä–Ω—É–ª–∏ –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –º–æ–¥–µ–ª—å—é
        self.num_targets = 20  # –ú–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç 20 –≤—ã—Ö–æ–¥–æ–≤

        logger.info(f"MLManager initialized, device: {self.device}")

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            await self._load_model()

            # –ó–∞–≥—Ä—É–∂–∞–µ–º scaler
            await self._load_scaler()

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º feature engineer
            self.feature_engineer = FeatureEngineer(self.config)

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            self._initialized = True

            logger.info("ML components initialized successfully")

        except Exception as e:
            logger.error(f"Error initializing ML components: {e}")
            raise

    async def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ PatchTST –º–æ–¥–µ–ª–∏"""
        try:
            if not self.model_path.exists():
                raise FileNotFoundError(f"Model file not found: {self.model_path}")

            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            model_config = {
                "model": {
                    "input_size": self.num_features,  # 98 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    "output_size": self.num_targets,  # 20 –≤—ã—Ö–æ–¥–æ–≤
                    "context_window": self.context_length,  # 96 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫
                    "patch_len": 16,
                    "stride": 8,
                    "d_model": 256,  # –°–æ–≥–ª–∞—Å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                    "n_heads": 4,
                    "e_layers": 3,
                    "d_ff": 512,
                    "dropout": 0.1,
                    "temperature_scaling": True,
                    "temperature": 2.0,
                }
            }
            self.model = create_unified_model(model_config)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π CUDA –æ—à–∏–±–æ–∫
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                checkpoint = torch.load(self.model_path, map_location=self.device)
            except Exception as cuda_error:
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ CUDA, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ CPU
                logger.warning(
                    f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ {self.device}, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU: {cuda_error}"
                )
                checkpoint = torch.load(
                    self.model_path, map_location=torch.device("cpu")
                )
                self.device = torch.device("cpu")

            self.model.load_state_dict(checkpoint["model_state_dict"])

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            try:
                self.model.to(self.device)
            except Exception as e:
                logger.warning(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ {self.device}, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU: {e}"
                )
                self.device = torch.device("cpu")
                self.model.to(self.device)

            self.model.eval()

            logger.info(f"Model loaded successfully from {self.model_path}")

        except Exception as e:
            logger.error(f"Error loading model: {e}")
            raise

    async def _load_scaler(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ scaler –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if not self.scaler_path.exists():
                raise FileNotFoundError(f"Scaler file not found: {self.scaler_path}")

            with open(self.scaler_path, "rb") as f:
                self.scaler = pickle.load(f)

            logger.info(f"Scaler loaded successfully from {self.scaler_path}")

        except Exception as e:
            logger.error(f"Error loading scaler: {e}")
            raise

    async def predict(
        self, input_data: Union[pd.DataFrame, np.ndarray]
    ) -> Dict[str, Any]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            input_data: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–º–∏–Ω–∏–º—É–º 96 —Å–≤–µ—á–µ–π) –∏–ª–∏ numpy array —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

        Returns:
            Dict —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
            if not self._initialized or self.model is None:
                raise ValueError("ML model not initialized. Call initialize() first.")

            # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not isinstance(input_data, (pd.DataFrame, np.ndarray)):
                raise TypeError(
                    f"input_data must be pd.DataFrame or np.ndarray, got {type(input_data)}"
                )

            # –ï—Å–ª–∏ —ç—Ç–æ numpy array - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å (—É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
            if isinstance(input_data, np.ndarray):
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º 3D –º–∞—Å—Å–∏–≤—ã (batch_size, sequence_length, features)
                if input_data.ndim == 3:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –æ–¥–∏–Ω–æ—á–Ω—ã–π –±–∞—Ç—á
                    if input_data.shape[0] == 1:
                        input_data = input_data.squeeze(0)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ
                    else:
                        raise ValueError(
                            f"Expected single batch, got batch_size={input_data.shape[0]}"
                        )

                # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º 2D —Ñ–æ—Ä–º—É
                if (
                    input_data.shape[0] != self.context_length
                    or input_data.shape[1] != self.num_features
                ):
                    raise ValueError(
                        f"Expected shape ({self.context_length}, {self.num_features}), got {input_data.shape}"
                    )
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º numpy array —Å –ø–æ–º–æ—â—å—é scaler
                features_scaled = self.scaler.transform(input_data)
                logger.info("‚úÖ Numpy array –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω —Å –ø–æ–º–æ—â—å—é scaler")

            # –ï—Å–ª–∏ —ç—Ç–æ DataFrame - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ OHLCV –¥–∞–Ω–Ω—ã–µ
            else:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame —Å async/await –ª–æ–≥–∏–∫–æ–π
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
                if len(input_data) < self.context_length:
                    raise ValueError(
                        f"Need at least {self.context_length} candles, got {len(input_data)}"
                    )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ symbol
                if "symbol" not in input_data.columns:
                    logger.warning(
                        "‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'symbol' –≤ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö! –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ—Ç–æ—á–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º."
                    )
                    input_data = input_data.copy()
                    input_data["symbol"] = (
                        "UNKNOWN_SYMBOL"  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª
                    )

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ - —Ç–µ–ø–µ—Ä—å —ç—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
                features_result = self.feature_engineer.create_features(input_data)

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –º–æ–∂–µ—Ç –±—ã—Ç—å DataFrame –∏–ª–∏ ndarray
                if isinstance(features_result, pd.DataFrame):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ DataFrame
                    numeric_cols = features_result.select_dtypes(
                        include=[np.number]
                    ).columns
                    # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    feature_cols = [
                        col
                        for col in numeric_cols
                        if not col.startswith(("future_", "direction_", "profit_"))
                        and col not in ["id", "timestamp", "datetime", "symbol"]
                    ]
                    features_array = features_result[feature_cols].values

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    if features_array.shape[1] != self.num_features:
                        logger.warning(
                            f"Feature count mismatch: expected {self.num_features}, got {features_array.shape[1]}"
                        )
                        # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±–æ–ª—å—à–µ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ num_features
                        if features_array.shape[1] > self.num_features:
                            features_array = features_array[:, : self.num_features]
                        else:
                            # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ - –¥–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                            padding = np.zeros(
                                (
                                    features_array.shape[0],
                                    self.num_features - features_array.shape[1],
                                )
                            )
                            features_array = np.hstack([features_array, padding])

                elif isinstance(features_result, np.ndarray):
                    features_array = features_result
                else:
                    raise ValueError(
                        f"Expected DataFrame or np.ndarray from create_features, got {type(features_result)}"
                    )

                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ context_length —Å—Ç—Ä–æ–∫
                if len(features_array) >= self.context_length:
                    features = features_array[-self.context_length :]
                else:
                    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ - –¥–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ (padding)
                    padding_size = self.context_length - len(features_array)
                    padding = np.zeros((padding_size, features_array.shape[1]))
                    features = np.vstack([padding, features_array])

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ scaler
                features_scaled = self.scaler.transform(features)
                logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã —Å –ø–æ–º–æ—â—å—é scaler")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
            x = torch.FloatTensor(features_scaled).unsqueeze(0).to(self.device)

            # –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –í–•–û–î–ù–´–• –î–ê–ù–ù–´–•
            logger.warning(
                f"""
üîç ML –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï - –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä Feature Statistics:
   Shape: {features_scaled.shape}
   Min: {features_scaled.min():.6f}
   Max: {features_scaled.max():.6f}
   Mean: {features_scaled.mean():.6f}
   Std: {features_scaled.std():.6f}

üìà –ü–µ—Ä–≤—ã–µ 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ç–æ—á–∫–∞):
   {features_scaled[-1, :10]}

üéØ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö:
   NaN count: {np.isnan(features_scaled).sum()}
   Inf count: {np.isinf(features_scaled).sum()}
   Zero variance features: {(features_scaled.std(axis=0) < 1e-6).sum()}
   üîç Variance statistics:
     Min std: {features_scaled.std(axis=0).min():.8f}
     Max std: {features_scaled.std(axis=0).max():.8f}
     Mean std: {features_scaled.std(axis=0).mean():.8f}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""
            )
            logger.debug(f"Input tensor shape: {x.shape}")

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ inference
            if self.device.type == "cuda":
                gpu_memory_before = (
                    torch.cuda.memory_allocated(self.device) / 1024**2
                )  # MB
                gpu_memory_cached = (
                    torch.cuda.memory_reserved(self.device) / 1024**2
                )  # MB
                logger.debug(
                    f"GPU Memory before inference: {gpu_memory_before:.1f}MB allocated, {gpu_memory_cached:.1f}MB cached"
                )

            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏
            import time

            start_time = time.time()

            with torch.no_grad():
                outputs = self.model(x)

            inference_time = (time.time() - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ inference
            if self.device.type == "cuda":
                gpu_memory_after = (
                    torch.cuda.memory_allocated(self.device) / 1024**2
                )  # MB
                logger.debug(
                    f"GPU Memory after inference: {gpu_memory_after:.1f}MB allocated"
                )
                logger.info(f"Inference time: {inference_time:.1f}ms on {self.device}")

            # –û—Ç–ª–∞–¥–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏
            outputs_np = outputs.cpu().numpy()[0]
            logger.debug(
                f"Model outputs: min={outputs_np.min():.3f}, max={outputs_np.max():.3f}, mean={outputs_np.mean():.3f}"
            )
            logger.debug(f"Model outputs sample: {outputs_np[:10]}")

            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            predictions = self._interpret_predictions(outputs)

            logger.info(f"ML Manager –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions}")
            return predictions

        except Exception as e:
            logger.error(f"Error making prediction: {e}")
            raise

    def _interpret_predictions(self, outputs: torch.Tensor) -> Dict[str, Any]:
        """
        –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏.

        Args:
            outputs: –¢–µ–Ω–∑–æ—Ä —Å 32 –≤—ã—Ö–æ–¥–∞–º–∏ –º–æ–¥–µ–ª–∏

        Returns:
            Dict —Å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        """
        outputs_np = outputs.cpu().numpy()[0]

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–æ–≤ (20 –∑–Ω–∞—á–µ–Ω–∏–π):
        # 0-3: future returns (15m, 1h, 4h, 12h)
        # 4-15: direction logits (12 values = 3 classes √ó 4 timeframes)
        # 16-19: risk metrics

        # –í–ê–ñ–ù–û: –≤ –º–æ–¥–µ–ª–∏ —Å 20 –≤—ã—Ö–æ–¥–∞–º–∏ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö long/short levels!
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º future returns –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —É—Ä–æ–≤–Ω–µ–π

        future_returns = outputs_np[0:4]
        direction_logits = outputs_np[4:16]  # 12 –∑–Ω–∞—á–µ–Ω–∏–π!
        risk_metrics = outputs_np[16:20]

        # –í –º–æ–¥–µ–ª–∏ —Å 20 –≤—ã—Ö–æ–¥–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º future_returns –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —É—Ä–æ–≤–Ω–µ–π
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è SL/TP
        long_levels = future_returns  # –ò—Å–ø–æ–ª—å–∑—É–µ–º future returns –∫–∞–∫ –±–∞–∑—É –¥–ª—è —É—Ä–æ–≤–Ω–µ–π
        short_levels = -future_returns  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ–∑–∏—Ü–∏–π

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º risk_metrics –∫–∞–∫ confidence_scores
        # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∫–∞–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å—Ä–µ–¥–∏ –∫–ª–∞—Å—Å–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        confidence_scores = np.zeros(4)
        for i in range(4):
            logits = direction_logits[i * 3 : (i + 1) * 3]
            probs = np.exp(logits) / np.sum(np.exp(logits))
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence_scores[i] = np.max(probs)

        # –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
        logger.warning(
            f"""
üîç ML –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä Raw Model Outputs (–≤—Å–µ 20 –∑–Ω–∞—á–µ–Ω–∏–π):
   {outputs_np}

üìà Future Returns (0-3):
   15m: {future_returns[0]:.6f}
   1h:  {future_returns[1]:.6f}
   4h:  {future_returns[2]:.6f}
   12h: {future_returns[3]:.6f}

üéØ Direction Logits (4-15) - 12 –∑–Ω–∞—á–µ–Ω–∏–π:
   Raw logits: {direction_logits}
   –°—Ç—Ä—É–∫—Ç—É—Ä–∞: 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞ (LONG=0, SHORT=1, NEUTRAL=2)

‚ö° Risk Metrics (16-19):
   {risk_metrics}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""
        )

        # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø DIRECTIONS (12 –∑–Ω–∞—á–µ–Ω–∏–π = 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞)
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ 4 –≥—Ä—É–ø–ø—ã –ø–æ 3 –ª–æ–≥–∏—Ç–∞
        direction_logits_reshaped = direction_logits.reshape(
            4, 3
        )  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞

        # –ü—Ä–∏–º–µ–Ω—è–µ–º softmax –∫ –∫–∞–∂–¥–æ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
        directions = []
        direction_probs = []

        for i, logits in enumerate(direction_logits_reshaped):
            # Softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            exp_logits = np.exp(logits - np.max(logits))  # –î–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            probs = exp_logits / exp_logits.sum()
            direction_probs.append(probs)

            # Argmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞ (0=LONG, 1=SHORT, 2=NEUTRAL)
            direction_class = np.argmax(probs)
            directions.append(direction_class)

            logger.info(
                f"–¢–∞–π–º—Ñ—Ä–µ–π–º {i + 1}: logits={logits}, probs={probs}, class={direction_class}"
            )

        directions = np.array(directions)
        logger.info(f"Direction predictions: {directions}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∏–≥–Ω–∞–ª
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∫–ª–∞—Å—Å–æ–≤ —Å –±–æ–ª—å—à–∏–º –≤–µ—Å–æ–º –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã
        weights = np.array([0.4, 0.3, 0.2, 0.1])
        weighted_direction = np.sum(directions * weights)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        # –ß–µ–º –±–æ–ª—å—à–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —Å–æ–≥–ª–∞—Å–Ω—ã, —Ç–µ–º —Å–∏–ª—å–Ω–µ–µ —Å–∏–≥–Ω–∞–ª
        direction_counts = np.bincount(directions, minlength=3)
        max_agreement = direction_counts.max() / len(directions)
        signal_strength = max_agreement  # –æ—Ç 0.25 –¥–æ 1.0

        logger.info(f"Weighted direction: {weighted_direction:.3f}")
        logger.info(
            f"Direction counts: LONG={direction_counts[0]}, SHORT={direction_counts[1]}, NEUTRAL={direction_counts[2]}"
        )
        logger.info(f"Signal strength (agreement): {signal_strength:.3f}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª–∏ + —É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
        # –í –æ–±—É—á–µ–Ω–∏–∏: 0=LONG (–ø–æ–∫—É–ø–∫–∞), 1=SHORT (–ø—Ä–æ–¥–∞–∂–∞), 2=FLAT (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ)
        #
        # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –° –£–ß–ï–¢–û–ú –°–ò–õ–´ –°–ò–ì–ù–ê–õ–ê:
        # weighted_direction –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0.0 - 2.0
        # –≥–¥–µ 0.0 = –≤—Å–µ LONG, 1.0 = –≤—Å–µ SHORT, 2.0 = –≤—Å–µ NEUTRAL
        #
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∫–∞–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä
        # –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —Å–æ–≥–ª–∞—Å–Ω—ã - —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª

        # –°—á–∏—Ç–∞–µ–º –≥–æ–ª–æ—Å–∞ –∑–∞ –∫–∞–∂–¥–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
        long_votes = np.sum(directions == 0)
        short_votes = np.sum(directions == 1)
        neutral_votes = np.sum(directions == 2)

        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –ø–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É –≥–æ–ª–æ—Å–æ–≤
        if long_votes >= 3:  # 3+ –∏–∑ 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∑–∞ LONG
            signal_type = "LONG"
        elif short_votes >= 3:  # 3+ –∏–∑ 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∑–∞ SHORT
            signal_type = "SHORT"
        elif neutral_votes >= 3:  # 3+ –∏–∑ 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∑–∞ NEUTRAL
            signal_type = "NEUTRAL"
        else:
            # –ù–µ—Ç —è–≤–Ω–æ–≥–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫—É—é –ª–æ–≥–∏–∫—É
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ç–¥–∞–µ–º —Ç–æ—Ä–≥–æ–≤—ã–º —Å–∏–≥–Ω–∞–ª–∞–º (LONG/SHORT) –Ω–∞–¥ NEUTRAL

            if long_votes > short_votes and long_votes > neutral_votes:
                # LONG –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤
                signal_type = "LONG"
            elif short_votes > long_votes and short_votes > neutral_votes:
                # SHORT –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤
                signal_type = "SHORT"
            elif long_votes == short_votes and long_votes > neutral_votes:
                # LONG –∏ SHORT —Ä–∞–≤–Ω—ã, –Ω–æ –±–æ–ª—å—à–µ NEUTRAL - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
                if weighted_direction < 1.0:
                    signal_type = "LONG"  # –ë–ª–∏–∂–µ –∫ 0 (LONG)
                else:
                    signal_type = "SHORT"  # –ë–ª–∏–∂–µ –∫ 1 (SHORT)
            else:
                # NEUTRAL –ø–æ–±–µ–∂–¥–∞–µ—Ç –∏–ª–∏ –Ω–∏—á—å—è —Å —Ç–æ—Ä–≥–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º—è–≥–∫–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
                if weighted_direction < 0.5:
                    signal_type = "LONG"  # –°–∏–ª—å–Ω—ã–π LONG
                elif weighted_direction > 1.5:
                    signal_type = "NEUTRAL"  # –°–∏–ª—å–Ω—ã–π NEUTRAL
                elif weighted_direction > 1.2:
                    signal_type = "SHORT"  # –£–º–µ—Ä–µ–Ω–Ω—ã–π SHORT
                else:
                    # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –∑–æ–Ω–∞ - —Ä–µ—à–∞–µ–º –ø–æ —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞
                    if signal_strength > 0.4:  # –°–Ω–∏–∂–µ–Ω —Å 0.6
                        # –ü—Ä–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞ –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ—Ä–≥–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                        if weighted_direction < 1.0:
                            signal_type = "LONG"
                        else:
                            signal_type = "SHORT"
                    else:
                        signal_type = "NEUTRAL"

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Ä–æ–≤–Ω–∏ SL/TP –Ω–∞ –æ—Å–Ω–æ–≤–µ future_returns
        # future_returns —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤

        if signal_type == "LONG":
            # –î–ª—è LONG –ø–æ–∑–∏—Ü–∏–π:
            # Stop Loss: –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é (–≤–æ–∑–º–æ–∂–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—É—é) –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
            # Take Profit: –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å

            # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ —Ä–∏—Å–∫ –¥–ª—è stop loss
            min_return = float(np.min(future_returns))
            max_return = float(np.max(future_returns))

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω)
            # Stop Loss: –æ—Ç 1% –¥–æ 5%
            stop_loss_pct = np.clip(abs(min_return) * 100, 1.0, 5.0) / 100.0

            # Take Profit: –æ—Ç 2% –¥–æ 10%
            take_profit_pct = np.clip(max_return * 100, 2.0, 10.0) / 100.0

        elif signal_type == "SHORT":
            # –î–ª—è SHORT –ø–æ–∑–∏—Ü–∏–π –ª–æ–≥–∏–∫–∞ –∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞
            min_return = float(np.min(future_returns))
            max_return = float(np.max(future_returns))

            # Stop Loss –¥–ª—è SHORT = —Ä–∏—Å–∫ —Ä–æ—Å—Ç–∞ —Ü–µ–Ω—ã
            stop_loss_pct = np.clip(abs(max_return) * 100, 1.0, 5.0) / 100.0

            # Take Profit –¥–ª—è SHORT = –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã
            take_profit_pct = np.clip(abs(min_return) * 100, 2.0, 10.0) / 100.0

        else:
            stop_loss_pct = None
            take_profit_pct = None

        # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã SL/TP –±—É–¥—É—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –≤ ml_signal_processor
        # –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –∏ —ç—Ç–∏—Ö –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤

        # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
        avg_risk = float(np.mean(risk_metrics))
        risk_level = "LOW" if avg_risk < 0.3 else "MEDIUM" if avg_risk < 0.7 else "HIGH"

        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        # 1. –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (signal_strength)
        # 2. Confidence scores –æ—Ç –º–æ–¥–µ–ª–∏
        # 3. –†–∏—Å–∫ –º–µ—Ç—Ä–∏–∫

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: confidence_scores —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (0-1), –Ω–µ –Ω—É–∂–µ–Ω sigmoid
        model_confidence = float(np.mean(confidence_scores))

        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Ñ–æ—Ä–º—É–ª–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –±–∞–∑–æ–≤—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        base_confidence = 0.4 if signal_type in ["LONG", "SHORT"] else 0.2

        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        consistency_bonus = 0.0
        max_votes = max(long_votes, short_votes, neutral_votes)
        if signal_type in ["LONG", "SHORT"]:
            # –î–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–∞–µ–º –±–æ–Ω—É—Å –¥–∞–∂–µ –ø—Ä–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ
            consistency_bonus = (
                max_votes - 1
            ) * 0.15  # 0.15 –∑–∞ –∫–∞–∂–¥—ã–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≥–æ–ª–æ—Å

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞
        combined_confidence = min(
            0.95,
            base_confidence
            + signal_strength * 0.3
            + model_confidence * 0.2
            + (1.0 - avg_risk) * 0.1
            + consistency_bonus,
        )

        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞
        success_probability = combined_confidence

        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        sl_str = f"{stop_loss_pct:.3f}" if stop_loss_pct is not None else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
        tp_str = (
            f"{take_profit_pct:.3f}" if take_profit_pct is not None else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
        )

        logger.info(
            f"""
üìä ML –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø):
   –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {signal_type} (–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ: {weighted_direction:.3f})
   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º: {directions}
   –°–∏–ª–∞ —Å–∏–≥–Ω–∞–ª–∞ (—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å): {signal_strength:.3f}
   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {model_confidence:.1%}
   –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {combined_confidence:.1%}
   –†–∏—Å–∫: {risk_level} ({avg_risk:.3f})
   –ë—É–¥—É—â–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: 15–º={future_returns[0]:.3f}, 1—á={future_returns[1]:.3f}, 4—á={future_returns[2]:.3f}, 12—á={future_returns[3]:.3f}
   Stop Loss %: {sl_str}
   Take Profit %: {tp_str}
"""
        )

        return {
            "signal_type": signal_type,
            "signal_strength": float(signal_strength),
            "confidence": float(combined_confidence),
            "success_probability": float(success_probability),
            "stop_loss_pct": stop_loss_pct,  # –ü—Ä–æ—Ü–µ–Ω—Ç, –Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ü–µ–Ω–∞!
            "take_profit_pct": take_profit_pct,  # –ü—Ä–æ—Ü–µ–Ω—Ç, –Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ü–µ–Ω–∞!
            "risk_level": risk_level,
            "predictions": {
                "returns_15m": float(future_returns[0]),
                "returns_1h": float(future_returns[1]),
                "returns_4h": float(future_returns[2]),
                "returns_12h": float(future_returns[3]),
                "direction_score": float(weighted_direction),
                "directions_by_timeframe": directions.tolist(),  # [15m, 1h, 4h, 12h]
                "direction_probabilities": [p.tolist() for p in direction_probs],
            },
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

    async def update_model(self, new_model_path: str):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é.

        Args:
            new_model_path: –ü—É—Ç—å –∫ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—É—é
            backup_path = self.model_path.with_suffix(".pth.backup")
            if self.model_path.exists():
                self.model_path.rename(backup_path)

            # –ö–æ–ø–∏—Ä—É–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
            Path(new_model_path).rename(self.model_path)

            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            await self._load_model()

            logger.info(f"Model updated successfully from {new_model_path}")

        except Exception as e:
            logger.error(f"Error updating model: {e}")
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
            if backup_path.exists():
                backup_path.rename(self.model_path)
            raise

    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        return {
            "model_type": "UnifiedPatchTST",
            "model_path": str(self.model_path),
            "context_length": self.context_length,
            "num_features": self.num_features,
            "num_targets": self.num_targets,
            "device": str(self.device),
            "model_loaded": self.model is not None,
            "scaler_loaded": self.scaler is not None,
        }
