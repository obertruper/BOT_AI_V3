#!/usr/bin/env python3
"""
ML Manager –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è PatchTST –º–æ–¥–µ–ª—å—é –≤ BOT Trading v3
"""

import os
import pickle
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

import numpy as np
import pandas as pd
import torch

from core.logger import setup_logger
from core.system.signal_deduplicator import signal_deduplicator
from core.system.worker_coordinator import worker_coordinator
from ml.logic.feature_engineering_production import (  # Production –≤–µ—Ä—Å–∏—è –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
    ProductionFeatureEngineer as FeatureEngineer,
)
from ml.logic.patchtst_model import create_unified_model
from ml.logic.signal_quality_analyzer import SignalQualityAnalyzer
from ml.ml_prediction_logger import ml_prediction_logger

logger = setup_logger("ml_manager")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ GPU –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
if torch.cuda.is_available():
    try:
        # Benchmark mode –¥–ª—è cudnn
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.enabled = True

        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ float32 matmul precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö GPU
        # torch.set_float32_matmul_precision('high')  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ –∏–∑-–∑–∞ warning

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Ampere+ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (RTX 5090)
        # torch.backends.cuda.matmul.allow_tf32 = True  # Deprecated
        # torch.backends.cudnn.allow_tf32 = True  # Deprecated

        logger.info("‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã")
    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")


class MLManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è ML –º–æ–¥–µ–ª—è–º–∏ –≤ —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ.
    –†–∞–±–æ—Ç–∞–µ—Ç —Å PatchTST –º–æ–¥–µ–ª—å—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏–π —Ä—ã–Ω–∫–∞.
    """

    def __init__(self, config: dict[str, Any]):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ML –º–µ–Ω–µ–¥–∂–µ—Ä–∞.

        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
        """
        self.config = config
        self.model = None
        self.scaler = None
        self.feature_engineer = None
        # –ü–æ–ª—É—á–∞–µ–º device –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        device_config = config.get("ml", {}).get("model", {}).get("device", "auto")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPU —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        if device_config == "auto":
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CUDA
                if torch.cuda.is_available():
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU
                    gpu_count = torch.cuda.device_count()
                    if gpu_count > 0:
                        # –í—ã–±–∏—Ä–∞–µ–º GPU —Å –Ω–∞–∏–º–µ–Ω—å—à–µ–π –∑–∞–≥—Ä—É–∑–∫–æ–π –ø–∞–º—è—Ç–∏
                        best_gpu = 0
                        min_memory_used = float("inf")

                        for i in range(gpu_count):
                            try:
                                torch.cuda.set_device(i)
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å GPU
                                props = torch.cuda.get_device_properties(i)
                                logger.info(
                                    f"GPU {i}: {props.name}, "
                                    f"Compute Capability: {props.major}.{props.minor}, "
                                    f"Memory: {props.total_memory / 1024**3:.1f}GB"
                                )

                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (–∑–∞—â–∏—Ç–∞ –æ—Ç MagicMock –≤ —Ç–µ—Å—Ç–∞—Ö)
                                try:
                                    memory_used = torch.cuda.memory_allocated(i)
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ, –∞ –Ω–µ MagicMock
                                    if (
                                        isinstance(memory_used, (int, float))
                                        and memory_used < min_memory_used
                                    ):
                                        min_memory_used = memory_used
                                        best_gpu = i
                                except (TypeError, AttributeError):
                                    # –í —Ç–µ—Å—Ç–∞—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å MagicMock - –∏—Å–ø–æ–ª—å–∑—É–µ–º GPU 0 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                                    logger.debug(
                                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–∞–º—è—Ç—å GPU {i}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"
                                    )
                                    if i == 0:  # –ü–µ—Ä–≤—ã–π GPU –∫–∞–∫ fallback
                                        best_gpu = i
                            except Exception as gpu_error:
                                logger.warning(f"GPU {i} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_error}")
                                continue

                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª—É—á—à–∏–π GPU
                        torch.cuda.set_device(best_gpu)
                        self.device = torch.device(f"cuda:{best_gpu}")

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å GPU —Ç–µ—Å—Ç–æ–≤—ã–º —Ç–µ–Ω–∑–æ—Ä–æ–º
                        test_tensor = torch.zeros(1, 1).to(self.device)
                        _ = test_tensor * 2  # –ü—Ä–æ—Å—Ç–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

                        # RTX 5090 (Blackwell) –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
                        # - GPU –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ–Ω —Å PyTorch 2.9.0+
                        # - torch.compile –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã sm_120
                        # - –ú–æ–∂–µ—Ç –¥–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–∏—Ä–æ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                        gpu_name = props.name.upper()
                        if "RTX 5090" in gpu_name or props.major >= 12:
                            logger.info(
                                f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω RTX 5090 ({gpu_name}, sm_{props.major}{props.minor})"
                            )

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É torch.compile
                            try:
                                # –¢–µ—Å—Ç –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
                                import torch.nn as nn

                                test_model = nn.Linear(1, 1).to(self.device)
                                compiled_test = torch.compile(test_model)
                                test_input = torch.randn(1, 1).to(self.device)
                                _ = compiled_test(test_input)

                                logger.info(
                                    "‚úÖ torch.compile –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è RTX 5090 - –≤–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é!"
                                )
                                # –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º TORCH_COMPILE_DISABLE - –ø–æ–∑–≤–æ–ª—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å torch.compile

                            except Exception as compile_error:
                                logger.warning(
                                    f"‚ö†Ô∏è torch.compile –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è RTX 5090: {compile_error}. "
                                    "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."
                                )
                                os.environ["TORCH_COMPILE_DISABLE"] = "1"

                        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω GPU {best_gpu} ({props.name})")
                        logger.info(
                            f"üíæ GPU –ø–∞–º—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞: {props.total_memory / 1024**3:.2f} GB"
                        )
                    else:
                        logger.warning("CUDA –¥–æ—Å—Ç—É–ø–Ω–∞, –Ω–æ GPU –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                        self.device = torch.device("cpu")
                else:
                    logger.info("CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
                    self.device = torch.device("cpu")

            except Exception as e:
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ GPU: {type(e).__name__}: {e}")
                logger.info("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ CPU")
                self.device = torch.device("cpu")

                # –û—á–∏—â–∞–µ–º CUDA –∫–µ—à –ø—Ä–∏ –æ—à–∏–±–∫–µ
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
        else:
            # –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ device
            try:
                self.device = torch.device(device_config)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
                if "cuda" in device_config:
                    test_tensor = torch.zeros(1, 1).to(self.device)
                    _ = test_tensor * 2
                logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω device: {device_config}")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å device {device_config}: {e}")
                self.device = torch.device("cpu")

        # –§–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self._initialized = False

        # –ö—ç—à –º–æ–¥–µ–ª–µ–π (–¥–ª—è MLManager —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ç–µ—Å—Ç–∞–º–∏)
        self._model_cache = {}
        self._cache_size = config.get("ml", {}).get("model_cache_size", 3)
        self._memory_limit = config.get("ml", {}).get("memory_limit_mb", 1024)

        # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏
        base_dir = Path(__file__).parent.parent  # –ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
        model_dir = base_dir / config.get("ml", {}).get("model_directory", "models/saved")
        self.model_path = model_dir / "best_model_20250728_215703.pth"
        self.scaler_path = model_dir / "data_scaler.pkl"

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.context_length = 96  # 24 —á–∞—Å–∞ –ø—Ä–∏ 15-–º–∏–Ω—É—Ç–Ω—ã—Ö —Å–≤–µ—á–∞—Ö
        self.num_features = 240  # –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ 240 –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ checkpoint)
        self.num_targets = 20  # –ú–æ–¥–µ–ª—å –≤—ã–¥–∞–µ—Ç 20 –≤—ã—Ö–æ–¥–æ–≤

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤
        self.quality_analyzer = SignalQualityAnalyzer(config)

        logger.info(f"MLManager initialized, device: {self.device}")

    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
        try:
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º—Å—è –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–µ –≤–æ—Ä–∫–µ—Ä–æ–≤ —Å soft-fail —Ä–µ–∂–∏–º–æ–º
            await worker_coordinator.start()
            self.worker_id = await worker_coordinator.register_worker(
                worker_type="ml_manager",
                metadata={
                    "device": str(self.device),
                    "model_path": str(self.model_path),
                    "num_features": self.num_features,
                    "context_length": self.context_length,
                },
                allow_duplicates=True,  # Soft-fail —Ä–µ–∂–∏–º: —Ä–∞–∑—Ä–µ—à–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
            )

            if not self.worker_id:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ WorkerCoordinator, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π worker_id
                import time

                self.worker_id = f"ml_manager_fallback_{int(time.time())}"

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            await self._load_model()

            # –ó–∞–≥—Ä—É–∂–∞–µ–º scaler
            await self._load_scaler()

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º feature engineer
            self.feature_engineer = FeatureEngineer(self.config)

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            self._initialized = True

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º heartbeat –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            await worker_coordinator.heartbeat(self.worker_id, status="running")

            logger.info("‚úÖ ML components initialized successfully")

        except Exception as e:
            logger.error(f"Error initializing ML components: {e}")
            if hasattr(self, "worker_id") and self.worker_id:
                await worker_coordinator.unregister_worker(self.worker_id)
            raise

    async def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ PatchTST –º–æ–¥–µ–ª–∏"""
        try:
            if not self.model_path.exists():
                raise FileNotFoundError(f"Model file not found: {self.model_path}")

            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            model_config = {
                "model": {
                    "input_size": self.num_features,  # 98 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    "output_size": self.num_targets,  # 20 –≤—ã—Ö–æ–¥–æ–≤
                    "context_window": self.context_length,  # 96 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫
                    "patch_len": 16,
                    "stride": 8,
                    "d_model": 256,  # –°–æ–≥–ª–∞—Å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                    "n_heads": 4,
                    "e_layers": 3,
                    "d_ff": 512,
                    "dropout": 0.1,
                    "temperature_scaling": True,
                    "temperature": 2.0,
                }
            }
            self.model = create_unified_model(model_config)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π CUDA –æ—à–∏–±–æ–∫
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                checkpoint = torch.load(self.model_path, map_location=self.device)
            except Exception as cuda_error:
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ CUDA, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ CPU
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ {self.device}, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU: {cuda_error}")
                checkpoint = torch.load(self.model_path, map_location=torch.device("cpu"))
                self.device = torch.device("cpu")

            self.model.load_state_dict(checkpoint["model_state_dict"])

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            try:
                self.model.to(self.device)
            except Exception as e:
                logger.warning(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ {self.device}, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU: {e}"
                )
                self.device = torch.device("cpu")
                self.model.to(self.device)

            self.model.eval()

            # –ü—Ä–∏–º–µ–Ω—è–µ–º torch.compile –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            if os.environ.get("TORCH_COMPILE_DISABLE", "").lower() not in ("1", "true"):
                try:
                    logger.info("üöÄ –ü—Ä–∏–º–µ–Ω—è–µ–º torch.compile –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏...")

                    # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
                    self.model = torch.compile(
                        self.model,
                        mode="max-autotune",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
                        fullgraph=False,  # –ü–æ–∑–≤–æ–ª—è–µ–º graph breaks –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        dynamic=False,  # Static shapes –¥–ª—è –ª—É—á—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    )

                    logger.info("‚úÖ torch.compile —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω –∫ –º–æ–¥–µ–ª–∏!")

                    # Warm-up run –¥–ª—è JIT –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
                    logger.info("üî• –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ —Å torch.compile...")
                    with torch.no_grad():
                        warmup_input = torch.randn(1, self.context_length, self.num_features).to(
                            self.device
                        )
                        _ = self.model(warmup_input)
                    logger.info("‚úÖ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥—Ä–µ—Ç–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")

                except Exception as compile_error:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å torch.compile: {compile_error}")
                    logger.info("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª—å—é –±–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
            else:
                logger.info("‚ÑπÔ∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è")

            logger.info(f"Model loaded successfully from {self.model_path}")

        except Exception as e:
            logger.error(f"Error loading model: {e}")
            raise

    async def _load_scaler(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ scaler –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if not self.scaler_path.exists():
                raise FileNotFoundError(f"Scaler file not found: {self.scaler_path}")

            with open(self.scaler_path, "rb") as f:
                self.scaler = pickle.load(f)

            logger.info(f"Scaler loaded successfully from {self.scaler_path}")

        except Exception as e:
            logger.error(f"Error loading scaler: {e}")
            raise

    async def predict(
        self, input_data: pd.DataFrame | np.ndarray, symbol: str | None = None
    ) -> dict[str, Any]:
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö.

        Args:
            input_data: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ (–º–∏–Ω–∏–º—É–º 96 —Å–≤–µ—á–µ–π) –∏–ª–∏ numpy array —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
            symbol: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–∏–º–≤–æ–ª –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–≥–¥–∞ input_data —ç—Ç–æ numpy array)

        Returns:
            Dict —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
            if not self._initialized or self.model is None:
                raise ValueError("ML model not initialized. Call initialize() first.")

            # –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not isinstance(input_data, (pd.DataFrame, np.ndarray)):
                raise TypeError(
                    f"input_data must be pd.DataFrame or np.ndarray, got {type(input_data)}"
                )

            # –ï—Å–ª–∏ —ç—Ç–æ numpy array - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å (—É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
            if isinstance(input_data, np.ndarray):
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º 3D –º–∞—Å—Å–∏–≤—ã (batch_size, sequence_length, features)
                if input_data.ndim == 3:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –æ–¥–∏–Ω–æ—á–Ω—ã–π –±–∞—Ç—á
                    if input_data.shape[0] == 1:
                        input_data = input_data.squeeze(0)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ
                    else:
                        raise ValueError(
                            f"Expected single batch, got batch_size={input_data.shape[0]}"
                        )

                # –¢–µ–ø–µ—Ä—å –ø—Ä–æ–≤–µ—Ä—è–µ–º 2D —Ñ–æ—Ä–º—É
                if (
                    input_data.shape[0] != self.context_length
                    or input_data.shape[1] != self.num_features
                ):
                    raise ValueError(
                        f"Expected shape ({self.context_length}, {self.num_features}), got {input_data.shape}"
                    )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
                features = input_data
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º numpy array —Å –ø–æ–º–æ—â—å—é scaler
                features_scaled = self.scaler.transform(input_data)
                logger.info("‚úÖ Numpy array –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω —Å –ø–æ–º–æ—â—å—é scaler")

            # –ï—Å–ª–∏ —ç—Ç–æ DataFrame - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ OHLCV –¥–∞–Ω–Ω—ã–µ
            else:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame —Å async/await –ª–æ–≥–∏–∫–æ–π
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
                if len(input_data) < self.context_length:
                    raise ValueError(
                        f"Need at least {self.context_length} candles, got {len(input_data)}"
                    )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ symbol
                if "symbol" not in input_data.columns:
                    logger.warning(
                        "‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'symbol' –≤ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö! –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ—Ç–æ—á–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º."
                    )
                    input_data = input_data.copy()
                    input_data["symbol"] = "UNKNOWN_SYMBOL"  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–∏–º–≤–æ–ª

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ - —Ç–µ–ø–µ—Ä—å —ç—Ç–æ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
                features_result = self.feature_engineer.create_features(input_data)

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –º–æ–∂–µ—Ç –±—ã—Ç—å DataFrame –∏–ª–∏ ndarray
                if isinstance(features_result, pd.DataFrame):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ DataFrame
                    numeric_cols = features_result.select_dtypes(include=[np.number]).columns
                    # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    feature_cols = [
                        col
                        for col in numeric_cols
                        if not col.startswith(("future_", "direction_", "profit_"))
                        and col not in ["id", "timestamp", "datetime", "symbol"]
                    ]
                    features_array = features_result[feature_cols].values

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                    if features_array.shape[1] != self.num_features:
                        logger.warning(
                            f"Feature count mismatch: expected {self.num_features}, got {features_array.shape[1]}"
                        )
                        # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –±–æ–ª—å—à–µ - –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ num_features
                        if features_array.shape[1] > self.num_features:
                            features_array = features_array[:, : self.num_features]
                        else:
                            # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ - –¥–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                            padding = np.zeros(
                                (
                                    features_array.shape[0],
                                    self.num_features - features_array.shape[1],
                                )
                            )
                            features_array = np.hstack([features_array, padding])

                elif isinstance(features_result, np.ndarray):
                    features_array = features_result
                else:
                    raise ValueError(
                        f"Expected DataFrame or np.ndarray from create_features, got {type(features_result)}"
                    )

                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ context_length —Å—Ç—Ä–æ–∫
                if len(features_array) >= self.context_length:
                    features = features_array[-self.context_length :]

                    # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –í–•–û–î–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í
                    if hasattr(self, "feature_engineer") and hasattr(
                        self.feature_engineer, "feature_names"
                    ):
                        feature_names = self.feature_engineer.feature_names
                    else:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                        from ml.config.features_240 import get_required_features_list

                        feature_names = get_required_features_list()

                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    current_features = features[-1] if len(features) > 0 else features[0]

                    # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Å–∏–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
                    features_table = []
                    features_table.append(
                        "\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
                    )
                    features_table.append(
                        f"‚ïë            –í–•–û–î–ù–´–ï –ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò - {len(current_features)} –ü–†–ò–ó–ù–ê–ö–û–í             ‚ïë"
                    )
                    features_table.append(
                        "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
                    )

                    # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                    key_indicators = [
                        ("returns", 0),
                        ("rsi", 9),
                        ("macd", 12),
                        ("bb_position", 19),
                        ("atr_pct", 24),
                        ("stoch_k", 25),
                        ("adx", 27),
                        ("volume_ratio", 4),
                        ("obv_trend", 71),
                        ("momentum_1h", 115),
                        ("trend_1h", 124),
                        ("signal_strength", 139),
                    ]

                    features_table.append(
                        "‚ïë üéØ –ö–õ–Æ–ß–ï–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´:                                             ‚ïë"
                    )
                    for i in range(0, len(key_indicators), 2):
                        if i < len(key_indicators):
                            name1, idx1 = key_indicators[i]
                            val1 = current_features[idx1] if idx1 < len(current_features) else 0

                            if i + 1 < len(key_indicators):
                                name2, idx2 = key_indicators[i + 1]
                                val2 = current_features[idx2] if idx2 < len(current_features) else 0
                                features_table.append(
                                    f"‚ïë   ‚Ä¢ {name1:15s}: {val1:>8.4f}  ‚îÇ  {name2:15s}: {val2:>8.4f}  ‚ïë"
                                )
                            else:
                                features_table.append(
                                    f"‚ïë   ‚Ä¢ {name1:15s}: {val1:>8.4f}  ‚îÇ                                  ‚ïë"
                                )

                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
                    nan_count = np.sum(np.isnan(current_features))
                    zero_count = np.sum(current_features == 0)
                    mean_val = np.nanmean(current_features)
                    std_val = np.nanstd(current_features)

                    features_table.append(
                        "‚ïü‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï¢"
                    )
                    features_table.append(
                        "‚ïë üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–ò–ó–ù–ê–ö–û–í:                                            ‚ïë"
                    )
                    features_table.append(
                        f"‚ïë   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(current_features):<6} ‚Ä¢ NaN: {nan_count:<6} ‚Ä¢ Zeros: {zero_count:<6}         ‚ïë"
                    )
                    features_table.append(
                        f"‚ïë   ‚Ä¢ Mean: {mean_val:>8.4f}  ‚Ä¢ Std: {std_val:>8.4f}                           ‚ïë"
                    )
                    features_table.append(
                        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
                    )

                    # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É –æ–¥–Ω–∏–º –±–ª–æ–∫–æ–º
                    logger.info("\n".join(features_table))

                else:
                    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ - –¥–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ (padding)
                    padding_size = self.context_length - len(features_array)
                    padding = np.zeros((padding_size, features_array.shape[1]))
                    features = np.vstack([padding, features_array])

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ scaler
                features_scaled = self.scaler.transform(features)
                logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã —Å –ø–æ–º–æ—â—å—é scaler")
                
                # –§–ò–õ–¨–¢–†–ê–¶–ò–Ø ZERO VARIANCE FEATURES (–∏–∑ BOT_AI_V2)
                # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π
                feature_stds = features_scaled.std(axis=0)
                zero_variance_mask = feature_stds < 1e-6
                zero_variance_count = zero_variance_mask.sum()
                
                if zero_variance_count > 0:
                    logger.warning(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {zero_variance_count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π")
                    
                    # –ó–∞–º–µ–Ω—è–µ–º zero variance –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∞ –º–∞–ª–æ–µ —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    # (–ø–æ–¥—Ö–æ–¥ –∏–∑ BOT_AI_V2: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º —à—É–º)
                    for i, is_zero_var in enumerate(zero_variance_mask):
                        if is_zero_var:
                            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –≥–∞—É—Å—Å–æ–≤ —à—É–º –≤–º–µ—Å—Ç–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                            noise = np.random.normal(0, 1e-4, features_scaled.shape[0])
                            features_scaled[:, i] = features_scaled[:, i] + noise
                    
                    logger.info(f"‚úÖ Zero variance –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ —à—É–º –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è ML –∫–∞—á–µ—Å—Ç–≤–∞")
                else:
                    logger.info("‚úÖ Zero variance –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
            x = torch.FloatTensor(features_scaled).unsqueeze(0).to(self.device)

            # –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –í–•–û–î–ù–´–• –î–ê–ù–ù–´–•
            logger.warning(
                f"""
üîç ML –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï - –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä Feature Statistics:
   Shape: {features_scaled.shape}
   Min: {features_scaled.min():.6f}
   Max: {features_scaled.max():.6f}
   Mean: {features_scaled.mean():.6f}
   Std: {features_scaled.std():.6f}

üìà –ü–µ—Ä–≤—ã–µ 10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è —Ç–æ—á–∫–∞):
   {features_scaled[-1, :10]}

üéØ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö:
   NaN count: {np.isnan(features_scaled).sum()}
   Inf count: {np.isinf(features_scaled).sum()}
   Zero variance features: {(features_scaled.std(axis=0) < 1e-6).sum()}
   üîç Variance statistics:
     Min std: {features_scaled.std(axis=0).min():.8f}
     Max std: {features_scaled.std(axis=0).max():.8f}
     Mean std: {features_scaled.std(axis=0).mean():.8f}
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""
            )
            logger.debug(f"Input tensor shape: {x.shape}")

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ inference
            if self.device.type == "cuda":
                gpu_memory_before = torch.cuda.memory_allocated(self.device) / 1024**2  # MB
                gpu_memory_cached = torch.cuda.memory_reserved(self.device) / 1024**2  # MB
                logger.debug(
                    f"GPU Memory before inference: {gpu_memory_before:.1f}MB allocated, {gpu_memory_cached:.1f}MB cached"
                )

            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏
            import time

            start_time = time.time()

            with torch.no_grad():
                outputs = self.model(x)

            inference_time = (time.time() - start_time) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ inference
            if self.device.type == "cuda":
                gpu_memory_after = torch.cuda.memory_allocated(self.device) / 1024**2  # MB
                logger.debug(f"GPU Memory after inference: {gpu_memory_after:.1f}MB allocated")
                logger.info(f"Inference time: {inference_time:.1f}ms on {self.device}")

            # –û—Ç–ª–∞–¥–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏
            outputs_np = outputs.cpu().numpy()[0]
            logger.debug(
                f"Model outputs: min={outputs_np.min():.3f}, max={outputs_np.max():.3f}, mean={outputs_np.mean():.3f}"
            )
            logger.debug(f"Model outputs sample: {outputs_np[:10]}")

            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            predictions = self._interpret_predictions(outputs)

            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π symbol –ø–∞—Ä–∞–º–µ—Ç—Ä –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ DataFrame
                if symbol:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª
                    pass
                elif isinstance(input_data, pd.DataFrame) and "symbol" in input_data.columns:
                    symbol = input_data["symbol"].iloc[-1] if not input_data.empty else "UNKNOWN"
                else:
                    symbol = "UNKNOWN"

                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                import asyncio

                if asyncio.iscoroutinefunction(ml_prediction_logger.log_prediction):
                    await ml_prediction_logger.log_prediction(
                        symbol=symbol,
                        features=features[
                            -1
                        ],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ
                        model_outputs=outputs_np,
                        predictions=predictions,
                        market_data=input_data if isinstance(input_data, pd.DataFrame) else None,
                    )
                else:
                    # –ï—Å–ª–∏ –º–µ—Ç–æ–¥ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π, —Å–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É
                    asyncio.create_task(
                        ml_prediction_logger.log_prediction(
                            symbol=symbol,
                            features=features[-1],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                            model_outputs=outputs_np,
                            predictions=predictions,
                            market_data=(
                                input_data if isinstance(input_data, pd.DataFrame) else None
                            ),
                        )
                    )
            except Exception as log_error:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {log_error}")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º heartbeat –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            try:
                if hasattr(self, "worker_id") and self.worker_id:
                    await worker_coordinator.heartbeat(
                        self.worker_id, status="running", active_tasks=1
                    )
            except Exception as heartbeat_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ heartbeat: {heartbeat_error}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
            try:
                # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                signal_data = {
                    "symbol": symbol,
                    "direction": predictions.get("primary_direction", "NEUTRAL"),
                    "strategy": "ml_patchtst",
                    "timestamp": datetime.now(),
                    "signal_strength": predictions.get("primary_confidence", 0.0),
                    "price_level": predictions.get("primary_returns", {}).get("15m", 0.0),
                }

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞
                is_unique = await signal_deduplicator.check_and_register_signal(signal_data)
                if not is_unique:
                    logger.warning(f"üîÑ –î—É–±–ª–∏–∫–∞—Ç ML —Å–∏–≥–Ω–∞–ª–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω –¥–ª—è {symbol}")
                    predictions["is_duplicate"] = True
                else:
                    predictions["is_duplicate"] = False

            except Exception as dedup_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞: {dedup_error}")
                predictions["is_duplicate"] = False

            logger.info(f"ML Manager –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions}")
            return predictions

        except Exception as e:
            logger.error(f"Error making prediction: {e}")
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º heartbeat –æ–± –æ—à–∏–±–∫–µ
            try:
                if hasattr(self, "worker_id") and self.worker_id:
                    await worker_coordinator.heartbeat(self.worker_id, status="error")
            except Exception as heartbeat_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ heartbeat –ø—Ä–∏ –æ—à–∏–±–∫–µ: {heartbeat_error}")
            raise

    def _interpret_predictions(self, outputs: torch.Tensor) -> dict[str, Any]:
        """
        –£–õ–£–ß–®–ï–ù–ù–ê–Ø –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–æ–≤.

        –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è!
        –í –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –±—ã–ª–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ:
        - –ö–ª–∞—Å—Å 0 = LONG (–ø–æ–∫—É–ø–∫–∞, —Ä–æ—Å—Ç —Ü–µ–Ω—ã)
        - –ö–ª–∞—Å—Å 1 = SHORT (–ø—Ä–æ–¥–∞–∂–∞, –ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã)
        - –ö–ª–∞—Å—Å 2 = NEUTRAL/FLAT (–±–æ–∫–æ–≤–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ, –Ω–µ—Ç —Ç–æ—Ä–≥–æ–≤–ª–∏)

        Args:
            outputs: –¢–µ–Ω–∑–æ—Ä —Å 20 –≤—ã—Ö–æ–¥–∞–º–∏ –º–æ–¥–µ–ª–∏

        Returns:
            Dict —Å –ü–†–ê–í–ò–õ–¨–ù–û –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ —Å–ª–æ–≤–∞—Ä–∏ –≤ –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏
        timeframes = ["15m", "1h", "4h", "12h"]
        direction_names = {0: "LONG‚ÜóÔ∏è", 1: "SHORT‚ÜòÔ∏è", 2: "FLAT‚û°Ô∏è"}
        direction_map = {0: "LONG", 1: "SHORT", 2: "NEUTRAL"}

        # –≠—Ç–∞–ø 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏
        outputs_np = outputs.cpu().numpy()[0]

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–æ–≤ (20 –∑–Ω–∞—á–µ–Ω–∏–π):
        # 0-3: future returns (15m, 1h, 4h, 12h)
        # 4-15: direction logits (12 values = 3 classes √ó 4 timeframes)
        # 16-19: risk metrics

        future_returns = outputs_np[0:4]
        direction_logits = outputs_np[4:16]  # 12 –∑–Ω–∞—á–µ–Ω–∏–π!
        risk_metrics = outputs_np[16:20]

        # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø DIRECTIONS (12 –∑–Ω–∞—á–µ–Ω–∏–π = 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞)
        direction_logits_reshaped = direction_logits.reshape(4, 3)  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞

        # –ü—Ä–∏–º–µ–Ω—è–µ–º softmax –∫ –∫–∞–∂–¥–æ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
        directions = []
        direction_probs = []

        for i, logits in enumerate(direction_logits_reshaped):
            # Softmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            exp_logits = np.exp(logits - np.max(logits))  # –î–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            probs = exp_logits / exp_logits.sum()
            direction_probs.append(probs)

            # Argmax –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞ (0=LONG, 1=SHORT, 2=NEUTRAL)
            direction_class = np.argmax(probs)
            directions.append(direction_class)

        directions = np.array(directions)

        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• –ü–ê–†–ê–ú–ï–¢–†–û–í –ú–û–î–ï–õ–ò
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥—ã –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        outputs_formatted = [f"{x:.4f}" for x in outputs_np]

        logger.info(
            f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    ü§ñ ML MODEL PREDICTION ANALYSIS                   ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üìä RAW MODEL OUTPUTS (20 parameters):                                ‚ïë
‚ïë  [0-4]:  {', '.join(outputs_formatted[0:5]):50s}    ‚ïë
‚ïë  [5-9]:  {', '.join(outputs_formatted[5:10]):50s}    ‚ïë
‚ïë  [10-14]: {', '.join(outputs_formatted[10:15]):50s}   ‚ïë
‚ïë  [15-19]: {', '.join(outputs_formatted[15:20]):50s}   ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üìà FUTURE RETURNS (–æ–∂–∏–¥–∞–µ–º—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏):                           ‚ïë
‚ïë   ‚Ä¢ 15m:  {future_returns[0]:+.6f} ({future_returns[0]*100:+6.3f}%)                       ‚ïë
‚ïë   ‚Ä¢ 1h:   {future_returns[1]:+.6f} ({future_returns[1]*100:+6.3f}%)                       ‚ïë
‚ïë   ‚Ä¢ 4h:   {future_returns[2]:+.6f} ({future_returns[2]*100:+6.3f}%)                       ‚ïë
‚ïë   ‚Ä¢ 12h:  {future_returns[3]:+.6f} ({future_returns[3]*100:+6.3f}%)                       ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üéØ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø –ü–û –¢–ê–ô–ú–§–†–ï–ô–ú–ê–ú:                                      ‚ïë
‚ïë   ‚Ä¢ 15m:  {direction_names.get(directions[0], str(directions[0])):8s} | Conf: {direction_probs[0].max():.3f} |                      ‚ïë
‚ïë      Probs: [LONG: {direction_probs[0][0]:.3f}, SHORT: {direction_probs[0][1]:.3f}, NEUTRAL: {direction_probs[0][2]:.3f}]          ‚ïë
‚ïë   ‚Ä¢ 1h:   {direction_names.get(directions[1], str(directions[1])):8s} | Conf: {direction_probs[1].max():.3f} |                      ‚ïë
‚ïë      Probs: [LONG: {direction_probs[1][0]:.3f}, SHORT: {direction_probs[1][1]:.3f}, NEUTRAL: {direction_probs[1][2]:.3f}]          ‚ïë
‚ïë   ‚Ä¢ 4h:   {direction_names.get(directions[2], str(directions[2])):8s} | Conf: {direction_probs[2].max():.3f} |                      ‚ïë
‚ïë      Probs: [LONG: {direction_probs[2][0]:.3f}, SHORT: {direction_probs[2][1]:.3f}, NEUTRAL: {direction_probs[2][2]:.3f}]          ‚ïë
‚ïë   ‚Ä¢ 12h:  {direction_names.get(directions[3], str(directions[3])):8s} | Conf: {direction_probs[3].max():.3f} |                      ‚ïë
‚ïë      Probs: [LONG: {direction_probs[3][0]:.3f}, SHORT: {direction_probs[3][1]:.3f}, NEUTRAL: {direction_probs[3][2]:.3f}]          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë ‚ö° RISK METRICS (–º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞):                                     ‚ïë
‚ïë   ‚Ä¢ Max Drawdown 1h:  {risk_metrics[0]:+.6f}                                  ‚ïë
‚ïë   ‚Ä¢ Max Rally 1h:     {risk_metrics[1]:+.6f}                                  ‚ïë
‚ïë   ‚Ä¢ Max Drawdown 4h:  {risk_metrics[2]:+.6f}                                  ‚ïë
‚ïë   ‚Ä¢ Max Rally 4h:     {risk_metrics[3]:+.6f}                                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
        )

        # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤—Å–µ—Ö 20 –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏
        logger.info(
            f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë               üìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø 20 –í–´–•–û–î–û–í –ú–û–î–ï–õ–ò           ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üîÆ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –î–û–•–û–î–ù–û–°–¢–ò (outputs 0-3):                           ‚ïë
‚ïë   ‚Ä¢ Out[0] = {outputs_np[0]:+.6f} ‚Üí 15m return prediction            ‚ïë
‚ïë   ‚Ä¢ Out[1] = {outputs_np[1]:+.6f} ‚Üí 1h return prediction             ‚ïë
‚ïë   ‚Ä¢ Out[2] = {outputs_np[2]:+.6f} ‚Üí 4h return prediction             ‚ïë
‚ïë   ‚Ä¢ Out[3] = {outputs_np[3]:+.6f} ‚Üí 12h return prediction            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üéØ –õ–û–ì–ò–¢–´ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø 15m (outputs 4-6):                            ‚ïë
‚ïë   ‚Ä¢ Out[4] = {outputs_np[4]:+.6f} ‚Üí Logit for LONG                   ‚ïë
‚ïë   ‚Ä¢ Out[5] = {outputs_np[5]:+.6f} ‚Üí Logit for SHORT                  ‚ïë
‚ïë   ‚Ä¢ Out[6] = {outputs_np[6]:+.6f} ‚Üí Logit for NEUTRAL                ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üéØ –õ–û–ì–ò–¢–´ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø 1h (outputs 7-9):                             ‚ïë
‚ïë   ‚Ä¢ Out[7] = {outputs_np[7]:+.6f} ‚Üí Logit for LONG                   ‚ïë
‚ïë   ‚Ä¢ Out[8] = {outputs_np[8]:+.6f} ‚Üí Logit for SHORT                  ‚ïë
‚ïë   ‚Ä¢ Out[9] = {outputs_np[9]:+.6f} ‚Üí Logit for NEUTRAL                ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üéØ –õ–û–ì–ò–¢–´ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø 4h (outputs 10-12):                           ‚ïë
‚ïë   ‚Ä¢ Out[10] = {outputs_np[10]:+.6f} ‚Üí Logit for LONG                 ‚ïë
‚ïë   ‚Ä¢ Out[11] = {outputs_np[11]:+.6f} ‚Üí Logit for SHORT                ‚ïë
‚ïë   ‚Ä¢ Out[12] = {outputs_np[12]:+.6f} ‚Üí Logit for NEUTRAL              ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üéØ –õ–û–ì–ò–¢–´ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø 12h (outputs 13-15):                          ‚ïë
‚ïë   ‚Ä¢ Out[13] = {outputs_np[13]:+.6f} ‚Üí Logit for LONG                 ‚ïë
‚ïë   ‚Ä¢ Out[14] = {outputs_np[14]:+.6f} ‚Üí Logit for SHORT                ‚ïë
‚ïë   ‚Ä¢ Out[15] = {outputs_np[15]:+.6f} ‚Üí Logit for NEUTRAL              ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë ‚ö†Ô∏è –ú–ï–¢–†–ò–ö–ò –†–ò–°–ö–ê (outputs 16-19):                                   ‚ïë
‚ïë   ‚Ä¢ Out[16] = {outputs_np[16]:+.6f} ‚Üí Max Drawdown 1h                ‚ïë
‚ïë   ‚Ä¢ Out[17] = {outputs_np[17]:+.6f} ‚Üí Max Rally 1h                   ‚ïë
‚ïë   ‚Ä¢ Out[18] = {outputs_np[18]:+.6f} ‚Üí Max Drawdown 4h                ‚ïë
‚ïë   ‚Ä¢ Out[19] = {outputs_np[19]:+.6f} ‚Üí Max Rally 4h                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
        )

        # –≠—Ç–∞–ø 2: –†–∞—Å—á–µ—Ç weighted_direction –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        weights = np.array([0.4, 0.3, 0.2, 0.1])
        weighted_direction = np.sum(directions * weights)

        # –≠—Ç–∞–ø 3: –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–∞ —Å –ø–æ–º–æ—â—å—é –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        filter_result = self.quality_analyzer.analyze_signal_quality(
            directions=directions,
            direction_probs=direction_probs,
            future_returns=future_returns,
            risk_metrics=risk_metrics,
            weighted_direction=weighted_direction,
        )

        # –≠—Ç–∞–ø 4: –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        if not filter_result.passed:
            # –°–∏–≥–Ω–∞–ª –Ω–µ –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞
            signal_type = "NEUTRAL"
            signal_strength = 0.25  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            combined_confidence = 0.25
            stop_loss_pct = None
            take_profit_pct = None

            logger.warning(
                f"üö´ –°–∏–≥–Ω–∞–ª –æ—Ç–∫–ª–æ–Ω–µ–Ω –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º –∫–∞—á–µ—Å—Ç–≤–∞. "
                f"–ü—Ä–∏—á–∏–Ω—ã: {'; '.join(filter_result.rejection_reasons)}"
            )
        else:
            # –°–∏–≥–Ω–∞–ª –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            signal_type = filter_result.signal_type
            metrics = filter_result.quality_metrics

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            signal_strength = metrics.agreement_score
            combined_confidence = metrics.confidence_score

            # –†–∞—Å—á–µ—Ç SL/TP –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–∞
            if signal_type in ["LONG", "SHORT"]:
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ SL/TP –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
                base_sl = 0.01  # 1%
                base_tp = 0.02  # 2%

                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–≥–Ω–∞–ª–∞
                quality_multiplier = 0.8 + (metrics.quality_score * 0.4)  # 0.8-1.2

                stop_loss_pct = base_sl * quality_multiplier
                take_profit_pct = base_tp * quality_multiplier

                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                volatility = np.std(future_returns[:2])  # –ë–ª–∏–∂–∞–π—à–∏–µ –¢–§
                if volatility > 0.01:
                    stop_loss_pct *= 1.2
                    take_profit_pct *= 1.2

                # –§–∏–Ω–∞–ª—å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
                stop_loss_pct = np.clip(stop_loss_pct, 0.005, 0.025)  # 0.5% - 2.5%
                take_profit_pct = np.clip(take_profit_pct, 0.01, 0.05)  # 1% - 5%
            else:
                stop_loss_pct = None
                take_profit_pct = None

        # –≠—Ç–∞–ø 5: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        confidence_scores = np.array([np.max(probs) for probs in direction_probs])
        model_confidence = float(np.mean(confidence_scores))
        avg_risk = float(np.mean(risk_metrics))
        risk_level = "LOW" if avg_risk < 0.3 else "MEDIUM" if avg_risk < 0.7 else "HIGH"

        # Focal weighting –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –ª–æ–≥–≥–µ—Ä–æ–º
        focal_alpha = 0.25
        focal_gamma = 2.0
        focal_weighted_confidence = focal_alpha * (1 - model_confidence) ** focal_gamma

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        quality_score = filter_result.quality_metrics.quality_score if filter_result.passed else 0.0
        strategy_used = filter_result.strategy_used.value

        sl_str = f"{stop_loss_pct:.3f}" if stop_loss_pct else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
        tp_str = f"{take_profit_pct:.3f}" if take_profit_pct else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"

        # –¶–≤–µ—Ç–æ–≤–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è –¥–ª—è —Å–∏–≥–Ω–∞–ª–∞
        signal_emoji = "üü¢" if signal_type == "LONG" else "üî¥" if signal_type == "SHORT" else "‚ö™"
        passed_emoji = "‚úÖ" if filter_result.passed else "‚ùå"

        logger.info(
            f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    üìä ML PREDICTION FINAL RESULT                     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë {signal_emoji} SIGNAL TYPE: {signal_type:8s} | Strategy: {strategy_used:12s}        ‚ïë
‚ïë {passed_emoji} Quality Filter: {'PASSED' if filter_result.passed else 'REJECTED':8s} | Score: {quality_score:.3f}              ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üìà PREDICTIONS BY TIMEFRAME:                                         ‚ïë
‚ïë   15m: {direction_map.get(int(directions[0]), 'N/A'):8s} | Ret: {future_returns[0]:+.4f} | Conf: {confidence_scores[0]:.3f}       ‚ïë
‚ïë   1h:  {direction_map.get(int(directions[1]), 'N/A'):8s} | Ret: {future_returns[1]:+.4f} | Conf: {confidence_scores[1]:.3f}       ‚ïë
‚ïë   4h:  {direction_map.get(int(directions[2]), 'N/A'):8s} | Ret: {future_returns[2]:+.4f} | Conf: {confidence_scores[2]:.3f}       ‚ïë
‚ïë   12h: {direction_map.get(int(directions[3]), 'N/A'):8s} | Ret: {future_returns[3]:+.4f} | Conf: {confidence_scores[3]:.3f}       ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë üí™ SIGNAL STRENGTH: {signal_strength:.3f} | CONFIDENCE: {combined_confidence:.1%}           ‚ïë
‚ïë ‚ö†Ô∏è  RISK LEVEL: {risk_level:6s} | Score: {avg_risk:.3f}                         ‚ïë
‚ïë üõ°Ô∏è  STOP LOSS:  {sl_str:8s} | üéØ TAKE PROFIT: {tp_str:8s}          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
        )

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        return {
            # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–≥–Ω–∞–ª–∞
            "signal_type": signal_type,
            "signal_strength": float(signal_strength),
            "confidence": float(combined_confidence),
            "signal_confidence": float(combined_confidence),  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "success_probability": float(combined_confidence),
            # SL/TP –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            "stop_loss_pct": stop_loss_pct,
            "take_profit_pct": take_profit_pct,
            # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
            "risk_level": risk_level,
            "risk_score": float(avg_risk),
            "max_drawdown": float(risk_metrics[0]) if len(risk_metrics) > 0 else 0,
            "max_rally": float(risk_metrics[1]) if len(risk_metrics) > 1 else 0,
            # –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            "returns_15m": float(future_returns[0]),
            "returns_1h": float(future_returns[1]),
            "returns_4h": float(future_returns[2]),
            "returns_12h": float(future_returns[3]),
            # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
            "direction_15m": direction_map.get(int(directions[0]), "NEUTRAL"),
            "direction_1h": direction_map.get(int(directions[1]), "NEUTRAL"),
            "direction_4h": direction_map.get(int(directions[2]), "NEUTRAL"),
            "direction_12h": direction_map.get(int(directions[3]), "NEUTRAL"),
            "confidence_15m": float(confidence_scores[0]),
            "confidence_1h": float(confidence_scores[1]),
            "confidence_4h": float(confidence_scores[2]),
            "confidence_12h": float(confidence_scores[3]),
            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
            "quality_score": quality_score,
            "agreement_score": (
                filter_result.quality_metrics.agreement_score if filter_result.passed else 0.0
            ),
            "filter_strategy": strategy_used,
            "passed_quality_filters": filter_result.passed,
            "rejection_reasons": filter_result.rejection_reasons,
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            "primary_timeframe": "4h",  # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
            "predictions": {
                "returns_15m": float(future_returns[0]),
                "returns_1h": float(future_returns[1]),
                "returns_4h": float(future_returns[2]),
                "returns_12h": float(future_returns[3]),
                "direction_score": float(weighted_direction),
                "directions_by_timeframe": directions.tolist(),
                "direction_probabilities": [p.tolist() for p in direction_probs],
            },
            "timestamp": datetime.now(UTC).isoformat(),
        }

    async def update_model(self, new_model_path: str):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é.

        Args:
            new_model_path: –ü—É—Ç—å –∫ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—É—é
            backup_path = self.model_path.with_suffix(".pth.backup")
            if self.model_path.exists():
                self.model_path.rename(backup_path)

            # –ö–æ–ø–∏—Ä—É–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å
            Path(new_model_path).rename(self.model_path)

            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            await self._load_model()

            logger.info(f"Model updated successfully from {new_model_path}")

        except Exception as e:
            logger.error(f"Error updating model: {e}")
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
            if backup_path.exists():
                backup_path.rename(self.model_path)
            raise

    def get_model_info(self) -> dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        return {
            "model_type": "UnifiedPatchTST",
            "model_path": str(self.model_path),
            "context_length": self.context_length,
            "num_features": self.num_features,
            "num_targets": self.num_targets,
            "device": str(self.device),
            "model_loaded": self.model is not None,
            "scaler_loaded": self.scaler is not None,
        }

    def switch_filtering_strategy(self, strategy: str) -> bool:
        """
        –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤

        Args:
            strategy: –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (conservative/moderate/aggressive)

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ
        """
        if self.quality_analyzer.switch_strategy(strategy):
            logger.info(f"‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞: {strategy}")
            return True
        else:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞: {strategy}")
            return False

    def get_filtering_statistics(self) -> dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        return self.quality_analyzer.get_strategy_statistics()

    def get_available_strategies(self) -> list[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        return ["conservative", "moderate", "aggressive"]

    def get_current_strategy_config(self) -> dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

        Returns:
            –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–∫—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        """
        return {
            "active_strategy": self.quality_analyzer.active_strategy.value,
            "strategy_params": self.quality_analyzer.strategy_params,
            "timeframe_weights": self.quality_analyzer.timeframe_weights.tolist(),
            "quality_weights": self.quality_analyzer.quality_weights,
        }
