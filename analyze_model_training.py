#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ checkpoint
"""

from pathlib import Path

import torch


def analyze_training():
    """–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""

    print("=" * 70)
    print("üìä –ê–ù–ê–õ–ò–ó –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
    model_path = Path("models/saved/best_model_20250728_215703.pth")
    checkpoint = torch.load(model_path, map_location="cpu")

    # 1. –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    if "history" in checkpoint:
        history = checkpoint["history"]
        print("\nüìà –ò–°–¢–û–†–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
        print("-" * 50)

        if "train_loss" in history:
            train_losses = history["train_loss"]
            print(f"–≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: {len(train_losses)}")
            print(f"–ù–∞—á–∞–ª—å–Ω—ã–π train loss: {train_losses[0]:.4f}")
            print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π train loss: {train_losses[-1]:.4f}")
            print(f"–õ—É—á—à–∏–π train loss: {min(train_losses):.4f}")

        if "val_loss" in history:
            val_losses = history["val_loss"]
            print(f"\n–ù–∞—á–∞–ª—å–Ω—ã–π val loss: {val_losses[0]:.4f}")
            print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π val loss: {val_losses[-1]:.4f}")
            print(f"–õ—É—á—à–∏–π val loss: {min(val_losses):.4f}")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
            if len(train_losses) > 0 and len(val_losses) > 0:
                final_gap = val_losses[-1] - train_losses[-1]
                print(f"\n–†–∞–∑–Ω–∏—Ü–∞ train/val –Ω–∞ –∫–æ–Ω–µ—Ü: {final_gap:.4f}")
                if final_gap > 0.5:
                    print("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ!")

        # –ú–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        if "val_direction_acc" in history:
            val_acc = history["val_direction_acc"]
            print("\nüéØ –¢–û–ß–ù–û–°–¢–¨ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø:")
            print(f"–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {val_acc[0]:.1%}")
            print(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {val_acc[-1]:.1%}")
            print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {max(val_acc):.1%}")

    # 2. –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    print("\nüìä –§–ò–ù–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ú–û–î–ï–õ–ò:")
    print("-" * 50)

    if "best_metrics" in checkpoint:
        metrics = checkpoint["best_metrics"]
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                if "loss" in key:
                    print(f"{key}: {value:.4f}")
                elif "acc" in key or "accuracy" in key:
                    print(f"{key}: {value:.1%}")
                else:
                    print(f"{key}: {value:.4f}")
            elif isinstance(value, dict):
                print(f"\n{key}:")
                for k, v in value.items():
                    if isinstance(v, (int, float)):
                        print(f"  {k}: {v:.3f}")

    # 3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
    if "config" in checkpoint:
        config = checkpoint["config"]
        print("\n‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
        print("-" * 50)

        if "training" in config:
            train_cfg = config["training"]
            print(f"Batch size: {train_cfg.get('batch_size', 'N/A')}")
            print(f"Learning rate: {train_cfg.get('lr', 'N/A')}")
            print(f"Epochs: {train_cfg.get('epochs', 'N/A')}")

        if "data" in config:
            data_cfg = config["data"]
            print("\n–î–∞–Ω–Ω—ã–µ:")
            print(f"  Symbols: {data_cfg.get('symbols', 'N/A')}")
            print(f"  Sequence length: {data_cfg.get('sequence_length', 'N/A')}")
            print(f"  Features: {data_cfg.get('num_features', 'N/A')}")

    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
    print("\nüîç –ê–ù–ê–õ–ò–ó –í–ï–°–û–í –ú–û–î–ï–õ–ò:")
    print("-" * 50)

    state_dict = checkpoint["model_state_dict"]

    # –ê–Ω–∞–ª–∏–∑ direction head
    direction_weights = []
    for key in state_dict.keys():
        if "direction" in key.lower() and "weight" in key:
            weights = state_dict[key]
            direction_weights.append(weights)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤
            w_mean = weights.mean().item()
            w_std = weights.std().item()
            w_min = weights.min().item()
            w_max = weights.max().item()

            print(f"\n{key}:")
            print(f"  Shape: {list(weights.shape)}")
            print(f"  Mean: {w_mean:.6f}")
            print(f"  Std: {w_std:.6f}")
            print(f"  Range: [{w_min:.6f}, {w_max:.6f}]")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã—Ä–æ–∂–¥–µ–Ω–Ω–æ—Å—Ç—å
            if w_std < 0.01:
                print("  ‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –≤–µ—Å–æ–≤!")
            if abs(w_mean) > 1.0:
                print("  ‚ö†Ô∏è –ë–æ–ª—å—à–æ–µ —Å–º–µ—â–µ–Ω–∏–µ –≤–µ—Å–æ–≤!")

    # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è
    print("\nüéØ –ê–ù–ê–õ–ò–ó –í–´–•–û–î–ù–û–ì–û –°–õ–û–Ø (direction):")
    print("-" * 50)

    # –ò—â–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π –¥–ª—è direction
    final_direction_key = None
    for key in state_dict.keys():
        if "direction" in key.lower() and ("3.weight" in key or "final" in key or "output" in key):
            final_direction_key = key
            break

    if final_direction_key:
        final_weights = state_dict[final_direction_key]
        print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π: {final_direction_key}")
        print(f"Shape: {list(final_weights.shape)}")

        # –î–ª—è direction head –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å [12, 128] -> 12 –≤—ã—Ö–æ–¥–æ–≤ = 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞
        if final_weights.shape[0] == 12:
            print("‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 12 –≤—ã—Ö–æ–¥–æ–≤ (4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ √ó 3 –∫–ª–∞—Å—Å–∞)")

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º
            weights_reshaped = final_weights.reshape(4, 3, -1)  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞, 3 –∫–ª–∞—Å—Å–∞

            for tf in range(4):
                print(f"\n–¢–∞–π–º—Ñ—Ä–µ–π–º {tf + 1}:")
                for cls in range(3):
                    class_weights = weights_reshaped[tf, cls]
                    cls_name = ["LONG", "SHORT", "NEUTRAL"][cls]
                    print(
                        f"  {cls_name}: mean={class_weights.mean():.4f}, std={class_weights.std():.4f}"
                    )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ bias
        bias_key = final_direction_key.replace("weight", "bias")
        if bias_key in state_dict:
            bias = state_dict[bias_key]
            print(f"\nBias: {bias.numpy()}")

            if bias.shape[0] == 12:
                bias_reshaped = bias.reshape(4, 3)
                print("\nBias –ø–æ –∫–ª–∞—Å—Å–∞–º:")
                for tf in range(4):
                    print(
                        f"  TF{tf + 1}: LONG={bias_reshaped[tf, 0]:.4f}, SHORT={bias_reshaped[tf, 1]:.4f}, NEUTRAL={bias_reshaped[tf, 2]:.4f}"
                    )

    print("\n" + "=" * 70)
    print("üí° –í–´–í–û–î–´ –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 70)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–±–ª–µ–º
    problems = []

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
    if "history" in checkpoint:
        if "val_direction_acc" in checkpoint["history"]:
            final_acc = checkpoint["history"]["val_direction_acc"][-1]
            if final_acc < 0.4:
                problems.append(f"–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {final_acc:.1%}")
            elif final_acc > 0.35 and final_acc < 0.36:
                problems.append("–¢–æ—á–Ω–æ—Å—Ç—å ~33% —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (3 –∫–ª–∞—Å—Å–∞)")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ val_loss
    if "val_loss" in checkpoint:
        val_loss = checkpoint["val_loss"]
        if val_loss > 2.0:
            problems.append(f"–í—ã—Å–æ–∫–∏–π val_loss: {val_loss:.4f}")

    if problems:
        print("\n‚ùå –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´:")
        for p in problems:
            print(f"  - {p}")
    else:
        print("\n‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")

    print(
        """
üìù –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ü–†–ê–í–ò–õ–¨–ù–û–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:

1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:
   - –í –æ–±—É—á–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å 240 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   - –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ feature_engineering –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ –∂–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é:
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ scaler —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
   - –§–∞–π–ª: models/saved/data_scaler.pkl

3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö:
   - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π context_length (96 —Å–≤–µ—á–µ–π)

4. –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –±—ã–ª–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–æ –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–µ–π—á–∞—Å:
   - –î–∞–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å (–¥—Ä—É–≥–æ–π —Ä—ã–Ω–æ–∫)
   - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
   - –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤–µ—Ä—Å–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫
    """
    )


if __name__ == "__main__":
    analyze_training()
